WARNING: grid.env NOT FOUND
NO Enviroment
Date: Thu 02 May 2024 04:44:30 PM UTC
Directory: /home/ferrazzi/llm/mistral_finetuning
This job will be executed on th following nodes: vgpu2-1

/home/ferrazzi/.conda/envs/gpu_venv_lates/bin/python
Python 3.8.18
['ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_8_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_16_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_32_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_8_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_16_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_32_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_8_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_16_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_32_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_8_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_16_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_32_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_8_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_16_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_32_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_8_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_16_0.0002', 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_32_0.0002']
MODEL TYPE: qwen
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_8_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_8_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_16_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_16_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_32_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_32_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_8_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_8_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_16_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_16_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_32_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_64_0.01_32_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_8_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_8_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_16_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_16_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_32_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_32_0.01_32_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_8_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_8_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_16_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_16_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_32_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_32_64_0.01_32_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_8_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_8_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_16_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_16_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_32_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_32_0.01_32_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_8_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_8_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_16_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_16_0.0002.csv
PROCESSING: ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_32_0.0002
QUANTIZATION
saved:  data/qwen/7B_8bit_FT//maxNewTokensFactor8_nShotsInference0_qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_64_64_0.01_32_0.0002.csv
Date: Fri 03 May 2024 10:19:14 PM UTC
