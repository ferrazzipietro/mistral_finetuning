{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mistral_res = pd.read_csv('data/evaluation_results/mistral_8bit.csv')\n",
    "mistral_res['file'] = mistral_res['file'].apply(lambda x: x.split('/')[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_params_from_file_name(df: pd.DataFrame):\n",
    "    df['maxNewTokensFactor'] = df['file'].apply(lambda x: re.search(r'maxNewTokensFactor(\\d+)', x).group(1))\n",
    "    df['nShotsInference'] = df['file'].apply(lambda x: re.search(r'nShotsInference(\\d+)', x).group(1))\n",
    "    #df['layer'] = df['file'].apply(lambda x: re.search(r'adapters_(\\s+)', x).group(1))\n",
    "    df['model'] = df['file'].apply(lambda x: str(x.split('_adapters_')[0].split('nShotsInference')[1][2:]))\n",
    "    df['training_params_string'] = df['file'].apply(lambda x: x.split('adapters_')[1])\n",
    "    df['nbit'] = df['training_params_string'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['bnb_4bit_compute_dtype'] = df['training_params_string'].apply(lambda x: x.split('_')[2])\n",
    "    df['r'] = df['training_params_string'].apply(lambda x: int(x.split('_')[3]))\n",
    "    df['lora_alpha'] = df['training_params_string'].apply(lambda x: int(x.split('_')[4]))\n",
    "    df['lora_dropout'] = df['training_params_string'].apply(lambda x: float(x.split('_')[5]))\n",
    "    df['gradient_accumulation_steps'] = df['training_params_string'].apply(lambda x: int(x.split('_')[6]))\n",
    "    df['learning_rate'] = df['training_params_string'].apply(lambda x: float(x.split('_')[7].split('.')[0]))\n",
    "    df = df.drop(columns=['training_params_string', 'file'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>model</th>\n",
       "      <th>newtokenfactor_number</th>\n",
       "      <th>maxNewTokensFactor</th>\n",
       "      <th>nShotsInference</th>\n",
       "      <th>nbit</th>\n",
       "      <th>bnb_4bit_compute_dtype</th>\n",
       "      <th>r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.493113</td>\n",
       "      <td>0.506430</td>\n",
       "      <td>0.480477</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.496172</td>\n",
       "      <td>0.509871</td>\n",
       "      <td>0.483189</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.502440</td>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.488612</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.509777</td>\n",
       "      <td>0.525634</td>\n",
       "      <td>0.494848</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.521496</td>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.504881</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>0.295463</td>\n",
       "      <td>0.279430</td>\n",
       "      <td>0.313449</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>True</td>\n",
       "      <td>65</td>\n",
       "      <td>0.304092</td>\n",
       "      <td>0.287754</td>\n",
       "      <td>0.322397</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>0.314791</td>\n",
       "      <td>0.298493</td>\n",
       "      <td>0.332972</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.267397</td>\n",
       "      <td>0.252285</td>\n",
       "      <td>0.284436</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.246596</td>\n",
       "      <td>0.232318</td>\n",
       "      <td>0.262744</td>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     similar_is_equal  similar_is_equal_threshold  f1_score  precision  \\\n",
       "0                True                          95  0.493113   0.506430   \n",
       "1                True                          90  0.496172   0.509871   \n",
       "2                True                          85  0.502440   0.517073   \n",
       "3                True                          80  0.509777   0.525634   \n",
       "4                True                          75  0.521496   0.539241   \n",
       "..                ...                         ...       ...        ...   \n",
       "686              True                          70  0.295463   0.279430   \n",
       "687              True                          65  0.304092   0.287754   \n",
       "688              True                          60  0.314791   0.298493   \n",
       "689              True                         100  0.267397   0.252285   \n",
       "690             False                         100  0.246596   0.232318   \n",
       "\n",
       "       recall                     model newtokenfactor_number  \\\n",
       "0    0.480477  Mistral-7B-Instruct-v0.2                     8   \n",
       "1    0.483189  Mistral-7B-Instruct-v0.2                     8   \n",
       "2    0.488612  Mistral-7B-Instruct-v0.2                     8   \n",
       "3    0.494848  Mistral-7B-Instruct-v0.2                     8   \n",
       "4    0.504881  Mistral-7B-Instruct-v0.2                     8   \n",
       "..        ...                       ...                   ...   \n",
       "686  0.313449  Mistral-7B-Instruct-v0.2                     8   \n",
       "687  0.322397  Mistral-7B-Instruct-v0.2                     8   \n",
       "688  0.332972  Mistral-7B-Instruct-v0.2                     8   \n",
       "689  0.284436  Mistral-7B-Instruct-v0.2                     8   \n",
       "690  0.262744  Mistral-7B-Instruct-v0.2                     8   \n",
       "\n",
       "    maxNewTokensFactor nShotsInference  nbit bnb_4bit_compute_dtype   r  \\\n",
       "0                    8               2     8         torch.bfloat16  64   \n",
       "1                    8               2     8         torch.bfloat16  64   \n",
       "2                    8               2     8         torch.bfloat16  64   \n",
       "3                    8               2     8         torch.bfloat16  64   \n",
       "4                    8               2     8         torch.bfloat16  64   \n",
       "..                 ...             ...   ...                    ...  ..   \n",
       "686                  8               2     8         torch.bfloat16  32   \n",
       "687                  8               2     8         torch.bfloat16  32   \n",
       "688                  8               2     8         torch.bfloat16  32   \n",
       "689                  8               2     8         torch.bfloat16  32   \n",
       "690                  8               2     8         torch.bfloat16  32   \n",
       "\n",
       "     lora_alpha  lora_dropout  gradient_accumulation_steps  learning_rate  \n",
       "0            32          0.01                            8            0.0  \n",
       "1            32          0.01                            8            0.0  \n",
       "2            32          0.01                            8            0.0  \n",
       "3            32          0.01                            8            0.0  \n",
       "4            32          0.01                            8            0.0  \n",
       "..          ...           ...                          ...            ...  \n",
       "686          32          0.01                            8            0.0  \n",
       "687          32          0.01                            8            0.0  \n",
       "688          32          0.01                            8            0.0  \n",
       "689          32          0.01                            8            0.0  \n",
       "690          32          0.01                            8            0.0  \n",
       "\n",
       "[691 rows x 16 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = extract_params_from_file_name(mistral_res)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_8_torch.bfloat16_64_32_0.01_8_0.0002.csv\n"
     ]
    }
   ],
   "source": [
    "print(mistral_res.file.to_list()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mistral_res[mistral_res['similar_is_equal_threshold']>=65].sort_values(by='f1_score', ascending=False)['file'].to_list()[0])\n",
    "print(mistral_res[mistral_res['similar_is_equal_threshold']>=65].sort_values(by='f1_score', ascending=False)['file'].to_list()[1])\n",
    "print(mistral_res[mistral_res['similar_is_equal_threshold']>=65].sort_values(by='f1_score', ascending=False)['file'].to_list()[2])\n",
    "print(mistral_res[mistral_res['similar_is_equal_threshold']>=65].sort_values(by='f1_score', ascending=False)['file'].to_list()[3])\n",
    "print(mistral_res[mistral_res['similar_is_equal_threshold']>=65].sort_values(by='f1_score', ascending=False)['file'].to_list()[4])\n",
    "print(mistral_res[mistral_res['similar_is_equal_threshold']>=65].sort_values(by='f1_score', ascending=False)['file'].to_list()[5])\n",
    "print(mistral_res[mistral_res['similar_is_equal_threshold']>=65].sort_values(by='f1_score', ascending=False)['file'].to_list()[6])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_finetune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
