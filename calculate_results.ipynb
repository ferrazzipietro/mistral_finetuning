{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_params_from_file_name(df: pd.DataFrame):\n",
    "    df['maxNewTokensFactor'] = df['file'].apply(lambda x: re.search(r'maxNewTokensFactor(\\d+)', x).group(1))\n",
    "    df['nShotsInference'] = df['file'].apply(lambda x: re.search(r'nShotsInference(\\d+)', x).group(1))\n",
    "    #df['layer'] = df['file'].apply(lambda x: re.search(r'adapters_(\\s+)', x).group(1))\n",
    "    df['model'] = df['file'].apply(lambda x: str(x.split('_adapters_')[0].split('nShotsInference')[1][2:]))\n",
    "    df['training_params_string'] = df['file'].apply(lambda x: x.split('adapters_')[1])\n",
    "    df['nbit'] = df['training_params_string'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['bnb_4bit_compute_dtype'] = df['training_params_string'].apply(lambda x: x.split('_')[2])\n",
    "    df['r'] = df['training_params_string'].apply(lambda x: int(x.split('_')[3]))\n",
    "    df['lora_alpha'] = df['training_params_string'].apply(lambda x: int(x.split('_')[4]))\n",
    "    df['lora_dropout'] = df['training_params_string'].apply(lambda x: float(x.split('_')[5]))\n",
    "    df['gradient_accumulation_steps'] = df['training_params_string'].apply(lambda x: int(x.split('_')[6]))\n",
    "    df['learning_rate'] = df['training_params_string'].apply(lambda x: float(x.split('_')[7].split('.')[0]))\n",
    "    df = df.drop(columns=['training_params_string', 'file'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_13B_4bit_base_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/llama_13B_4bit_base_wordsLevelTrue_evaluation.csv\")\n",
    "llama_13B_8bit_base_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/llama_13B_8bit_base_wordsLevelTrue_evaluation.csv\")\n",
    "llama_7B_4bit_base_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/llama_7B_4bit_base_wordsLevelTrue_evaluation.csv\")\n",
    "llama_7B_8bit_base_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/llama_7B_8bit_base_wordsLevelTrue_evaluation.csv\")\n",
    "llama_7B_8bit_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/llama_7B_8bit_wordsLevelTrue_evaluation.csv\")\n",
    "mistral_4bit_base_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/mistral_4bit_base_wordsLevelTrue_evaluation.csv\")\n",
    "mistral_4bit_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/mistral_4bit_wordsLevelTrue_evaluation.csv\")\n",
    "mistral_noInstr_4bit_wordsLevelTrue_evaluation = pd.read_csv(\"data/evaluation_results/mistral_noInstr_4bit_wordsLevelTrue_evaluation.csv\")\n",
    "\n",
    "# llama_13B_4bit_base_wordsLevelTrue_evaluation = extract_params_from_file_name(llama_13B_4bit_base_wordsLevelTrue_evaluation)\n",
    "# llama_13B_8bit_base_wordsLevelTrue_evaluation = extract_params_from_file_name(llama_13B_8bit_base_wordsLevelTrue_evaluation)\n",
    "# llama_7B_4bit_base_wordsLevelTrue_evaluation = extract_params_from_file_name(llama_7B_4bit_base_wordsLevelTrue_evaluation)\n",
    "# llama_7B_8bit_base_wordsLevelTrue_evaluation = extract_params_from_file_name(llama_7B_8bit_base_wordsLevelTrue_evaluation)\n",
    "# llama_7B_8bit_wordsLevelTrue_evaluation = extract_params_from_file_name(llama_7B_8bit_wordsLevelTrue_evaluation)\n",
    "# mistral_4bit_base_wordsLevelTrue_evaluation = extract_params_from_file_name(mistral_4bit_base_wordsLevelTrue_evaluation)\n",
    "# mistral_4bit_wordsLevelTrue_evaluation = extract_params_from_file_name(mistral_4bit_wordsLevelTrue_evaluation)\n",
    "# mistral_noInstr_4bit_wordsLevelTrue_evaluation = extract_params_from_file_name(mistral_noInstr_4bit_wordsLevelTrue_evaluation)\n",
    "\n",
    "res = pd.concat([llama_13B_4bit_base_wordsLevelTrue_evaluation, llama_13B_8bit_base_wordsLevelTrue_evaluation,\n",
    "           llama_7B_4bit_base_wordsLevelTrue_evaluation, llama_7B_8bit_base_wordsLevelTrue_evaluation,\n",
    "           llama_7B_8bit_wordsLevelTrue_evaluation, mistral_4bit_base_wordsLevelTrue_evaluation,\n",
    "           mistral_4bit_wordsLevelTrue_evaluation, mistral_noInstr_4bit_wordsLevelTrue_evaluation])#.to_csv('data/evaluation_results/joint_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '3B'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3B\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '3B'"
     ]
    }
   ],
   "source": [
    "l = '3B'\n",
    "int(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE:  data/evaluation_results/zefiro_4bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_noInstr_8bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/zefiro_NoQuant_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/zefiro_8bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_14B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_NoQuant_FT_float16.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_NoQuant_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_NoQuant_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_4bits_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_NoQuantbit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_14B_4bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_4bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_NoQuant_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_NoQuantbit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_8bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_14B_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_8bit_base_wordsLevelTrue_evaluation.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_configurations</th>\n",
       "      <th>model_size</th>\n",
       "      <th>quantization</th>\n",
       "      <th>fine_tuning</th>\n",
       "      <th>...</th>\n",
       "      <th>nShotsInference</th>\n",
       "      <th>model</th>\n",
       "      <th>nbit</th>\n",
       "      <th>bnb_4bit_compute_dtype</th>\n",
       "      <th>r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>similar_is_equal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.436886</td>\n",
       "      <td>0.368857</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>4</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor4_nShots...</td>\n",
       "      <td>0.347961</td>\n",
       "      <td>0.420459</td>\n",
       "      <td>0.296788</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>4</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>0.391605</td>\n",
       "      <td>0.630199</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>4</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.414676</td>\n",
       "      <td>0.387327</td>\n",
       "      <td>0.446180</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>4</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.450917</td>\n",
       "      <td>0.394938</td>\n",
       "      <td>0.525387</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>4</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.497369</td>\n",
       "      <td>0.556719</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>qwen</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7B</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>0.520493</td>\n",
       "      <td>0.555185</td>\n",
       "      <td>0.489881</td>\n",
       "      <td>qwen</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7B</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.509443</td>\n",
       "      <td>0.575241</td>\n",
       "      <td>0.457153</td>\n",
       "      <td>qwen</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7B</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.508342</td>\n",
       "      <td>0.560437</td>\n",
       "      <td>0.465108</td>\n",
       "      <td>qwen</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7B</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.467672</td>\n",
       "      <td>0.565293</td>\n",
       "      <td>0.398802</td>\n",
       "      <td>qwen</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7B</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1562 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               file  f1_score  \\\n",
       "0          0.0  data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.400000   \n",
       "1          1.0  data/zefiro/4bit_FT/maxNewTokensFactor4_nShots...  0.347961   \n",
       "2          2.0  data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.483046   \n",
       "3          3.0  data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.414676   \n",
       "4          4.0  data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.450917   \n",
       "..         ...                                                ...       ...   \n",
       "6          NaN  data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.497369   \n",
       "7          NaN  data/qwen/7B_8bit_base/maxNewTokensFactor8_nSh...  0.520493   \n",
       "8          NaN  data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.509443   \n",
       "9          NaN  data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.508342   \n",
       "10         NaN  data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.467672   \n",
       "\n",
       "    precision    recall model_type model_configurations model_size  \\\n",
       "0    0.436886  0.368857     zefiro              4bit_FT          7   \n",
       "1    0.420459  0.296788     zefiro              4bit_FT          7   \n",
       "2    0.391605  0.630199     zefiro              4bit_FT          7   \n",
       "3    0.387327  0.446180     zefiro              4bit_FT          7   \n",
       "4    0.394938  0.525387     zefiro              4bit_FT          7   \n",
       "..        ...       ...        ...                  ...        ...   \n",
       "6    0.556719  0.449454       qwen         7B_8bit_base         7B   \n",
       "7    0.555185  0.489881       qwen         7B_8bit_base         7B   \n",
       "8    0.575241  0.457153       qwen         7B_8bit_base         7B   \n",
       "9    0.560437  0.465108       qwen         7B_8bit_base         7B   \n",
       "10   0.565293  0.398802       qwen         7B_8bit_base         7B   \n",
       "\n",
       "   quantization fine_tuning  ... nShotsInference                        model  \\\n",
       "0          4bit          FT  ...               4          zefiro-7b-base-ita_   \n",
       "1          4bit          FT  ...               4          zefiro-7b-base-ita_   \n",
       "2          4bit          FT  ...               0          zefiro-7b-base-ita_   \n",
       "3          4bit          FT  ...               0          zefiro-7b-base-ita_   \n",
       "4          4bit          FT  ...               0          zefiro-7b-base-ita_   \n",
       "..          ...         ...  ...             ...                          ...   \n",
       "6          8bit        base  ...               3  BaseModel_Qwen1.5-7B-Chat_8   \n",
       "7          8bit        base  ...               1  BaseModel_Qwen1.5-7B-Chat_8   \n",
       "8          8bit        base  ...               1  BaseModel_Qwen1.5-7B-Chat_8   \n",
       "9          8bit        base  ...               4  BaseModel_Qwen1.5-7B-Chat_8   \n",
       "10         8bit        base  ...               0  BaseModel_Qwen1.5-7B-Chat_8   \n",
       "\n",
       "   nbit bnb_4bit_compute_dtype     r  lora_alpha  lora_dropout  \\\n",
       "0     4         torch.bfloat16  32.0        64.0          0.01   \n",
       "1     4         torch.bfloat16  64.0        32.0          0.01   \n",
       "2     4         torch.bfloat16  64.0        32.0          0.01   \n",
       "3     4         torch.bfloat16  32.0        64.0          0.01   \n",
       "4     4         torch.bfloat16  64.0        64.0          0.01   \n",
       "..  ...                    ...   ...         ...           ...   \n",
       "6   NaN                    NaN   NaN         NaN           NaN   \n",
       "7   NaN                    NaN   NaN         NaN           NaN   \n",
       "8   NaN                    NaN   NaN         NaN           NaN   \n",
       "9   NaN                    NaN   NaN         NaN           NaN   \n",
       "10  NaN                    NaN   NaN         NaN           NaN   \n",
       "\n",
       "    gradient_accumulation_steps  learning_rate similar_is_equal  \n",
       "0                           4.0         0.0002              NaN  \n",
       "1                           8.0         0.0002              NaN  \n",
       "2                           2.0         0.0002              NaN  \n",
       "3                           4.0         0.0002              NaN  \n",
       "4                           8.0         0.0002              NaN  \n",
       "..                          ...            ...              ...  \n",
       "6                           NaN            NaN              NaN  \n",
       "7                           NaN            NaN              NaN  \n",
       "8                           NaN            NaN              NaN  \n",
       "9                           NaN            NaN              NaN  \n",
       "10                          NaN            NaN              NaN  \n",
       "\n",
       "[1562 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_params_from_file_name(df: pd.DataFrame):\n",
    "\n",
    "    def adjust_model_size_format(model_size_str):\n",
    "        try:\n",
    "            int(model_size_str)\n",
    "        except ValueError:\n",
    "            model_size_str = model_size_str.replace('b', '').replace('B', '')\n",
    "\n",
    "\n",
    "\n",
    "    df['model_type'] = df['file'].apply(lambda x: str(x.split('/')[1]))\n",
    "    df['model_configurations'] = df['file'].apply(lambda x: str(x.split('/')[2]))\n",
    "    if df['model_type'][0] == 'mistral' or df['model_type'][0] == 'zefiro':\n",
    "        df['model_size'] = 7\n",
    "        df['quantization'] = df['model_configurations'].apply(lambda x: str(x.split('_')[0]))\n",
    "        try:\n",
    "            df['fine_tuning'] = df['model_configurations'].apply(lambda x: str(x.split('_')[1]))\n",
    "        except IndexError:\n",
    "            df['fine_tuning'] = 'FT'\n",
    "    else:\n",
    "        df['model_size'] = df['model_configurations'].apply(lambda x: str(x.split('_')[0]))\n",
    "        df['quantization'] = df['model_configurations'].apply(lambda x: str(x.split('_')[1]))\n",
    "        df['fine_tuning'] = df['model_configurations'].apply(lambda x: str(x.split('_')[2]))\n",
    "\n",
    "    df['maxNewTokensFactor'] = df['file'].apply(lambda x: re.search(r'maxNewTokensFactor(\\d+)', x).group(1))\n",
    "    df['nShotsInference'] = df['file'].apply(lambda x: re.search(r'nShotsInference(\\d+)', x).group(1))\n",
    "    #\n",
    "    # df['layer'] = df['file'].apply(lambda x: re.search(r'adapters_(\\s+)', x).group(1))\n",
    "    df['model'] = df['file'].apply(lambda x: str(x.split('_adapters_')[0].split('nShotsInference')[1][2:].replace('.csv', '')))\n",
    "    if df['fine_tuning'][0] == 'FT':\n",
    "        df['training_params_string'] = df['file'].apply(lambda x: x.split('adapters_')[1])\n",
    "        df['nbit'] = df['training_params_string'].apply(lambda x: x.split('_')[1])\n",
    "        df['bnb_4bit_compute_dtype'] = df['training_params_string'].apply(lambda x: x.split('_')[2])\n",
    "        df['r'] = df['training_params_string'].apply(lambda x: int(x.split('_')[3]))\n",
    "        df['lora_alpha'] = df['training_params_string'].apply(lambda x: int(x.split('_')[4]))\n",
    "        df['lora_dropout'] = df['training_params_string'].apply(lambda x: float(x.split('_')[5]))\n",
    "        df['gradient_accumulation_steps'] = df['training_params_string'].apply(lambda x: int(x.split('_')[6]))\n",
    "        df['learning_rate'] = df['training_params_string'].apply(lambda x: x.split('_')[7].replace('.csv', ''))\n",
    "    elif df['fine_tuning'][0] in ['base', 'NoFT']:\n",
    "        df['training_params_string'] = None\n",
    "    return df\n",
    "\n",
    "csv_files = glob.glob('data/evaluation_results/*.csv')\n",
    "dfs = []\n",
    "empty_n = 0\n",
    "for file in csv_files:\n",
    "    if file =='data/evaluation_results/joint_results.csv':\n",
    "        continue\n",
    "    tmp_df = pd.read_csv(file)\n",
    "    if tmp_df.shape[0] == 0:\n",
    "        print('EMPTY FILE: ', file)\n",
    "        empty_n += 1\n",
    "        continue\n",
    "    print('SOURCE: ', file)\n",
    "    tmp_df = extract_params_from_file_name(tmp_df)\n",
    "    dfs.append(tmp_df)\n",
    "\n",
    "res = pd.concat(dfs)\n",
    "\n",
    "res = res.drop(['training_params_string', 'similar_is_equal_threshold'], axis = 1)\n",
    "display(res)\n",
    "res.to_csv('data/evaluation_results/joint_results.csv')\n",
    "# res = res.drop(columns=['similar_is_equal', 'similar_is_equal_threshold'])\n",
    "# print(empty_n)\n",
    "# res.sort_values(by='f1_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(file)\n",
    "extract_params_from_file_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_finetune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
