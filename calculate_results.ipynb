{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE:  data/evaluation_results/zefiro_4bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_noInstr_8bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_NoQuant_FT_bfloat.csv\n",
      "SOURCE:  data/evaluation_results/zefiro_NoQuant_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/zefiro_8bit_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_14B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama3_8B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_14B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistralNoQuant_FT_bfloat_ora.csv\n",
      "SOURCE:  data/evaluation_results/mistral_NoQuant_base_bfloat16.csv\n",
      "SOURCE:  data/evaluation_results/mistral_NoQuant_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_NoQuant_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama13B_8bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama13B_NoQuant_FT_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_NoQuant_FT.csv\n",
      "SOURCE:  data/evaluation_results/mistral_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_NoQuant_FT.csv\n",
      "SOURCE:  data/evaluation_results/mistra_8bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_NoQuant_FT_float32.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_NoQuantbit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_8bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_8bit_FT_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_4bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_NoQuant_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/mistral_NoQuant_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_13B_NoQuantbit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_NoQuant_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/llama_7B_4bit_FT_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_14B_8bit_base_wordsLevelTrue_evaluation.csv\n",
      "SOURCE:  data/evaluation_results/qwen_7B_8bit_base_wordsLevelTrue_evaluation.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>model_type</th>\n",
       "      <th>instructed</th>\n",
       "      <th>model_configurations</th>\n",
       "      <th>model_size</th>\n",
       "      <th>quantization</th>\n",
       "      <th>fine_tuning</th>\n",
       "      <th>maxNewTokensFactor</th>\n",
       "      <th>nShotsInference</th>\n",
       "      <th>model</th>\n",
       "      <th>bnb_4bit_compute_dtype</th>\n",
       "      <th>r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.436886</td>\n",
       "      <td>0.368857</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>instructed</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor4_nShots...</td>\n",
       "      <td>0.347961</td>\n",
       "      <td>0.420459</td>\n",
       "      <td>0.296788</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>instructed</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>0.391605</td>\n",
       "      <td>0.630199</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>instructed</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.414676</td>\n",
       "      <td>0.387327</td>\n",
       "      <td>0.446180</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>instructed</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>0.450917</td>\n",
       "      <td>0.394938</td>\n",
       "      <td>0.525387</td>\n",
       "      <td>zefiro</td>\n",
       "      <td>instructed</td>\n",
       "      <td>4bit_FT</td>\n",
       "      <td>7</td>\n",
       "      <td>4bit</td>\n",
       "      <td>FT</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>zefiro-7b-base-ita_</td>\n",
       "      <td>torch.bfloat16</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.497369</td>\n",
       "      <td>0.556719</td>\n",
       "      <td>0.449454</td>\n",
       "      <td>qwen</td>\n",
       "      <td>instructed</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>0.520493</td>\n",
       "      <td>0.555185</td>\n",
       "      <td>0.489881</td>\n",
       "      <td>qwen</td>\n",
       "      <td>instructed</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.509443</td>\n",
       "      <td>0.575241</td>\n",
       "      <td>0.457153</td>\n",
       "      <td>qwen</td>\n",
       "      <td>instructed</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.508342</td>\n",
       "      <td>0.560437</td>\n",
       "      <td>0.465108</td>\n",
       "      <td>qwen</td>\n",
       "      <td>instructed</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>0.467672</td>\n",
       "      <td>0.565293</td>\n",
       "      <td>0.398802</td>\n",
       "      <td>qwen</td>\n",
       "      <td>instructed</td>\n",
       "      <td>7B_8bit_base</td>\n",
       "      <td>7</td>\n",
       "      <td>8bit</td>\n",
       "      <td>base</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>BaseModel_Qwen1.5-7B-Chat_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2481 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  f1_score  precision  \\\n",
       "0   data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.400000   0.436886   \n",
       "1   data/zefiro/4bit_FT/maxNewTokensFactor4_nShots...  0.347961   0.420459   \n",
       "2   data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.483046   0.391605   \n",
       "3   data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.414676   0.387327   \n",
       "4   data/zefiro/4bit_FT/maxNewTokensFactor8_nShots...  0.450917   0.394938   \n",
       "..                                                ...       ...        ...   \n",
       "6   data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.497369   0.556719   \n",
       "7   data/qwen/7B_8bit_base/maxNewTokensFactor8_nSh...  0.520493   0.555185   \n",
       "8   data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.509443   0.575241   \n",
       "9   data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.508342   0.560437   \n",
       "10  data/qwen/7B_8bit_base/maxNewTokensFactor4_nSh...  0.467672   0.565293   \n",
       "\n",
       "      recall model_type  instructed model_configurations model_size  \\\n",
       "0   0.368857     zefiro  instructed              4bit_FT          7   \n",
       "1   0.296788     zefiro  instructed              4bit_FT          7   \n",
       "2   0.630199     zefiro  instructed              4bit_FT          7   \n",
       "3   0.446180     zefiro  instructed              4bit_FT          7   \n",
       "4   0.525387     zefiro  instructed              4bit_FT          7   \n",
       "..       ...        ...         ...                  ...        ...   \n",
       "6   0.449454       qwen  instructed         7B_8bit_base          7   \n",
       "7   0.489881       qwen  instructed         7B_8bit_base          7   \n",
       "8   0.457153       qwen  instructed         7B_8bit_base          7   \n",
       "9   0.465108       qwen  instructed         7B_8bit_base          7   \n",
       "10  0.398802       qwen  instructed         7B_8bit_base          7   \n",
       "\n",
       "   quantization fine_tuning maxNewTokensFactor nShotsInference  \\\n",
       "0          4bit          FT                  8               4   \n",
       "1          4bit          FT                  4               4   \n",
       "2          4bit          FT                  8               0   \n",
       "3          4bit          FT                  8               0   \n",
       "4          4bit          FT                  8               0   \n",
       "..          ...         ...                ...             ...   \n",
       "6          8bit        base                  4               3   \n",
       "7          8bit        base                  8               1   \n",
       "8          8bit        base                  4               1   \n",
       "9          8bit        base                  4               4   \n",
       "10         8bit        base                  4               0   \n",
       "\n",
       "                          model bnb_4bit_compute_dtype     r  lora_alpha  \\\n",
       "0           zefiro-7b-base-ita_         torch.bfloat16  32.0        64.0   \n",
       "1           zefiro-7b-base-ita_         torch.bfloat16  64.0        32.0   \n",
       "2           zefiro-7b-base-ita_         torch.bfloat16  64.0        32.0   \n",
       "3           zefiro-7b-base-ita_         torch.bfloat16  32.0        64.0   \n",
       "4           zefiro-7b-base-ita_         torch.bfloat16  64.0        64.0   \n",
       "..                          ...                    ...   ...         ...   \n",
       "6   BaseModel_Qwen1.5-7B-Chat_8                    NaN   NaN         NaN   \n",
       "7   BaseModel_Qwen1.5-7B-Chat_8                    NaN   NaN         NaN   \n",
       "8   BaseModel_Qwen1.5-7B-Chat_8                    NaN   NaN         NaN   \n",
       "9   BaseModel_Qwen1.5-7B-Chat_8                    NaN   NaN         NaN   \n",
       "10  BaseModel_Qwen1.5-7B-Chat_8                    NaN   NaN         NaN   \n",
       "\n",
       "    lora_dropout  gradient_accumulation_steps learning_rate  \n",
       "0           0.01                          4.0        0.0002  \n",
       "1           0.01                          8.0        0.0002  \n",
       "2           0.01                          2.0        0.0002  \n",
       "3           0.01                          4.0        0.0002  \n",
       "4           0.01                          8.0        0.0002  \n",
       "..           ...                          ...           ...  \n",
       "6            NaN                          NaN           NaN  \n",
       "7            NaN                          NaN           NaN  \n",
       "8            NaN                          NaN           NaN  \n",
       "9            NaN                          NaN           NaN  \n",
       "10           NaN                          NaN           NaN  \n",
       "\n",
       "[2481 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "from utils.calculate_results_helper import extract_params_from_file_name, refine_output_df\n",
    "\n",
    "csv_files = glob.glob('data/evaluation_results/*.csv')\n",
    "dfs = []\n",
    "empty_n = 0\n",
    "for file in csv_files:\n",
    "    if file =='data/evaluation_results/joint_results.csv':\n",
    "        continue\n",
    "    tmp_df = pd.read_csv(file)\n",
    "    if tmp_df.shape[0] == 0:\n",
    "        print('EMPTY FILE: ', file)\n",
    "        empty_n += 1\n",
    "        continue\n",
    "    print('SOURCE: ', file)\n",
    "    tmp_df = extract_params_from_file_name(tmp_df)\n",
    "    dfs.append(tmp_df)\n",
    "\n",
    "res = pd.concat(dfs)\n",
    "res = refine_output_df(res)\n",
    "display(res)\n",
    "res.to_csv('data/evaluation_results/joint_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col:  model_type vals:  ['zefiro' 'mistral' 'qwen' 'llama']\n",
      "col:  instructed vals:  ['instructed' 'notInstructed']\n",
      "col:  model_size vals:  ['7' '14' '13']\n",
      "col:  quantization vals:  ['4bit' '8bit' 'NoQuant']\n",
      "col:  fine_tuning vals:  ['FT' 'unsure' 'base']\n",
      "col:  maxNewTokensFactor vals:  ['8' '4' '2']\n",
      "col:  nShotsInference vals:  ['4' '0' '2' '1' '3']\n",
      "col:  bnb_4bit_compute_dtype vals:  ['torch.bfloat16' nan]\n",
      "col:  r vals:  [32. 64. 16. nan]\n",
      "col:  lora_alpha vals:  [64. 32. nan]\n",
      "col:  lora_dropout vals:  [0.01  nan 0.05]\n",
      "col:  gradient_accumulation_steps vals:  [ 4.  8.  2. nan 16.]\n",
      "col:  learning_rate vals:  ['0.0002' nan '0.0008' '0.002']\n"
     ]
    }
   ],
   "source": [
    "for col in res.columns:\n",
    "    if col in ['file', 'f1_score', 'recall', 'precision', 'model_configurations', 'model']:\n",
    "        continue\n",
    "    print('col: ', col, 'vals: ', res[col].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_finetune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
