{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is the best model for Llama 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/llama/7B_NoQuant_FT/maxNewTokensFactor8_nShotsInference0_llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002.csv\"\n",
    "apadpetrs_checkpoint = \"ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "class OutputAnalist():\n",
    "    def __init__(self, data, verbose=False) -> None:\n",
    "        self.verbose = verbose\n",
    "        self.data = data\n",
    "        self.counter_dict = {\n",
    "            'perfect_output':0,\n",
    "            'is_empty_list':0,\n",
    "            'is_list_of_lists':0,\n",
    "            'is_list_of_dicts':0,\n",
    "            'is_list_of_lists_and_dict':0,\n",
    "            'is_list_of_strings':0,\n",
    "            'is_list_of_empty_dict':0,\n",
    "            'is_list_with_one_empty_dict':0,\n",
    "            'is_list_of_dicts_with_empty_lists':0,\n",
    "            'is_list_of_dicts_with_one_key_multiple_values':0,\n",
    "            'is_list_of_dicts_with_multiple_keys_included_entity':0,\n",
    "            'is_list_of_dict_numeric_values':0,\n",
    "            'is_list_of_dicts_none_values':0,\n",
    "            'is_list_of_dicts_and_strings':0,\n",
    "            'is_list_of_dicts_and_lists_of_strings':0,\n",
    "            'is_list_of_dicts_with_value_list':0,\n",
    "            'is_string':0,\n",
    "            'is_list_of_strings_representing_dicts':0,\n",
    "            'is_list_of_dicts_of_lists':0,\n",
    "            'is_numeric':0,\n",
    "            'are_entities_extracted_as_dict_keys_instead_of_values':0,\n",
    "            'uknown':0\n",
    "        }\n",
    "  \n",
    "    def _remove_space_from_dict_keys(self, model_ouput_list: list) -> list:\n",
    "        \"\"\"\n",
    "        Remove the spaces from the keys of a dictionary. E.g., [{\"entity \": \"value\"}] -> [{\"entity\": \"value\"}]\n",
    "\n",
    "        Args:\n",
    "        model_ouput_list (dict): the list of dictionaries to be cleaned\n",
    "\n",
    "        return:\n",
    "        list: the cleaned list of dicts\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for dict in model_ouput_list:\n",
    "            # print('DICT: ', dict)\n",
    "            out.append({k.replace(' ', ''): v for k, v in dict.items()})\n",
    "        return out\n",
    "    \n",
    "    def _drop_duplicates(self, model_response: list) -> str:\n",
    "        \"\"\"\n",
    "        Drop the duplicates from a list. This is useful when the model output contains the same entity multiple times.\n",
    "\n",
    "        Args:\n",
    "        model_response (str): the model response with no duplicates\n",
    "        \"\"\"\n",
    "        # print('DROPPING DUPLICATES: ', model_response)\n",
    "        try :\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        except Exception as error:\n",
    "            model_response = self._remove_space_from_dict_keys(model_response)\n",
    "            # print('ERROR: ', model_response)\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        \n",
    "    def _assess_model_output(self, model_response: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the model output is in the right format. If not, return False.\n",
    "        \n",
    "        Args:\n",
    "        model_output (str): the postprocessed model output after beeing passed to _postprocess_model_output()\n",
    "\n",
    "        return:\n",
    "        bool: True if the format is correct, False otherwise\n",
    "        \"\"\"\n",
    "        good_format = True\n",
    "        try :\n",
    "            res = json.loads(model_response)\n",
    "            # print( res)\n",
    "        except:\n",
    "            good_format = False\n",
    "        return good_format\n",
    "\n",
    "            \n",
    "    def _remove_json_special_chars(self, string):\n",
    "        \"\"\"\n",
    "        Remove the special characters from a string. This is useful when the model output contains special characters that are not allowed in the json format.\n",
    "        \"\"\"\n",
    "        # print('sto pulendo: ', string)\n",
    "        chars = ['\\xa0', '\\x80', '\\x93', '\\U00100000', '\\r\\n', '\\U00100000I', '\\\\u001d', '\\\\\"']\n",
    "        for char in chars:\n",
    "            string = string.replace(char, ' ')\n",
    "        char_no_space = ['\\xad']\n",
    "        for char in char_no_space:\n",
    "            string = string.replace(char, '')\n",
    "        string = string.replace('\\\\u0010', '^')\n",
    "        return string\n",
    "    \n",
    "    \n",
    "    def _clean_ground_truth(self, example: dict) -> dict:\n",
    "        ground_truth = example['ground_truth']\n",
    "        # print('inner ground truth: ', ground_truth)\n",
    "        ground_truth = self._remove_json_special_chars(ground_truth)\n",
    "        ground_truth = ground_truth.replace('</s>', '').replace('<|im_e', '').replace('<|end_of_text|>', '').replace('<|endoftext|>', '')\n",
    "        return({'ground_truth': ground_truth})\n",
    "\n",
    "    def _clean_model_output(self, example: dict,  wrong_keys_to_entity:bool, latest_version:bool=True) -> dict:\n",
    "        \"\"\"\n",
    "        Postprocess the model output to return a json like formatted string that can be used to compute the F1 score.\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the model output as it is returned by the model. The processing of the output is done in the function\n",
    "        wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'. If not, all keys that are not 'entity' are dropped\n",
    "\n",
    "        return:\n",
    "        dict: the model response\n",
    "\n",
    "        \"\"\"\n",
    "       \n",
    "        def is_empty_list(string:str)  -> bool:\n",
    "            if string=='[]':\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_lists(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, list) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_lists_and_dict(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                found_dict = False\n",
    "                found_list = False\n",
    "                for element in tmp:\n",
    "                    if isinstance(element, list):\n",
    "                        found_list = True\n",
    "                    elif isinstance(element, dict):\n",
    "                        found_dict = True\n",
    "                    if found_list and found_dict:\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, str) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_empty_dict(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                #print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    if all(str(item) == \"{}\" for item in tmp):\n",
    "                        return True\n",
    "            return False\n",
    "\n",
    "        def is_list_with_one_empty_dict(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list):\n",
    "                    for item in tmp:\n",
    "                        if item == {}:\n",
    "                            return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_with_empty_lists(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        for v in item.values():\n",
    "                            if v == []:\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_with_one_key_multiple_values(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item) == 1 and len(item.values()) > 1:\n",
    "                            return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_dicts_with_multiple_keys_included_entity(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item) > 1 and 'entity' in item.keys():\n",
    "                            return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_dict_numeric_values(string:str)  -> bool:\n",
    "            #print('STRING: ', string)\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                #print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item.values()) > 0:\n",
    "                            val = list(item.values())[0] \n",
    "                            if isinstance(val, int) or isinstance(val, float):\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_none_values(string:str) -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item.values()) > 0:\n",
    "                            val = list(item.values())[0] \n",
    "                            if val is None:\n",
    "                                return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_dicts_and_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                #print('ASSESSED')\n",
    "                tmp = json.loads(string)\n",
    "                found_dict = False\n",
    "                found_string = False\n",
    "                for element in tmp:\n",
    "                    if isinstance(element, str):\n",
    "                        found_string = True\n",
    "                    elif isinstance(element, dict):\n",
    "                        found_dict = True\n",
    "                    if found_string and found_dict:\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_and_lists_of_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                # print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list):\n",
    "                    if all(isinstance(item, dict) for item in tmp):\n",
    "                        return False\n",
    "                    for item in tmp:\n",
    "                        # print('ITEM: ', item)\n",
    "                        if isinstance(item, dict):\n",
    "                            \n",
    "                            if len(item.values()) == 0:\n",
    "                               return False\n",
    "                            if item.get('entity') is None:\n",
    "                                return False\n",
    "                        elif isinstance(item, list):\n",
    "                            if len(item) != 1:\n",
    "                                return False\n",
    "                            if not isinstance(item[0], str):\n",
    "                                return False\n",
    "                        else:\n",
    "                            return False\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_with_value_list(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        for v in item.values():\n",
    "                            if isinstance(v, list):\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_string(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, str):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_strings_representing_dicts(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                # print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, str) for item in tmp):\n",
    "                    tmp_list = []\n",
    "                    for item in tmp:\n",
    "                        # print('ITEM: ', item)\n",
    "                        if self._assess_model_output(item):\n",
    "                          tmp_list.append(json.loads(item))\n",
    "                    if all(isinstance(item, dict) for item in tmp_list):\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_of_lists(string:str)  -> bool:\n",
    "            # print('STRING: ', string)\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                # print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        # print('item: ',item)\n",
    "                        tmp2 = list(item.values())[0]\n",
    "                        if len(tmp2) > 0:\n",
    "                            if isinstance(list(item.values())[0], list):\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_numeric(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, (int, float)):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def are_entities_extracted_as_dict_keys_instead_of_values(string:str, example:dict) -> bool:\n",
    "            if is_list_of_dicts(string):\n",
    "                tmp = json.loads(string)\n",
    "                keys = [key for item in tmp for key in item.keys()]\n",
    "                if 'entity' not in keys:\n",
    "                    if all(entity in example['sentence'] for entity in keys):\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        \n",
    "        def convert_wrong_keys_into_entity(string:str) -> List[str]:\n",
    "            if is_list_of_dicts(string):\n",
    "                tmp = json.loads(string)\n",
    "                tmp = [str({\"entity\":v}) for el in tmp for v in el.values()]\n",
    "                return tmp\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "\n",
    "        def only_dicts_with_key_entity(string:str, wrong_keys_to_entity:bool) -> Tuple[bool, str]:\n",
    "            \"\"\"\n",
    "            Extract only the dictionaries with the key 'entity' in the list of dictionaries in the string\n",
    "            \n",
    "            Args:\n",
    "            string (str): the string to be cleaned\n",
    "            wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'\n",
    "            \"\"\"\n",
    "            els_between_curly = re.findall(r'\\{(.+?)\\}', string)\n",
    "            clean = [el for el in els_between_curly if el.startswith('\"entity\"') or el.startswith(\"'entity'\")]\n",
    "            clean = ['{' + el + '}' for el in clean]\n",
    "            dirty = []\n",
    "            if wrong_keys_to_entity:\n",
    "                dirty = [el for el in els_between_curly if (not el.startswith('\"entity\"')) and (not el.startswith(\"'entity'\"))]\n",
    "                dirty = ['{' + el + '}' for el in dirty]\n",
    "                dirty = '[' + ', '.join(dirty) + ']'\n",
    "                cleaned_dirty = convert_wrong_keys_into_entity(dirty)\n",
    "                out = '[' + ', '.join(clean) + ', '.join(cleaned_dirty) +  ']'\n",
    "            else:\n",
    "                out = '[' + ', '.join(clean) + ']'\n",
    "            # out = out.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\" \\'\", \" \\\"\")\n",
    "            operations_performed = False\n",
    "            if len(clean) != len(els_between_curly):\n",
    "                operations_performed = True\n",
    "            if is_empty_list(out):\n",
    "                return operations_performed, '[{\"entity\":\"\"}]'\n",
    "            return operations_performed, str(out)\n",
    "        \n",
    "        if self.verbose: print('EXAMPLE:  ', example['model_responses'])\n",
    "        model_output = example['model_responses']\n",
    "        if self.verbose: print('ORIGINAL MODEL OUTPUT:', model_output)\n",
    "        # print('ORIGINAL MODEL OUTPUT:', model_output)\n",
    "        if self.verbose: print('GROUND TRUTH: ', example['ground_truth'])\n",
    "        # model_output = self._exceptions_handler(model_output)\n",
    "\n",
    "        if is_list_of_dicts(model_output):\n",
    "            self.counter_dict['perfect_output'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts')\n",
    "            tmp = json.loads(model_output)\n",
    "            return {'model_output':str(tmp)}\n",
    "    \n",
    "        if model_output is None or is_empty_list(model_output):\n",
    "            return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "        # model_output = self._special_cases_handler(model_output)\n",
    "        model_output = self._remove_json_special_chars(model_output)\n",
    "        if self.verbose:print('PULITO: ', model_output)\n",
    "\n",
    "                \n",
    "        if are_entities_extracted_as_dict_keys_instead_of_values(model_output, example):\n",
    "            self.counter_dict['are_entities_extracted_as_dict_keys_instead_of_values'] += 1\n",
    "            if self.verbose: print('ENTITIES EXTRACTED AS DICT KEYS INSTEAD OF VALUES')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":k} for el in tmp for k in el.keys() ]\n",
    "            tmp = str(tmp)\n",
    "            return {'model_output':tmp}\n",
    "        \n",
    "        if is_list_of_dicts_and_lists_of_strings(model_output):\n",
    "            self.counter_dict['is_list_of_dicts_and_lists_of_strings'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts_and_lists_of_strings')\n",
    "            tmp = json.loads(model_output)\n",
    "            out = []\n",
    "            for item in tmp:\n",
    "                if self.verbose: print('ITEM: ', item)\n",
    "                if isinstance(item, dict):\n",
    "                    out.append(item)\n",
    "                elif isinstance(item, list):\n",
    "                    out.append({\"entity\":item[0]})\n",
    "            return {'model_output':str(out)}\n",
    "\n",
    "        if is_numeric(model_output):\n",
    "            self.counter_dict['is_numeric'] += 1\n",
    "            # print('IS NUMERIC')\n",
    "            return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "\n",
    "        # print('QUI HO QUESTO: ', model_output)\n",
    "        if is_list_of_strings_representing_dicts(model_output):\n",
    "            self.counter_dict['is_list_of_strings_representing_dicts'] += 1\n",
    "            if self.verbose: print('is_list_of_strings_representing_dicts 1')                \n",
    "            tmp = json.loads(model_output)\n",
    "            tmp_list = []\n",
    "            for item in tmp:\n",
    "                if self._assess_model_output(item):\n",
    "                  tmp_list.append(json.loads(item))\n",
    "            if self.verbose: print('TEMPOOOO 2 ',tmp)\n",
    "            return {'model_output':str(tmp_list)}\n",
    "        \n",
    "        if is_list_of_dicts_with_one_key_multiple_values(model_output):\n",
    "            self.counter_dict['is_list_of_dicts_with_one_key_multiple_values'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts_with_one_key_multiple_values')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":v[0]} for el in tmp for v in el.values()]\n",
    "            return {'model_output':str(tmp)}\n",
    "       \n",
    "        if is_list_of_dicts_with_multiple_keys_included_entity(model_output):\n",
    "            self.counter_dict['is_list_of_dicts_with_multiple_keys_included_entity'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts_with_multiple_keys_included_entity')\n",
    "            tmp = json.loads(model_output)\n",
    "            out = []\n",
    "            for item in tmp:\n",
    "                if item.get('entity') is not None:\n",
    "                    out.append({\"entity\":item.get('entity')})\n",
    "            return {'model_output':str(out)}\n",
    "        \n",
    "        \n",
    "        if is_list_of_lists_and_dict(model_output):\n",
    "            self.counter_dict['is_list_of_lists_and_dict'] += 1\n",
    "            if self.verbose: print('is_list_of_lists_and_dict')\n",
    "            tmp = json.loads(model_output)\n",
    "            for el in tmp:\n",
    "                if isinstance(el, list):\n",
    "                    tmp = str(el)\n",
    "                    # print('is_list_of_lists_and_dict')\n",
    "                    return {'model_output':tmp}\n",
    "                \n",
    "        if is_list_of_lists(model_output):\n",
    "            self.counter_dict['is_list_of_lists'] += 1\n",
    "            if self.verbose: print('is_list_of_lists')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp2 = str(tmp[0]).replace(\"'\", \"\\\"\")\n",
    "            if is_list_of_dicts_and_strings(tmp2):\n",
    "                tmp = tmp[0]\n",
    "                out = [item for item in tmp if isinstance(item, dict)]\n",
    "                return {'model_output':str(out)} \n",
    "            tmp = str(tmp[0])\n",
    "            return {'model_output':tmp}\n",
    "        \n",
    "\n",
    "        if is_list_of_strings(model_output):\n",
    "            self.counter_dict['is_list_of_strings'] += 1\n",
    "            if self.verbose: print('is_list_of_strings')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":el} for el in tmp]\n",
    "            tmp = str(tmp)\n",
    "            # print('is_list_of_strings')\n",
    "            if self.verbose: print('TEMPOOOO ',tmp)\n",
    "            return {'model_output': tmp}\n",
    "        \n",
    "        if is_string(model_output):\n",
    "            self.counter_dict['is_string'] += 1\n",
    "            # model_output = model_output.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\" \\'\", \" \\\"\")\n",
    "            if self.verbose: print('PULO: ', model_output)\n",
    "            tmp = json.loads(model_output)\n",
    "            if all(el in tmp for el in ['{', 'entity', '}']):\n",
    "                return {'model_output':tmp}\n",
    "            tmp = [{\"entity\":tmp}]\n",
    "            tmp = str(tmp)\n",
    "            #print('is_string')\n",
    "            return {'model_output':tmp}\n",
    "\n",
    "        \n",
    "        if latest_version:\n",
    "            model_output = self._extract_text_between_curl_brackets(model_output)\n",
    "            model_output = self._clean_text_between_curl_brackets(model_output)\n",
    "\n",
    "            # print('QUI HO il SECONDO QUESTO: ', model_output)\n",
    "\n",
    "            if is_list_of_strings_representing_dicts(model_output):\n",
    "                self.counter_dict['is_list_of_strings_representing_dicts'] += 1\n",
    "                if self.verbose: print('is_list_of_strings_representing_dicts 2')                \n",
    "                tmp = json.loads(model_output)\n",
    "                tmp_list = []\n",
    "                for item in tmp:\n",
    "                    if self._assess_model_output(item):\n",
    "                        tmp_list.append(json.loads(item))\n",
    "                return {'model_output':str(tmp_list)}\n",
    "            \n",
    "            if is_list_of_dicts_with_one_key_multiple_values(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_with_one_key_multiple_values'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_with_one_key_multiple_values')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v[0]} for el in tmp for v in el.values()]\n",
    "                return {'model_output':str(tmp)}\n",
    "            \n",
    "            if is_list_of_dicts_and_lists_of_strings(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_and_lists_of_strings'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_and_lists_of_strings')\n",
    "                tmp = json.loads(model_output)\n",
    "                out = []\n",
    "                for item in tmp:\n",
    "                    # print('ITEM: ', item)\n",
    "                    if isinstance(item, dict):\n",
    "                        out.append(item)\n",
    "                    elif isinstance(item, list):\n",
    "                        out.append({\"entity\":item[0]})\n",
    "                return {'model_output':str(out)}\n",
    "            \n",
    "            if self.verbose: print('QUI HO il TEERZO QUESTO: ', model_output)\n",
    "\n",
    "            if is_list_of_dicts_with_empty_lists(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_with_empty_lists'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_with_empty_lists')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v} for el in tmp for v in el.values() if v != []]\n",
    "                # print('TMP: ', tmp)\n",
    "                if is_list_of_dicts_with_value_list(str(tmp).replace(\"'\", \"\\\"\")):\n",
    "                    if self.verbose: print('is_list_of_dicts_with_value_list')\n",
    "                    tmp = [{\"entity\":v} for el in tmp for v in el.values() if not isinstance(v, list)]\n",
    "                    tmp2 = [{\"entity\":v[0]} for el in tmp for v in el.values() if isinstance(v, list)]\n",
    "                    # print('returning this: ', {'model_output ':str(tmp2)}  )\n",
    "                    return {'model_output':str(tmp2)}\n",
    "                # print('returning this: ', {'model_output ':str(tmp)}  )\n",
    "\n",
    "                return {'model_output':str(tmp)}\n",
    "            \n",
    "            if self.verbose: print('QUI HO il QUARTO QUESTO:', model_output)\n",
    "\n",
    "            if is_list_of_dicts_with_value_list(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_with_value_list'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_with_value_list')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v} for el in tmp for v in el.values() if not isinstance(v, list)]\n",
    "                tmp2 = [{\"entity\":v[0]} for el in tmp for v in el.values() if isinstance(v, list)]\n",
    "                return {'model_output':str(tmp)}\n",
    "\n",
    "            if is_list_of_dict_numeric_values(model_output):\n",
    "                self.counter_dict['is_list_of_dict_numeric_values'] += 1\n",
    "                if self.verbose: print('is_list_of_dict_int_values')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [str({\"entity\":str(v)}) for el in tmp for v in el.values()]\n",
    "                model_output = str(tmp)\n",
    "            \n",
    "            if is_list_of_dicts_none_values(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_none_values'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_none_values')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [str({\"entity\":v}) for el in tmp for v in el.values() if v is not None]\n",
    "                model_output = str(tmp)\n",
    "                    \n",
    "            if is_list_of_empty_dict(model_output):\n",
    "                self.counter_dict['is_list_of_empty_dict'] += 1\n",
    "                if self.verbose: print('is_list_of_empty_dict')\n",
    "                return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "            \n",
    "            if is_list_with_one_empty_dict(model_output):\n",
    "                self.counter_dict['is_list_with_one_empty_dict'] += 1\n",
    "                if self.verbose: print('is_list_with_one_empty_dict')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [el for el in tmp if el != {}]\n",
    "                model_output = tmp\n",
    "                return {'model_output':str(model_output)}\n",
    "            \n",
    "            if is_list_of_dicts_of_lists(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_of_lists'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_of_lists')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v} for el in tmp for v in el.values() if not isinstance(v, list)]\n",
    "                # tmp.extend([{\"entity\":el.values()[0]} for el in tmp if isinstance(el.values(), list)])\n",
    "                # print('returning this: ', {'model_output ':str(tmp)}  )\n",
    "                return {'model_output':str(tmp)}  \n",
    "                \n",
    "            if self.verbose: print('CLEANED: ', model_output)\n",
    "            cleaning_done, cleaned_model_output = only_dicts_with_key_entity(model_output, wrong_keys_to_entity=wrong_keys_to_entity)\n",
    "            if cleaning_done:\n",
    "                model_output = cleaned_model_output\n",
    "            \n",
    "            if is_list_of_dicts(model_output):\n",
    "                self.counter_dict['is_list_of_dicts'] += 1\n",
    "                if self.verbose: print('PRE  CLEANED: ', model_output)\n",
    "                if is_list_of_dicts_with_multiple_keys_included_entity(model_output):\n",
    "                    self.counter_dict['is_list_of_dicts_with_multiple_keys_included_entity'] += 1\n",
    "                    if self.verbose: print('is_list_of_dicts_with_multiple_keys_included_entity')\n",
    "                    tmp = json.loads(model_output)\n",
    "                    out = []\n",
    "                    for item in tmp:\n",
    "                        if len(item) > 1 and 'entity' in item.keys():\n",
    "                            out.append({\"entity\":item.get('entity')})\n",
    "                    return {'model_output':str(out)}\n",
    "                tmp = json.loads(model_output)\n",
    "                return {'model_output':str(tmp)}\n",
    "            \n",
    "            else: \n",
    "                self.counter_dict['uknown'] += 1\n",
    "                # print('NOT CLEANED: ', model_output, '\\n\\n')\n",
    "                return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "            \n",
    "    def _exceptions_handler(self, model_output: str, error) -> str:\n",
    "        # if hasattr(error, 'msg'):\n",
    "        #     if error.msg.startswith('Expecting property name enclosed in double quotes'):\n",
    "        #         model_output = model_output.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\": \\'\", \": \\\"\")\n",
    "        \n",
    "        try:\n",
    "            json.loads(model_output)\n",
    "        except Exception as error:\n",
    "            if isinstance(error, json.decoder.JSONDecodeError):\n",
    "                #if error.msg == \"Expecting ',' delimiter\":\n",
    "                key_part, value_part = model_output.split(': ', 1)\n",
    "                first_occurrence = value_part.find('\"')\n",
    "                last_occurrence = value_part.rfind('\"')\n",
    "                model_output = key_part + ': \"' + value_part[first_occurrence+1:last_occurrence].replace(\"'\", r'\\'') + '\"' + '}'\n",
    "        return model_output\n",
    "    # .replace(\"\\'\", \" \")\n",
    "    \n",
    "    def _substitute_apexes(self, model_output: str) -> str:\n",
    "        model_output = model_output.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\": \\'\", \": \\\"\")\n",
    "        return model_output\n",
    "    \n",
    "    \n",
    "    def _extract_text_between_curl_brackets(self, model_output: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the text between the curl brackets of the model output, as enities are usually outputted in this format: {\"entity\": \"value\"}\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the example from the dataset\n",
    "\n",
    "        \"\"\"\n",
    "        text_between_curl_brackets = re.findall(r'\\{(.+?)\\}', model_output)\n",
    "        cleaned_output = ['{'+ el +'}' for el in text_between_curl_brackets]\n",
    "        cleaned_output = '[' + ', '.join(cleaned_output) + ']'\n",
    "        return cleaned_output\n",
    "    \n",
    "\n",
    "    def _clean_text_between_curl_brackets(self, text_between_curl_brackets: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean the text between the curl brackets of the model output, as entities are usually outputted in this format: {\"key\": \"value\"}\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the example from the dataset\n",
    "\n",
    "        \"\"\"\n",
    "        text_between_curl_brackets = re.sub(r'\",(.+?)}', r'\"}', text_between_curl_brackets)\n",
    "        text_between_curl_brackets = re.sub(r'{},', r'', text_between_curl_brackets)\n",
    "        text_between_curl_brackets = re.sub(r',{}', r'', text_between_curl_brackets)\n",
    "        # print('CLEANED: ', text_between_curl_brackets)\n",
    "        # text_between_curl_brackets = re.sub(r'\\{\"entity\":\\[\\]\\},', r'', text_between_curl_brackets)\n",
    "        # text_between_curl_brackets = re.sub(r',{\\'entity\\':[]}', r'', text_between_curl_brackets)\n",
    "        return text_between_curl_brackets\n",
    "    \n",
    "    def apply_cleaning(self, data, wrong_keys_to_entity) -> None:\n",
    "        \"\"\"\n",
    "        Apply the cleaning to the model output and return the cleaned response in a new cloumn called 'model_output\n",
    "\n",
    "        Args:\n",
    "        data (list): the dataset containing the model output\n",
    "        wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'. If not, all keys that are not 'entity' are dropped\n",
    "        \"\"\"\n",
    "        data = data.filter(lambda example: example[\"entities\"] is not None)\n",
    "        data = data.map(lambda x: self._clean_ground_truth(x), remove_columns=['ground_truth'])\n",
    "        data = data.map(lambda x: self._clean_model_output(x, wrong_keys_to_entity)) \n",
    "        self.data = data\n",
    "        return data\n",
    "    \n",
    "    def get_examples_based_on_metric(self, metric, upper_threshold=1, lower_threshold=0):\n",
    "        \"\"\"\n",
    "        Select the examples based on the metric and the threshold.\n",
    "        Args:\n",
    "        metric (str): the metric to consider\n",
    "        threshold (float): the threshold to consider\n",
    "        return:\n",
    "        list: the list of examples that satisfy the condition\n",
    "        \"\"\"\n",
    "        out = [example for example in self.data if example[metric] <= upper_threshold and example[metric] >= lower_threshold]\n",
    "        return(Dataset.from_pandas(pd.DataFrame(out)))\n",
    "\n",
    "    def create_allucinations_columns(self, data, verbose:bool=False):\n",
    "        light_allucinations, heavy_allucinations = [], []\n",
    "        for el in data:\n",
    "            light_invented_entities = []\n",
    "            heavy_invented_entities = []\n",
    "            for extracted_entity in el['model_output_parsed']['entities']:\n",
    "                if extracted_entity not in el['sentence']:\n",
    "                    if verbose: print(f\"'{extracted_entity}' not in sentence...\")\n",
    "                    if len(extracted_entity.split())==1:\n",
    "                        possible_entities = el['sentence'].split()\n",
    "                    else:\n",
    "                        n_words_in_entity= len(extracted_entity.split())\n",
    "                        possible_entities = [' '.join(el['sentence'].split()[i:i+n_words_in_entity]) for i in range(len(el['sentence'].split())-(n_words_in_entity-1))]\n",
    "                    if verbose: print(f'looking through {possible_entities}...')\n",
    "                    similarities = [fuzz.ratio(extracted_entity, possible_similar_entity) > 80\n",
    "                                    for possible_similar_entity in possible_entities]\n",
    "                    if any(similarities):\n",
    "                        if verbose: print('SIMILARITY FOUND', extracted_entity, '||||', el['sentence'].split()[similarities.index(True):similarities.index(True)+len(extracted_entity.split())])\n",
    "                        light_invented_entities.append({'extracted_entity':extracted_entity, 'original_entity':el['sentence'].split()[similarities.index(True)], 'original_sentence':el['sentence']})  \n",
    "                    else:\n",
    "                        heavy_invented_entities.append({'extracted_entity':extracted_entity, 'original_sentence':el['sentence']})\n",
    "                    if verbose: print('\\n')\n",
    "\n",
    "            light_allucinations.append(light_invented_entities)\n",
    "            heavy_allucinations.append(heavy_invented_entities)\n",
    "        data = data.add_column('light_allucinations', light_allucinations)\n",
    "        data = data.add_column('heavy_allucinations', heavy_allucinations)\n",
    "        return data\n",
    "\n",
    "    def remove_allucinations_from_computation(self, data_with_allucination_col):\n",
    "        \n",
    "        def helper(example):\n",
    "            if example['heavy_allucinations'] == []:\n",
    "                return example\n",
    "            else:\n",
    "                for el in example['heavy_allucinations']:\n",
    "                    print('REMOVING: ', el['extracted_entity'])\n",
    "                    example['model_output_parsed']['entities'].remove(el['extracted_entity'])\n",
    "                return example\n",
    "            \n",
    "        data_with_allucination_col = data_with_allucination_col.map(helper)\n",
    "        return data_with_allucination_col\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'entities', 'original_text', 'original_id', 'prompt', 'inference_prompt', 'ground_truth', 'model_responses', 'model_output'],\n",
      "    num_rows: 681\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "file =  data_path\n",
    "eval_data = Dataset.from_csv(file) \n",
    "\n",
    "output_cleaner = OutputCleaner(verbose=False)\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False) #.select(range(12,13))\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=cleaned_data)\n",
    "print(evaluator.data)\n",
    "evaluator.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'])\n",
    "tmp = evaluator.add_TP_FP_TN_FN_to_data()\n",
    "\n",
    "tmp = tmp.map(lambda x: {'model_output_parsed':evaluator._parse_json(x['model_output'])})\n",
    "tmp = tmp.map(lambda x: {'ground_truth_parsed':evaluator._parse_json(x['ground_truth'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vediamo quante volte succede che il modello inventa entità che non son onel testo originario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 166 invented entities over 4589 extracted entities -> 3.6%\n"
     ]
    }
   ],
   "source": [
    "output_analist = OutputAnalist(tmp)\n",
    "\n",
    "allucinations = []\n",
    "for el in output_analist.data:\n",
    "    invented_entities = []\n",
    "    for extracted_entity in el['model_output_parsed']['entities']:\n",
    "        if extracted_entity not in el['sentence']:\n",
    "            #print('EXTRACTED ENTITY NOT IN sentence: ', extracted_entity, '||||', el['sentence'])\n",
    "            invented_entities.append(extracted_entity)\n",
    "    allucinations.append(invented_entities)\n",
    "len1 = len([el for sublist in allucinations for el in sublist])\n",
    "len2 = len([el for sublist in output_analist.data['model_output_parsed'] for el in sublist['entities']])\n",
    "print(f\"There are {len1} invented entities over {len2} extracted entities -> {round(len1/len2*100,1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quante di queste allucinazioni sono però molto simili a qualcosa che c'è nel testo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 90 heavy allucinations over 166 allucinations -> 54.2%\n",
      "71 sentences are impacted by allucination out of 681 -> 13.2%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmp1 = output_analist.create_allucinations_columns(tmp, verbose = False)\n",
    "\n",
    "len1 = len([el for sublist in allucinations for el in sublist])\n",
    "len2 = len([el for sublist in tmp1['heavy_allucinations'] for el in sublist])\n",
    "print(f\"There are {len2} heavy allucinations over {len1} allucinations -> {round(len2/len1*100,1)}%\")\n",
    "print(f\"{len([sublist for sublist in tmp1['heavy_allucinations'] if len(sublist)>0])} sentences are impacted by allucination out of 681 -> {round(len2/681*100,1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### quando il modello è allucinato le performances peggiorano? Non solo quello è sbagliato, ma magari anche le altre fanno casino..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO allucinations -> f1:0.695427538103849 recall: 0.7049581005586593, precision 0.6861512319456244\n",
      "   allucinations -> f1:0.6286057692307692 recall: 0.6705128205128205, precision 0.5916289592760181\n"
     ]
    }
   ],
   "source": [
    "data_allucinated = tmp1.filter(lambda x: len(x['heavy_allucinations'])>0)\n",
    "evaluator_allucinations = Evaluator(data=data_allucinated, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_allucinations.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'])\n",
    "evaluator_NO_allucinations = Evaluator(data=tmp1.filter(lambda x: len(x['heavy_allucinations'])==0), offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_NO_allucinations.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'])\n",
    "print(f\"NO allucinations -> f1:{evaluator_NO_allucinations.evaluation_table['f1']} recall: {evaluator_NO_allucinations.evaluation_table['recall']}, precision {evaluator_NO_allucinations.evaluation_table['precision']}\")\n",
    "print(f\"   allucinations -> f1:{evaluator_allucinations.evaluation_table['f1']} recall: {evaluator_allucinations.evaluation_table['recall']}, precision {evaluator_allucinations.evaluation_table['precision']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cerchiamo di capire quale sia essere l'impatto delle allucinazioni, cioè cosa succede se le togliamo dal computo e laciamo il resto invariato. Per esempio, se le estratte sono 'Pietro' 'ferrazzi' e la frase originale è 'Pietro sta programmando', normalmente conteggio 'ferrazzi' come FP. Qui voglio vedere se escludendolo dal conteggio le performance sono comunque peggiori. In altre parole, voglio vedere se un'allucinazione ha l'effetto di modifcare anche quello che succede intorno ad essa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene fuori che il modello è stra meglio quando allucina. Forse si può spiegare dicendo che le allucinazioni avvengono solo quando il modello generalizza molto bene la sentence e quindi in realtà sono astrazioni corrette sulla frase. Tipo, la frase parla di sintomi del tumore senza citarlo, l'allucinazione consiste nel riposrtare timore come entità. Da verificare..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo è il confronto tra avere alluccinazioni e dopo averle tolte considerando soltanto le frasi per cui sono state generate allucinazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allucinations removed -> f1:0.695427538103849 recall: 0.7049581005586593, precision 0.6861512319456244\n",
      "allucinations        -> f1:0.8883115383505097 recall: 0.9923250564334086, precision 0.8040342809364549\n"
     ]
    }
   ],
   "source": [
    "output_analist = OutputAnalist(tmp)\n",
    "data_allucinated_removed = output_analist.remove_allucinations_from_computation(data_allucinated)\n",
    "\n",
    "evaluator_marginal_allucinations = Evaluator(data_allucinated_removed, offset=False, output_cleaner=None)\n",
    "evaluator_marginal_allucinations.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'],\n",
    "                                    already_parsed_inputs=True)\n",
    "print(f\"allucinations removed -> f1:{evaluator_NO_allucinations.evaluation_table['f1']} recall: {evaluator_NO_allucinations.evaluation_table['recall']}, precision {evaluator_NO_allucinations.evaluation_table['precision']}\")\n",
    "\n",
    "evaluator_marginal_allucinations = Evaluator(data_allucinated, offset=False, output_cleaner=None)\n",
    "evaluator_marginal_allucinations.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'],\n",
    "                                    already_parsed_inputs=True)\n",
    "print(f\"allucinations        -> f1:{evaluator_marginal_allucinations.evaluation_table['f1']} recall: {evaluator_marginal_allucinations.evaluation_table['recall']}, precision {evaluator_marginal_allucinations.evaluation_table['precision']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un allucinazione è un FP. \n",
    "H0: p( TN | allucinazione ) < p( TN | ! allucinazione)  [cioè, il fatto che ci siano delle allucinazioni è correlato alla miglior comprensione del contesto da parte del modello, che 'esagera' a generare positivi, ma non sbaglia più i negativi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward.',\n",
       " 'entities': \"[{'id': '7194', 'offsets': array([84, 92]), 'role': '', 'semantic_type_id': '', 'text': 'deviated', 'type': 'EVENT'}\\n {'id': '7916', 'offsets': array([ 0, 44]), 'role': '', 'semantic_type_id': '', 'text': 'The right and left vascular axes of the neck', 'type': 'BODYPART'}\\n {'id': '7922', 'offsets': array([46, 77]), 'role': '', 'semantic_type_id': '', 'text': 'carotid artery and jugular vein', 'type': 'BODYPART'}]\",\n",
       " 'original_text': 'A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago. In the family history, her mother, sisters and cousins underwent a surgery for MNG. Despite of the large volume of the mass, the patient never described signs of cervical compression whatsoever respiratory, digestive, laryngeal, vascular or neurologic signs. She never suffered from thyroid dysfunction. Her neck was deformed by the voluminous formation classified grade III according to the WHO modified classification. The mass took the front and the two sides of the neck. Its surface was embossed and covered by a thin normal skin. There were some veins of the collateral circulation limited to the neck. The goiter measured 18 x 11 cm. The mass was firm, painless, and mobile with the swallowing movements. Lymphadenopathy research was difficult and found no palpable lymph nodes. The laboratory tests (T 3, T 4 and TSH) were normal. Thoracic radiography showed a large cervical opacity roughly round and strewn with microcalcifications associated with a right eccentricity of the trachea. Cervical and chest CT revealed the presence of a partially calcified thyroid mass slightly plunging in the anterior mediastinum. It took heterogeneously the contrast and then evocate a large MNG. The trachea was surrounded by the goiter, slightly narrowed and right deviated as well as the lower part of the larynx. The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward. The patient underwent a surgery for her enormous MNG slightly plunging in the mediastinum. Endotracheal intubation was relatively easy by the laryngoscope. The incision performed was a Kocher cervicotomy. There was a multinodular, hypervascularized goiter. Its lower end plunges behind the sternal manubrium. The larynx was deviated towards the right side. The total thyroidectomy was performed in two steps: initially a right lobo-isthmectomy, then the left lobectomy. The retrosternal part of the goiter was released using the finger by the same incision. Both recurrent laryngeal nerves (RLN) were not identified because of the hemorrhage. One parathyroid gland was accidently devascularized and was autotransplanted to the ipsilateral sternocleidomastoid muscle. The operation was finished by double aspiration drainage. In the first hours after surgery, the patient developed a large cervical hematoma. She was readmitted to the operating room, and after evacuation of the hematoma there was no vessels bleeding. The operation was completed with a double suction drainage. In the immediate postoperative period, the patient developed hemodynamic collapse requiring the introduction of dobutamine. After 48 hours of hemodynamic support, the blood pressure stabilized and dobutamine was stopped. Histological study concluded in multinodular colloid goiter. The patient was discharged from the hospital after 20 days in good health.\\r\\n',\n",
       " 'original_id': 'EN100067',\n",
       " 'prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward.>>> [/INST][{\"entity\": \"deviated\"}, {\"entity\": \"The right and left vascular axes of the neck\"}, {\"entity\": \"carotid artery and jugular vein\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward.>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"deviated\"}, {\"entity\": \"The right and left vascular axes of the neck\"}, {\"entity\": \"carotid artery and jugular vein\"}] ',\n",
       " 'model_responses': ' [{\"entity\": \"devoted\"}, {\"entity\": \"The right and left vascular axes of the neck\"}]  [{\"entity\": \"carotid artery\"}, {\"entity\": \"jugular vein\"}]</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " 'model_output': \"[{'entity': 'devoted'}, {'entity': 'The right and left vascular axes of the neck'}, {'entity': 'carotid artery'}, {'entity': 'jugular vein'}]\",\n",
       " 'TP': 13,\n",
       " 'FP': 1,\n",
       " 'FN': 7,\n",
       " 'precision': 0.9285714285714286,\n",
       " 'recall': 0.65,\n",
       " 'f1': 0.7647058823529412,\n",
       " 'model_output_parsed': {'entities': ['The right and left vascular axes of the neck',\n",
       "   'carotid artery',\n",
       "   'jugular vein']},\n",
       " 'ground_truth_parsed': {'entities': ['deviated',\n",
       "   'The right and left vascular axes of the neck',\n",
       "   'carotid artery and jugular vein']},\n",
       " 'light_allucinations': [],\n",
       " 'heavy_allucinations': [{'extracted_entity': 'devoted',\n",
       "   'original_sentence': 'The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward.'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_allucinated_removed[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (629478500.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[30], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    IL CODICE PER I TP; FP; FN è sbagliato\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "IL CODICE PER I TP; FP; FN è sbagliato"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
