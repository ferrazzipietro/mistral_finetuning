{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is the best model for Llama 7B"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from utils.evaluator import Evaluator\n",
    "data_path = \"data/llama/7B_NoQuant_FT/maxNewTokensFactor8_nShotsInference0_llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002.csv\"\n",
    "apadpetrs_checkpoint = \"ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002\""
=======
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "data_path = \"'data/llama/7B_NoQuant_FT_cl_v2prompt/maxNewTokensFactor4_nShotsInference0_llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002_clent.csv'\" #\"data/llama/7B_NoQuant_FT/maxNewTokensFactor8_nShotsInference0_llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002.csv\"\n",
    "apadpetrs_checkpoint = \"ferrazzipietro/Llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002_clent\" # \"ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002\""
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 5,
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from transformers import AutoTokenizer\n",
    "import string\n",
    "\n",
    "class OutputAnalist():\n",
    "    def __init__(self, data, verbose=False) -> None:\n",
    "        self.verbose = verbose\n",
    "        self.data = data\n",
    "        self.counter_dict = {\n",
    "            'perfect_output':0,\n",
    "            'is_empty_list':0,\n",
    "            'is_list_of_lists':0,\n",
    "            'is_list_of_dicts':0,\n",
    "            'is_list_of_lists_and_dict':0,\n",
    "            'is_list_of_strings':0,\n",
    "            'is_list_of_empty_dict':0,\n",
    "            'is_list_with_one_empty_dict':0,\n",
    "            'is_list_of_dicts_with_empty_lists':0,\n",
    "            'is_list_of_dicts_with_one_key_multiple_values':0,\n",
    "            'is_list_of_dicts_with_multiple_keys_included_entity':0,\n",
    "            'is_list_of_dict_numeric_values':0,\n",
    "            'is_list_of_dicts_none_values':0,\n",
    "            'is_list_of_dicts_and_strings':0,\n",
    "            'is_list_of_dicts_and_lists_of_strings':0,\n",
    "            'is_list_of_dicts_with_value_list':0,\n",
    "            'is_string':0,\n",
    "            'is_list_of_strings_representing_dicts':0,\n",
    "            'is_list_of_dicts_of_lists':0,\n",
    "            'is_numeric':0,\n",
    "            'are_entities_extracted_as_dict_keys_instead_of_values':0,\n",
    "            'uknown':0\n",
    "        }\n",
    "  \n",
    "    def _remove_space_from_dict_keys(self, model_ouput_list: list) -> list:\n",
    "        \"\"\"\n",
    "        Remove the spaces from the keys of a dictionary. E.g., [{\"entity \": \"value\"}] -> [{\"entity\": \"value\"}]\n",
    "\n",
    "        Args:\n",
    "        model_ouput_list (dict): the list of dictionaries to be cleaned\n",
    "\n",
    "        return:\n",
    "        list: the cleaned list of dicts\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for dict in model_ouput_list:\n",
    "            # print('DICT: ', dict)\n",
    "            out.append({k.replace(' ', ''): v for k, v in dict.items()})\n",
    "        return out\n",
    "    \n",
    "    def _drop_duplicates(self, model_response: list) -> str:\n",
    "        \"\"\"\n",
    "        Drop the duplicates from a list. This is useful when the model output contains the same entity multiple times.\n",
    "\n",
    "        Args:\n",
    "        model_response (str): the model response with no duplicates\n",
    "        \"\"\"\n",
    "        # print('DROPPING DUPLICATES: ', model_response)\n",
    "        try :\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        except Exception as error:\n",
    "            model_response = self._remove_space_from_dict_keys(model_response)\n",
    "            # print('ERROR: ', model_response)\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        \n",
    "    def _assess_model_output(self, model_response: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the model output is in the right format. If not, return False.\n",
    "        \n",
    "        Args:\n",
    "        model_output (str): the postprocessed model output after beeing passed to _postprocess_model_output()\n",
    "\n",
    "        return:\n",
    "        bool: True if the format is correct, False otherwise\n",
    "        \"\"\"\n",
    "        good_format = True\n",
    "        try :\n",
    "            res = json.loads(model_response)\n",
    "            # print( res)\n",
    "        except:\n",
    "            good_format = False\n",
    "        return good_format\n",
    "\n",
    "            \n",
    "    def _remove_json_special_chars(self, string):\n",
    "        \"\"\"\n",
    "        Remove the special characters from a string. This is useful when the model output contains special characters that are not allowed in the json format.\n",
    "        \"\"\"\n",
    "        # print('sto pulendo: ', string)\n",
    "        chars = ['\\xa0', '\\x80', '\\x93', '\\U00100000', '\\r\\n', '\\U00100000I', '\\\\u001d', '\\\\\"']\n",
    "        for char in chars:\n",
    "            string = string.replace(char, ' ')\n",
    "        char_no_space = ['\\xad']\n",
    "        for char in char_no_space:\n",
    "            string = string.replace(char, '')\n",
    "        string = string.replace('\\\\u0010', '^')\n",
    "        return string\n",
    "    \n",
    "    \n",
    "    def _clean_ground_truth(self, example: dict) -> dict:\n",
    "        ground_truth = example['ground_truth']\n",
    "        # print('inner ground truth: ', ground_truth)\n",
    "        ground_truth = self._remove_json_special_chars(ground_truth)\n",
    "        ground_truth = ground_truth.replace('</s>', '').replace('<|im_e', '').replace('<|end_of_text|>', '').replace('<|endoftext|>', '')\n",
    "        return({'ground_truth': ground_truth})\n",
    "\n",
    "    def _clean_model_output(self, example: dict,  wrong_keys_to_entity:bool, latest_version:bool=True) -> dict:\n",
    "        \"\"\"\n",
    "        Postprocess the model output to return a json like formatted string that can be used to compute the F1 score.\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the model output as it is returned by the model. The processing of the output is done in the function\n",
    "        wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'. If not, all keys that are not 'entity' are dropped\n",
    "\n",
    "        return:\n",
    "        dict: the model response\n",
    "\n",
    "        \"\"\"\n",
    "       \n",
    "        def is_empty_list(string:str)  -> bool:\n",
    "            if string=='[]':\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_lists(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, list) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_lists_and_dict(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                found_dict = False\n",
    "                found_list = False\n",
    "                for element in tmp:\n",
    "                    if isinstance(element, list):\n",
    "                        found_list = True\n",
    "                    elif isinstance(element, dict):\n",
    "                        found_dict = True\n",
    "                    if found_list and found_dict:\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, str) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_empty_dict(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                #print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    if all(str(item) == \"{}\" for item in tmp):\n",
    "                        return True\n",
    "            return False\n",
    "\n",
    "        def is_list_with_one_empty_dict(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list):\n",
    "                    for item in tmp:\n",
    "                        if item == {}:\n",
    "                            return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_with_empty_lists(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        for v in item.values():\n",
    "                            if v == []:\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_with_one_key_multiple_values(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item) == 1 and len(item.values()) > 1:\n",
    "                            return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_dicts_with_multiple_keys_included_entity(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item) > 1 and 'entity' in item.keys():\n",
    "                            return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_dict_numeric_values(string:str)  -> bool:\n",
    "            #print('STRING: ', string)\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                #print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item.values()) > 0:\n",
    "                            val = list(item.values())[0] \n",
    "                            if isinstance(val, int) or isinstance(val, float):\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_none_values(string:str) -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        if len(item.values()) > 0:\n",
    "                            val = list(item.values())[0] \n",
    "                            if val is None:\n",
    "                                return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_dicts_and_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                #print('ASSESSED')\n",
    "                tmp = json.loads(string)\n",
    "                found_dict = False\n",
    "                found_string = False\n",
    "                for element in tmp:\n",
    "                    if isinstance(element, str):\n",
    "                        found_string = True\n",
    "                    elif isinstance(element, dict):\n",
    "                        found_dict = True\n",
    "                    if found_string and found_dict:\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_and_lists_of_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                # print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list):\n",
    "                    if all(isinstance(item, dict) for item in tmp):\n",
    "                        return False\n",
    "                    for item in tmp:\n",
    "                        # print('ITEM: ', item)\n",
    "                        if isinstance(item, dict):\n",
    "                            \n",
    "                            if len(item.values()) == 0:\n",
    "                               return False\n",
    "                            if item.get('entity') is None:\n",
    "                                return False\n",
    "                        elif isinstance(item, list):\n",
    "                            if len(item) != 1:\n",
    "                                return False\n",
    "                            if not isinstance(item[0], str):\n",
    "                                return False\n",
    "                        else:\n",
    "                            return False\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_with_value_list(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        for v in item.values():\n",
    "                            if isinstance(v, list):\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_string(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, str):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_strings_representing_dicts(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                # print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, str) for item in tmp):\n",
    "                    tmp_list = []\n",
    "                    for item in tmp:\n",
    "                        # print('ITEM: ', item)\n",
    "                        if self._assess_model_output(item):\n",
    "                          tmp_list.append(json.loads(item))\n",
    "                    if all(isinstance(item, dict) for item in tmp_list):\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts_of_lists(string:str)  -> bool:\n",
    "            # print('STRING: ', string)\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                # print('TMP: ', tmp)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    for item in tmp:\n",
    "                        # print('item: ',item)\n",
    "                        tmp2 = list(item.values())[0]\n",
    "                        if len(tmp2) > 0:\n",
    "                            if isinstance(list(item.values())[0], list):\n",
    "                                return True\n",
    "            return False\n",
    "        \n",
    "        def is_numeric(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, (int, float)):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def are_entities_extracted_as_dict_keys_instead_of_values(string:str, example:dict) -> bool:\n",
    "            if is_list_of_dicts(string):\n",
    "                tmp = json.loads(string)\n",
    "                keys = [key for item in tmp for key in item.keys()]\n",
    "                if 'entity' not in keys:\n",
    "                    if all(entity in example['sentence'] for entity in keys):\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        \n",
    "        def convert_wrong_keys_into_entity(string:str) -> List[str]:\n",
    "            if is_list_of_dicts(string):\n",
    "                tmp = json.loads(string)\n",
    "                tmp = [str({\"entity\":v}) for el in tmp for v in el.values()]\n",
    "                return tmp\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "\n",
    "        def only_dicts_with_key_entity(string:str, wrong_keys_to_entity:bool) -> Tuple[bool, str]:\n",
    "            \"\"\"\n",
    "            Extract only the dictionaries with the key 'entity' in the list of dictionaries in the string\n",
    "            \n",
    "            Args:\n",
    "            string (str): the string to be cleaned\n",
    "            wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'\n",
    "            \"\"\"\n",
    "            els_between_curly = re.findall(r'\\{(.+?)\\}', string)\n",
    "            clean = [el for el in els_between_curly if el.startswith('\"entity\"') or el.startswith(\"'entity'\")]\n",
    "            clean = ['{' + el + '}' for el in clean]\n",
    "            dirty = []\n",
    "            if wrong_keys_to_entity:\n",
    "                dirty = [el for el in els_between_curly if (not el.startswith('\"entity\"')) and (not el.startswith(\"'entity'\"))]\n",
    "                dirty = ['{' + el + '}' for el in dirty]\n",
    "                dirty = '[' + ', '.join(dirty) + ']'\n",
    "                cleaned_dirty = convert_wrong_keys_into_entity(dirty)\n",
    "                out = '[' + ', '.join(clean) + ', '.join(cleaned_dirty) +  ']'\n",
    "            else:\n",
    "                out = '[' + ', '.join(clean) + ']'\n",
    "            # out = out.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\" \\'\", \" \\\"\")\n",
    "            operations_performed = False\n",
    "            if len(clean) != len(els_between_curly):\n",
    "                operations_performed = True\n",
    "            if is_empty_list(out):\n",
    "                return operations_performed, '[{\"entity\":\"\"}]'\n",
    "            return operations_performed, str(out)\n",
    "        \n",
    "        if self.verbose: print('EXAMPLE:  ', example['model_responses'])\n",
    "        model_output = example['model_responses']\n",
    "        if self.verbose: print('ORIGINAL MODEL OUTPUT:', model_output)\n",
    "        # print('ORIGINAL MODEL OUTPUT:', model_output)\n",
    "        if self.verbose: print('GROUND TRUTH: ', example['ground_truth'])\n",
    "        # model_output = self._exceptions_handler(model_output)\n",
    "\n",
    "        if is_list_of_dicts(model_output):\n",
    "            self.counter_dict['perfect_output'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts')\n",
    "            tmp = json.loads(model_output)\n",
    "            return {'model_output':str(tmp)}\n",
    "    \n",
    "        if model_output is None or is_empty_list(model_output):\n",
    "            return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "        # model_output = self._special_cases_handler(model_output)\n",
    "        model_output = self._remove_json_special_chars(model_output)\n",
    "        if self.verbose:print('PULITO: ', model_output)\n",
    "\n",
    "                \n",
    "        if are_entities_extracted_as_dict_keys_instead_of_values(model_output, example):\n",
    "            self.counter_dict['are_entities_extracted_as_dict_keys_instead_of_values'] += 1\n",
    "            if self.verbose: print('ENTITIES EXTRACTED AS DICT KEYS INSTEAD OF VALUES')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":k} for el in tmp for k in el.keys() ]\n",
    "            tmp = str(tmp)\n",
    "            return {'model_output':tmp}\n",
    "        \n",
    "        if is_list_of_dicts_and_lists_of_strings(model_output):\n",
    "            self.counter_dict['is_list_of_dicts_and_lists_of_strings'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts_and_lists_of_strings')\n",
    "            tmp = json.loads(model_output)\n",
    "            out = []\n",
    "            for item in tmp:\n",
    "                if self.verbose: print('ITEM: ', item)\n",
    "                if isinstance(item, dict):\n",
    "                    out.append(item)\n",
    "                elif isinstance(item, list):\n",
    "                    out.append({\"entity\":item[0]})\n",
    "            return {'model_output':str(out)}\n",
    "\n",
    "        if is_numeric(model_output):\n",
    "            self.counter_dict['is_numeric'] += 1\n",
    "            # print('IS NUMERIC')\n",
    "            return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "\n",
    "        # print('QUI HO QUESTO: ', model_output)\n",
    "        if is_list_of_strings_representing_dicts(model_output):\n",
    "            self.counter_dict['is_list_of_strings_representing_dicts'] += 1\n",
    "            if self.verbose: print('is_list_of_strings_representing_dicts 1')                \n",
    "            tmp = json.loads(model_output)\n",
    "            tmp_list = []\n",
    "            for item in tmp:\n",
    "                if self._assess_model_output(item):\n",
    "                  tmp_list.append(json.loads(item))\n",
    "            if self.verbose: print('TEMPOOOO 2 ',tmp)\n",
    "            return {'model_output':str(tmp_list)}\n",
    "        \n",
    "        if is_list_of_dicts_with_one_key_multiple_values(model_output):\n",
    "            self.counter_dict['is_list_of_dicts_with_one_key_multiple_values'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts_with_one_key_multiple_values')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":v[0]} for el in tmp for v in el.values()]\n",
    "            return {'model_output':str(tmp)}\n",
    "       \n",
    "        if is_list_of_dicts_with_multiple_keys_included_entity(model_output):\n",
    "            self.counter_dict['is_list_of_dicts_with_multiple_keys_included_entity'] += 1\n",
    "            if self.verbose: print('is_list_of_dicts_with_multiple_keys_included_entity')\n",
    "            tmp = json.loads(model_output)\n",
    "            out = []\n",
    "            for item in tmp:\n",
    "                if item.get('entity') is not None:\n",
    "                    out.append({\"entity\":item.get('entity')})\n",
    "            return {'model_output':str(out)}\n",
    "        \n",
    "        \n",
    "        if is_list_of_lists_and_dict(model_output):\n",
    "            self.counter_dict['is_list_of_lists_and_dict'] += 1\n",
    "            if self.verbose: print('is_list_of_lists_and_dict')\n",
    "            tmp = json.loads(model_output)\n",
    "            for el in tmp:\n",
    "                if isinstance(el, list):\n",
    "                    tmp = str(el)\n",
    "                    # print('is_list_of_lists_and_dict')\n",
    "                    return {'model_output':tmp}\n",
    "                \n",
    "        if is_list_of_lists(model_output):\n",
    "            self.counter_dict['is_list_of_lists'] += 1\n",
    "            if self.verbose: print('is_list_of_lists')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp2 = str(tmp[0]).replace(\"'\", \"\\\"\")\n",
    "            if is_list_of_dicts_and_strings(tmp2):\n",
    "                tmp = tmp[0]\n",
    "                out = [item for item in tmp if isinstance(item, dict)]\n",
    "                return {'model_output':str(out)} \n",
    "            tmp = str(tmp[0])\n",
    "            return {'model_output':tmp}\n",
    "        \n",
    "\n",
    "        if is_list_of_strings(model_output):\n",
    "            self.counter_dict['is_list_of_strings'] += 1\n",
    "            if self.verbose: print('is_list_of_strings')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":el} for el in tmp]\n",
    "            tmp = str(tmp)\n",
    "            # print('is_list_of_strings')\n",
    "            if self.verbose: print('TEMPOOOO ',tmp)\n",
    "            return {'model_output': tmp}\n",
    "        \n",
    "        if is_string(model_output):\n",
    "            self.counter_dict['is_string'] += 1\n",
    "            # model_output = model_output.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\" \\'\", \" \\\"\")\n",
    "            if self.verbose: print('PULO: ', model_output)\n",
    "            tmp = json.loads(model_output)\n",
    "            if all(el in tmp for el in ['{', 'entity', '}']):\n",
    "                return {'model_output':tmp}\n",
    "            tmp = [{\"entity\":tmp}]\n",
    "            tmp = str(tmp)\n",
    "            #print('is_string')\n",
    "            return {'model_output':tmp}\n",
    "\n",
    "        \n",
    "        if latest_version:\n",
    "            model_output = self._extract_text_between_curl_brackets(model_output)\n",
    "            model_output = self._clean_text_between_curl_brackets(model_output)\n",
    "\n",
    "            # print('QUI HO il SECONDO QUESTO: ', model_output)\n",
    "\n",
    "            if is_list_of_strings_representing_dicts(model_output):\n",
    "                self.counter_dict['is_list_of_strings_representing_dicts'] += 1\n",
    "                if self.verbose: print('is_list_of_strings_representing_dicts 2')                \n",
    "                tmp = json.loads(model_output)\n",
    "                tmp_list = []\n",
    "                for item in tmp:\n",
    "                    if self._assess_model_output(item):\n",
    "                        tmp_list.append(json.loads(item))\n",
    "                return {'model_output':str(tmp_list)}\n",
    "            \n",
    "            if is_list_of_dicts_with_one_key_multiple_values(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_with_one_key_multiple_values'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_with_one_key_multiple_values')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v[0]} for el in tmp for v in el.values()]\n",
    "                return {'model_output':str(tmp)}\n",
    "            \n",
    "            if is_list_of_dicts_and_lists_of_strings(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_and_lists_of_strings'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_and_lists_of_strings')\n",
    "                tmp = json.loads(model_output)\n",
    "                out = []\n",
    "                for item in tmp:\n",
    "                    # print('ITEM: ', item)\n",
    "                    if isinstance(item, dict):\n",
    "                        out.append(item)\n",
    "                    elif isinstance(item, list):\n",
    "                        out.append({\"entity\":item[0]})\n",
    "                return {'model_output':str(out)}\n",
    "            \n",
    "            if self.verbose: print('QUI HO il TEERZO QUESTO: ', model_output)\n",
    "\n",
    "            if is_list_of_dicts_with_empty_lists(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_with_empty_lists'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_with_empty_lists')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v} for el in tmp for v in el.values() if v != []]\n",
    "                # print('TMP: ', tmp)\n",
    "                if is_list_of_dicts_with_value_list(str(tmp).replace(\"'\", \"\\\"\")):\n",
    "                    if self.verbose: print('is_list_of_dicts_with_value_list')\n",
    "                    tmp = [{\"entity\":v} for el in tmp for v in el.values() if not isinstance(v, list)]\n",
    "                    tmp2 = [{\"entity\":v[0]} for el in tmp for v in el.values() if isinstance(v, list)]\n",
    "                    # print('returning this: ', {'model_output ':str(tmp2)}  )\n",
    "                    return {'model_output':str(tmp2)}\n",
    "                # print('returning this: ', {'model_output ':str(tmp)}  )\n",
    "\n",
    "                return {'model_output':str(tmp)}\n",
    "            \n",
    "            if self.verbose: print('QUI HO il QUARTO QUESTO:', model_output)\n",
    "\n",
    "            if is_list_of_dicts_with_value_list(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_with_value_list'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_with_value_list')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v} for el in tmp for v in el.values() if not isinstance(v, list)]\n",
    "                tmp2 = [{\"entity\":v[0]} for el in tmp for v in el.values() if isinstance(v, list)]\n",
    "                return {'model_output':str(tmp)}\n",
    "\n",
    "            if is_list_of_dict_numeric_values(model_output):\n",
    "                self.counter_dict['is_list_of_dict_numeric_values'] += 1\n",
    "                if self.verbose: print('is_list_of_dict_int_values')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [str({\"entity\":str(v)}) for el in tmp for v in el.values()]\n",
    "                model_output = str(tmp)\n",
    "            \n",
    "            if is_list_of_dicts_none_values(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_none_values'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_none_values')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [str({\"entity\":v}) for el in tmp for v in el.values() if v is not None]\n",
    "                model_output = str(tmp)\n",
    "                    \n",
    "            if is_list_of_empty_dict(model_output):\n",
    "                self.counter_dict['is_list_of_empty_dict'] += 1\n",
    "                if self.verbose: print('is_list_of_empty_dict')\n",
    "                return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "            \n",
    "            if is_list_with_one_empty_dict(model_output):\n",
    "                self.counter_dict['is_list_with_one_empty_dict'] += 1\n",
    "                if self.verbose: print('is_list_with_one_empty_dict')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [el for el in tmp if el != {}]\n",
    "                model_output = tmp\n",
    "                return {'model_output':str(model_output)}\n",
    "            \n",
    "            if is_list_of_dicts_of_lists(model_output):\n",
    "                self.counter_dict['is_list_of_dicts_of_lists'] += 1\n",
    "                if self.verbose: print('is_list_of_dicts_of_lists')\n",
    "                tmp = json.loads(model_output)\n",
    "                tmp = [{\"entity\":v} for el in tmp for v in el.values() if not isinstance(v, list)]\n",
    "                # tmp.extend([{\"entity\":el.values()[0]} for el in tmp if isinstance(el.values(), list)])\n",
    "                # print('returning this: ', {'model_output ':str(tmp)}  )\n",
    "                return {'model_output':str(tmp)}  \n",
    "                \n",
    "            if self.verbose: print('CLEANED: ', model_output)\n",
    "            cleaning_done, cleaned_model_output = only_dicts_with_key_entity(model_output, wrong_keys_to_entity=wrong_keys_to_entity)\n",
    "            if cleaning_done:\n",
    "                model_output = cleaned_model_output\n",
    "            \n",
    "            if is_list_of_dicts(model_output):\n",
    "                self.counter_dict['is_list_of_dicts'] += 1\n",
    "                if self.verbose: print('PRE  CLEANED: ', model_output)\n",
    "                if is_list_of_dicts_with_multiple_keys_included_entity(model_output):\n",
    "                    self.counter_dict['is_list_of_dicts_with_multiple_keys_included_entity'] += 1\n",
    "                    if self.verbose: print('is_list_of_dicts_with_multiple_keys_included_entity')\n",
    "                    tmp = json.loads(model_output)\n",
    "                    out = []\n",
    "                    for item in tmp:\n",
    "                        if len(item) > 1 and 'entity' in item.keys():\n",
    "                            out.append({\"entity\":item.get('entity')})\n",
    "                    return {'model_output':str(out)}\n",
    "                tmp = json.loads(model_output)\n",
    "                return {'model_output':str(tmp)}\n",
    "            \n",
    "            else: \n",
    "                self.counter_dict['uknown'] += 1\n",
    "                # print('NOT CLEANED: ', model_output, '\\n\\n')\n",
    "                return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "            \n",
    "    def _exceptions_handler(self, model_output: str, error) -> str:\n",
    "        # if hasattr(error, 'msg'):\n",
    "        #     if error.msg.startswith('Expecting property name enclosed in double quotes'):\n",
    "        #         model_output = model_output.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\": \\'\", \": \\\"\")\n",
    "        \n",
    "        try:\n",
    "            json.loads(model_output)\n",
    "        except Exception as error:\n",
    "            if isinstance(error, json.decoder.JSONDecodeError):\n",
    "                #if error.msg == \"Expecting ',' delimiter\":\n",
    "                key_part, value_part = model_output.split(': ', 1)\n",
    "                first_occurrence = value_part.find('\"')\n",
    "                last_occurrence = value_part.rfind('\"')\n",
    "                model_output = key_part + ': \"' + value_part[first_occurrence+1:last_occurrence].replace(\"'\", r'\\'') + '\"' + '}'\n",
    "        return model_output\n",
    "    # .replace(\"\\'\", \" \")\n",
    "    \n",
    "    def _substitute_apexes(self, model_output: str) -> str:\n",
    "        model_output = model_output.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\": \\'\", \": \\\"\")\n",
    "        return model_output\n",
    "    \n",
    "    \n",
    "    def _extract_text_between_curl_brackets(self, model_output: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the text between the curl brackets of the model output, as enities are usually outputted in this format: {\"entity\": \"value\"}\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the example from the dataset\n",
    "\n",
    "        \"\"\"\n",
    "        text_between_curl_brackets = re.findall(r'\\{(.+?)\\}', model_output)\n",
    "        cleaned_output = ['{'+ el +'}' for el in text_between_curl_brackets]\n",
    "        cleaned_output = '[' + ', '.join(cleaned_output) + ']'\n",
    "        return cleaned_output\n",
    "    \n",
    "\n",
    "    def _clean_text_between_curl_brackets(self, text_between_curl_brackets: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean the text between the curl brackets of the model output, as entities are usually outputted in this format: {\"key\": \"value\"}\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the example from the dataset\n",
    "\n",
    "        \"\"\"\n",
    "        text_between_curl_brackets = re.sub(r'\",(.+?)}', r'\"}', text_between_curl_brackets)\n",
    "        text_between_curl_brackets = re.sub(r'{},', r'', text_between_curl_brackets)\n",
    "        text_between_curl_brackets = re.sub(r',{}', r'', text_between_curl_brackets)\n",
    "        # print('CLEANED: ', text_between_curl_brackets)\n",
    "        # text_between_curl_brackets = re.sub(r'\\{\"entity\":\\[\\]\\},', r'', text_between_curl_brackets)\n",
    "        # text_between_curl_brackets = re.sub(r',{\\'entity\\':[]}', r'', text_between_curl_brackets)\n",
    "        return text_between_curl_brackets\n",
    "    \n",
    "    def apply_cleaning(self, data, wrong_keys_to_entity) -> None:\n",
    "        \"\"\"\n",
    "        Apply the cleaning to the model output and return the cleaned response in a new cloumn called 'model_output\n",
    "\n",
    "        Args:\n",
    "        data (list): the dataset containing the model output\n",
    "        wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'. If not, all keys that are not 'entity' are dropped\n",
    "        \"\"\"\n",
    "        data = data.filter(lambda example: example[\"entities\"] is not None)\n",
    "        data = data.map(lambda x: self._clean_ground_truth(x), remove_columns=['ground_truth'])\n",
    "        data = data.map(lambda x: self._clean_model_output(x, wrong_keys_to_entity)) \n",
    "        self.data = data\n",
    "        return data\n",
    "    \n",
    "    def get_examples_based_on_metric(self, metric, upper_threshold=1, lower_threshold=0):\n",
    "        \"\"\"\n",
    "        Select the examples based on the metric and the threshold.\n",
    "        Args:\n",
    "        metric (str): the metric to consider\n",
    "        threshold (float): the threshold to consider\n",
    "        return:\n",
    "        list: the list of examples that satisfy the condition\n",
    "        \"\"\"\n",
    "        out = [example for example in self.data if example[metric] <= upper_threshold and example[metric] >= lower_threshold]\n",
    "        return(Dataset.from_pandas(pd.DataFrame(out)))\n",
    "\n",
    "    def create_allucinations_columns(self, data, verbose:bool=False):\n",
    "        \"\"\"\n",
    "        Create two columns that contain the invented entities/hallucinations, which are spans of text that have been extracted but are not in the sentence.\n",
    "        The first column ('light_allucinations') contains the invented entities that are similar to at least one entity in the sentence, while the second column ('heavy_allucinations') contains the invented entities that are not similar to the entities in the sentence.\n",
    "       \n",
    "        Args:\n",
    "        data (list): the dataset containing the model output\n",
    "        verbose (bool): default False. If True, print verbose\n",
    "        \"\"\"\n",
    "        light_allucinations, heavy_allucinations = [], []\n",
    "        for el in data:\n",
    "            light_invented_entities = []\n",
    "            heavy_invented_entities = []\n",
    "            for extracted_entity in el['model_output_parsed']['entities']:\n",
    "                if extracted_entity.lower() not in el['sentence'].lower():\n",
    "                    if verbose: print(f\"'{extracted_entity}' not in sentence...\")\n",
    "                    if len(extracted_entity.split())==1:\n",
    "                        possible_entities = el['sentence'].split()\n",
    "                    else:\n",
    "                        n_words_in_entity= len(extracted_entity.split())\n",
    "                        possible_entities = [' '.join(el['sentence'].split()[i:i+n_words_in_entity]) for i in range(len(el['sentence'].split())-(n_words_in_entity-1))]\n",
    "                    if verbose: print(f'looking through {possible_entities}...')\n",
    "                    similarities = [fuzz.ratio(extracted_entity, possible_similar_entity) > 80\n",
    "                                    for possible_similar_entity in possible_entities]\n",
    "                    if any(similarities):\n",
    "                        if verbose: print('SIMILARITY FOUND', extracted_entity, '||||', el['sentence'].split()[similarities.index(True):similarities.index(True)+len(extracted_entity.split())])\n",
    "                        light_invented_entities.append({'extracted_entity':extracted_entity, 'original_entity':el['sentence'].split()[similarities.index(True)], 'original_sentence':el['sentence']})  \n",
    "                    else:\n",
    "                        heavy_invented_entities.append({'extracted_entity':extracted_entity, 'original_sentence':el['sentence']})\n",
    "                    if verbose: print('\\n')\n",
    "\n",
    "            light_allucinations.append(light_invented_entities)\n",
    "            heavy_allucinations.append(heavy_invented_entities)\n",
    "        data = data.add_column('light_allucinations', light_allucinations)\n",
    "        data = data.add_column('heavy_allucinations', heavy_allucinations)\n",
    "        return data\n",
    "\n",
    "    def remove_allucinations_from_computation(self, data, only_heavy:bool=True):\n",
    "        \"\"\"\n",
    "        Remove the invented entities/hallucinations, which are spans of text that have been extracted but are not in the sentence.\n",
    "        This function creates a new column called 'model_output_parsed' that contains the model output without the invented entities.\n",
    "        \"\"\"\n",
    "        if 'heavy_allucinations' not in data.column_names:\n",
    "            data = self.create_allucinations_columns(data)\n",
    "        \n",
    "        def helper(example):\n",
    "            if only_heavy:\n",
    "                if (example['heavy_allucinations'] == []):\n",
    "                    return example\n",
    "                else:\n",
    "                    for el in example['heavy_allucinations']:\n",
    "                        # print('REMOVING: ', el['extracted_entity'])\n",
    "                        example['model_output_parsed']['entities'].remove(el['extracted_entity'])\n",
    "                    return example\n",
    "            else:\n",
    "                if (example['light_allucinations'] == []) and (example['heavy_allucinations'] == []):\n",
    "                    return example\n",
    "                else:\n",
    "                    for el in example['light_allucinations']:\n",
    "                        # print('REMOVING: ', el['extracted_entity'])\n",
    "                        example['model_output_parsed']['entities'].remove(el['extracted_entity'])\n",
    "                    return example\n",
    "        data = data.map(helper)\n",
    "        return data\n",
    "    \n",
    "    def _assess_model_output(self, model_response: str) -> (bool, str):\n",
    "        \"\"\"\n",
    "        Check if the model output is in the right format. If not, return False.\n",
    "        \n",
    "        Args:\n",
    "        model_output (str): the postprocessed model output after beeing passed to _postprocess_model_output()\n",
    "\n",
    "        return:\n",
    "        bool: True if the format is correct, False otherwise\n",
    "        str: the model output in the adjusted format\n",
    "        \"\"\"\n",
    "        good_format = True\n",
    "        # if self.cleaner.verbose: print('prima sostituz:  ', model_response)\n",
    "        model_response = model_response.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\": \\'\", \": \\\"\")\n",
    "        model_response = re.sub(r'(?<=[a-zA-Z])\"(?=[a-zA-Z])', \"'\", model_response)\n",
    "        # if self.cleaner.verbose: print('dopo sostituz: ', model_response)\n",
    "        try :\n",
    "            out = json.loads(model_response)\n",
    "            if isinstance(out, dict):\n",
    "                model_response = '[' + model_response + ']'\n",
    "        except Exception as error:\n",
    "            print('ERROR: ', error)\n",
    "            if hasattr(error, 'msg'):\n",
    "                if error.msg.startswith('Expecting property name enclosed in double quotes'):\n",
    "                    model_response = model_response.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\": \\'\", \": \\\"\")\n",
    "                    try:\n",
    "                        out = json.loads(model_response)\n",
    "                        if isinstance(out, dict):\n",
    "                            model_response = '[' + model_response + ']'\n",
    "                            good_format = True\n",
    "                    except Exception as error2:\n",
    "                        if isinstance(error2, json.decoder.JSONDecodeError):\n",
    "                            if error2.msg == \"Expecting ',' delimiter\":\n",
    "                                model_response = self._change_apexes(model_response)\n",
    "                                good_format = True\n",
    "            else:\n",
    "                #print('MODEL RESPNSE: ', model_response)\n",
    "                good_format = False\n",
    "        if not good_format:\n",
    "            model_response = re.findall(r'\\[\\{(.+?)\\}\\]', model_response)\n",
    "            if len(model_response) != 0:\n",
    "                model_response = '[{' + model_response[0] + '}]'\n",
    "                good_format = True\n",
    "                try :\n",
    "                    json.loads(model_response)\n",
    "                except Exception as error:\n",
    "                    good_format = False\n",
    "            else:\n",
    "                good_format = False\n",
    "        return good_format, model_response\n",
    "\n",
    "    def _parse_json(self, model_response: str, drop_duplicates: bool = True) -> dict:\n",
    "        \"\"\"\n",
    "        Parse the model output to extract the entities and their offsets if present.\n",
    "        \n",
    "        Args:\n",
    "        model_response (str): the model response \n",
    "        drop_duplicates (bool): if True, drop the duplicates in the model response\n",
    "        \"\"\"\n",
    "        # print('MODEL RESPONSE 1: ', model_response)\n",
    "        model_response = model_response.replace(\"\\n\", \" \")\n",
    "\n",
    "        good_format, model_response = self._assess_model_output(model_response)\n",
    "\n",
    "        # print('MODEL RESPONSE 2: ', model_response)        \n",
    "        # print('MODEL RESPONSE 3: ', model_response)\n",
    "        if model_response == []:\n",
    "            model_response = '[{\"entity\":\"\"}]'\n",
    "        if good_format:\n",
    "            # print('MODEL RESPONSE 4: ', model_response)\n",
    "            # print('ORA STO PARSANDO: ', model_response)\n",
    "            output = json.loads(model_response)\n",
    "            # print('OUTPUT: ', type(output))\n",
    "            if drop_duplicates:\n",
    "                output = self._drop_duplicates(output)\n",
    "            entities = [entity[\"entity\"].strip() for entity in output]\n",
    "            # print('ENTITIES: ', entities)\n",
    "            return {\"entities\": entities}\n",
    "        if not good_format:\n",
    "            return {\"entities\": []}\n",
    "    \n",
    "    def count_repetitions_in_extraction(self):\n",
    "        \"\"\"\n",
    "        Count the number of times an entity is extracted multiple times in the model output.\n",
    "        Args:\n",
    "        data (list): the dataset containing the model output. \n",
    "        \"\"\"\n",
    "        duplications = 0\n",
    "        total_extracted = 0\n",
    "        extracted_deduplicated = 0\n",
    "        for el in self.data['model_output']:\n",
    "            ent_list = self._parse_json(el, drop_duplicates=False)['entities']\n",
    "            n_duplicated = len(ent_list) - len(set(ent_list)) \n",
    "            duplications += n_duplicated\n",
    "            total_extracted += len(ent_list)\n",
    "            extracted_deduplicated += len(set(ent_list))\n",
    "        return {\"n_duplicated_ent\":duplications, \"n_extracted_ent\":total_extracted, \"n_extracted_deduplicated_ent\":extracted_deduplicated}\n",
    "    \n",
    "    \n",
    "    def add_offset_to_entities(self):\n",
    "        \"\"\"\n",
    "        Add the offset to the entities in the dataset.\n",
    "        Args:\n",
    "        data (list): the dataset containing the model output\n",
    "        \"\"\"\n",
    "        entities_with_offset = []\n",
    "        gt_entities_with_offset = []\n",
    "        for el in self.data:\n",
    "            entities = el['model_output_parsed']['entities']\n",
    "            gt_entities = el['ground_truth_parsed']['entities']\n",
    "            sentence = el['sentence']\n",
    "            entities_with_offset.append(self._get_offset(entities, sentence))\n",
    "            gt_entities_with_offset.append(self._get_offset(gt_entities, sentence))\n",
    "            entities_with_offset[-1] =self._drop_subset_entities_by_offset(entities_with_offset[-1])\n",
    "            gt_entities_with_offset[-1] = self._drop_subset_entities_by_offset(gt_entities_with_offset[-1])\n",
    "\n",
    "        self.data = self.data.add_column('entities_with_offset', entities_with_offset)\n",
    "        self.data = self.data.add_column('gt_entities_with_offset', gt_entities_with_offset)\n",
    "    \n",
    "    def _get_offset(self, entities, sentence):\n",
    "        \"\"\"\n",
    "        Get the offset of the entities in the sentence.\n",
    "        Args:\n",
    "        entities (list): the list of entities\n",
    "        sentence (str): the sentence\n",
    "        \"\"\"\n",
    "        entities_with_offset = []\n",
    "        for entity in entities:\n",
    "            start = sentence.find(entity)\n",
    "            end = start + len(entity) -1\n",
    "            entities_with_offset.append({'entity':entity, 'start':start, 'end':end, 'offset':(start, end)})\n",
    "        return entities_with_offset\n",
    "    \n",
    "    def _drop_subset_entities_by_offset(self, entities):\n",
    "        \"\"\"\n",
    "        Drop the entities that are subsets of other entities.\n",
    "        Args:\n",
    "        entities (list): the list of entities\n",
    "        \"\"\"\n",
    "        entities = sorted(entities, key=lambda x: x['start'])\n",
    "        entities_to_drop = []\n",
    "        for ent in entities:\n",
    "            others_entities = [ent2 for ent2 in entities if ent2 != ent]\n",
    "            for ent2 in others_entities:\n",
    "                if ent['start']>= ent2['start'] and ent['end'] <= ent2['end']:\n",
    "                    entities_to_drop.append(ent['entity'])\n",
    "        entities = [ent for ent in entities if ent['entity'] not in entities_to_drop]\n",
    "        return entities\n",
    "\n",
    "    def _interval_in_offset(self, interval, start, end):\n",
    "        \"\"\"\n",
    "        Check if an integer is in the offset.\n",
    "        Args:\n",
    "        offset (tuple): the offset\n",
    "        start (int): the start of the offset\n",
    "        end (int): the end of the offset\n",
    "        \"\"\"\n",
    "        if interval[0] >= start and interval[1] <= end:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def convert_to_IOB_wordBased(self):\n",
    "        \"\"\"\n",
    "        Convert the entities in the dataset to the IOB format.\n",
    "        Args:\n",
    "        data (list): the dataset containing the model output\n",
    "        \"\"\"\n",
    "        self.add_offset_to_entities()\n",
    "        iob_entities = []\n",
    "        iob_ground_truth = []\n",
    "        for el in self.data:\n",
    "            iob_entities.append(self.example_to_IOB(el, 'model_output'))\n",
    "            iob_ground_truth.append(self.example_to_IOB(el, 'ground_truth'))\n",
    "        \n",
    "        def helper(x):\n",
    "            x['words'] = x['sentence'].split()\n",
    "            return x\n",
    "        self.data = self.data.add_column('word_labels_response', iob_entities)\n",
    "        self.data = self.data.add_column('word_labels_ground_truth', iob_ground_truth)\n",
    "        self.data= self.data.map(lambda x: helper(x))\n",
    "\n",
    "\n",
    "    def _tokenize_and_align_labels(self, tokenizer, word_level_labels_col_name):\n",
    "        examples = self.data\n",
    "        tokenized_inputs = tokenizer(examples[\"words\"], truncation=True, is_split_into_words=True, add_special_tokens=False)\n",
    "        labels = []\n",
    "        for i, words_label in enumerate(examples[word_level_labels_col_name]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "            label_ids = []\n",
    "            for k, word_idx in enumerate(word_ids): \n",
    "                same_word_as_previous  = False if (word_idx != word_ids[k-1] or k==0) else True\n",
    "                if word_idx is None:\n",
    "                    token_label = -100\n",
    "                elif words_label[word_idx] == 'O':\n",
    "                    token_label = 'O'\n",
    "                elif same_word_as_previous:\n",
    "                    token_label = 'I'\n",
    "                elif not same_word_as_previous:\n",
    "                    token_label = words_label[word_idx]\n",
    "                label_ids.append(token_label)\n",
    "                # if word_idx is not None:#  and k>12:\n",
    "                #     print(\"word_label: \", words_label[word_idx])\n",
    "                # print(tokenizer.decode(tokenized_inputs[i].ids[k]), \": \",word_idx,  \"\\nassigned_token_label:\",  label_ids[k], '\\n')\n",
    "            labels.append(label_ids)\n",
    "        col_name = 'token_labels_response' if word_level_labels_col_name == 'word_labels_response' else 'token_labels_ground_truth'\n",
    "        self.data = self.data.add_column(col_name, labels)\n",
    "    \n",
    "    def convert_to_IOB_tokenBased(self, tokenizer):\n",
    "        self.convert_to_IOB_wordBased()\n",
    "        self._tokenize_and_align_labels(tokenizer, 'word_labels_response')\n",
    "        self._tokenize_and_align_labels(tokenizer, 'word_labels_ground_truth')      \n",
    "\n",
    "     \n",
    "    def get_transition_matrix(self, labels_col_name):\n",
    "        def convert_to_probabilities(data):\n",
    "            new_data = {}\n",
    "            # Iterate over each outer key in the dictionary\n",
    "            for key, subdict in data.items():\n",
    "                new_data[key] = {}\n",
    "                # Calculate the sum of the sub-dictionary values\n",
    "                total = sum(subdict.values())\n",
    "                # Normalize each value by dividing by the total sum\n",
    "                for subkey in subdict:\n",
    "                    new_data[key][subkey] = round(subdict[subkey] / total, 3)\n",
    "            return new_data\n",
    "        \n",
    "        transition_matrix = {'O': {'O': 0, 'I': 0, 'B':0}, \n",
    "                             'I': {'O': 0, 'I': 0, 'B':0},\n",
    "                             'B': {'O': 0, 'I': 0, 'B':0}}\n",
    "        for example in self.data:\n",
    "            previous = example[labels_col_name][1]\n",
    "            for token in example[labels_col_name][1:]:\n",
    "                transition_matrix[previous][token] += 1\n",
    "                if previous=='O' and token=='I':\n",
    "                    print('EXAMPLE: \\n', example['sentence'], '\\n', example[labels_col_name], '\\n', example['model_output_parsed'])\n",
    "                previous = token\n",
    "\n",
    "        probability_matrix = convert_to_probabilities(transition_matrix)\n",
    "        return {'transition_matrix':transition_matrix, 'probability_matrix':probability_matrix}\n",
    "\n",
    "\n",
    "      \n",
    "    def _compare_prediction_label_one_example_token_by_token(self, example, prediction_col_name, ground_truth_col_name) -> (int, int, int):\n",
    "        \"\"\"\n",
    "        Compare the prediction with the label of one sentence.\n",
    "        Args:\n",
    "        predictions (list[str]): the list of the predicted labels\n",
    "        labels (list[str]): the list of the true labels\n",
    "        return:\n",
    "        int: the number of false positives\n",
    "        int: the number of false negatives\n",
    "        int: the number of true positives\n",
    "        \"\"\"\n",
    "        predictions = example[prediction_col_name]\n",
    "        labels = example[ground_truth_col_name]\n",
    "        TP, FP, FN = 0, 0, 0\n",
    "        # labels = ['O'] + labels[:-1] \n",
    "        for pred, lab in zip(predictions, labels):\n",
    "            # TP = TP + (1 if pred != 'O' and lab != 'O' else 0) \n",
    "            TP = TP + (1 if pred == lab and lab!='O' else 0)\n",
    "            FP = FP + (1 if pred != lab and lab =='O' else 0)\n",
    "            FN = FN + (1 if pred != lab and pred =='O' else 0)\n",
    "        TN = len(predictions) - (TP + FP + FN) \n",
    "        try:\n",
    "            precision = TP / (TP + FP)\n",
    "        except:\n",
    "            precision = 0\n",
    "        try:\n",
    "            recall = TP / (TP + FN)\n",
    "        except:\n",
    "            recall = 0\n",
    "        try:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        except:\n",
    "            f1 = 0\n",
    "        \n",
    "        example['TP'] = TP\n",
    "        example['FP'] = FP\n",
    "        example['FN'] = FN\n",
    "        example['TN'] = TN\n",
    "        example['precision'] = precision\n",
    "        example['recall'] = recall\n",
    "        example['f1'] = f1\n",
    "        return example\n",
    "    \n",
    "    def extract_FP_FN_TP_TN_token_by_token(self, prediction_col_name, ground_truth_col_name) -> (int, int, int):\n",
    "        \"\"\"\n",
    "        Extract the number of False Positives, False Negatives and True Positives from the model output and the ground truth.\n",
    "        Args:\n",
    "        predictions (list[str]): the list of the predicted labels\n",
    "        labels (list[str]): the list of the true labels\n",
    "        return:\n",
    "        int: the number of false positives\n",
    "        int: the number of false negatives\n",
    "        int: the number of true positives\n",
    "        \"\"\"\n",
    "        self.data = self.data.map(lambda x: self._compare_prediction_label_one_example_token_by_token(x, prediction_col_name, ground_truth_col_name), batched=False)\n",
    "\n",
    "\n",
    "    def create_evaluation_table_tkn(self, prediction_col_name, ground_truth_col_name):\n",
    "        \"\"\"\n",
    "        Create the evaluation table with the number of False Positives, False Negatives and True Positives, token based\n",
    "        \"\"\"\n",
    "        self.extract_FP_FN_TP_TN_token_by_token(prediction_col_name, ground_truth_col_name)\n",
    "        tmp_data = self.data.to_pandas()\n",
    "        TP = tmp_data['TP'].sum()\n",
    "        FP = tmp_data['FP'].sum()\n",
    "        FN = tmp_data['FN'].sum()\n",
    "        # TN = tmp_data['TN'].sum()\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        self.evaluation_table_tkn = {'TP': TP, 'FP': FP, 'FN': FN, #'TN': TN,\n",
    "                                  'precision':precision, 'recall':recall, 'f1':f1}\n",
    "        \n",
    "    \n",
    "\n",
    "    def example_to_IOB(self, example, type:str, verbose:bool = False):\n",
    "        \"\"\"\n",
    "        Convert the entities in the example to the IOB format.\n",
    "        Args:\n",
    "        example (dict): the example containing the model output\n",
    "        type (str): the type of the example. Either 'model_output' or 'ground_truth'\n",
    "        \"\"\"\n",
    "        if type == 'model_output':\n",
    "            field = 'entities_with_offset'\n",
    "        elif type == 'ground_truth':\n",
    "            field = 'gt_entities_with_offset'\n",
    "        \n",
    "        string.punctuation = string.punctuation + '“'\n",
    "        \n",
    "        def remove_punct(text):\n",
    "            if not sum([char.isdigit() for char in text])/len(text) > 0.5: # if the text is NOT more than 50% digits, the text is not a number, so remove the final punctuation\n",
    "                return text.rstrip(string.punctuation).lstrip(string.punctuation)\n",
    "            else:\n",
    "                return text\n",
    "\n",
    "        iob_grount_truth = []\n",
    "        words_list = example['sentence'].split()\n",
    "        index_char_begin_of_words = [0]\n",
    "        index_char_begin_of_words_corrected = [0]\n",
    "        for word in words_list:\n",
    "            index_char_begin_of_words.append(index_char_begin_of_words[-1] + len(word) + 1)\n",
    "            index_char_begin_of_words_corrected[-1] += (1 if word[0] in string.punctuation else 0)\n",
    "            index_char_begin_of_words_corrected.append(index_char_begin_of_words[-1])\n",
    "\n",
    "        if verbose: print(index_char_begin_of_words)        \n",
    "        if verbose: print(index_char_begin_of_words_corrected)\n",
    "\n",
    "        \n",
    "        words_list = [remove_punct(word) for word in words_list]  \n",
    "        if verbose: display(example[field])\n",
    "        if verbose: print(example['sentence'])\n",
    "        if verbose: print(example['model_output_parsed'])\n",
    "        if verbose: print([(ent['entity'], ent['start'], ent['end'] ) for ent in example[field]])\n",
    "        for i, word in enumerate(words_list):\n",
    "            word_interval = (index_char_begin_of_words_corrected[i], index_char_begin_of_words[i] + len(word) -1)\n",
    "            if any(self._interval_in_offset(word_interval, ent['start'], ent['end']) for ent in example[field] ):\n",
    "                assigned_ent = [ent for ent in example[field] if self._interval_in_offset(word_interval, ent['start'], ent['end'])][0]\n",
    "                if verbose: print(assigned_ent['start'] , word_interval[0])\n",
    "                if assigned_ent['start'] == word_interval[0]:\n",
    "                    iob_grount_truth.append('B')\n",
    "                else:\n",
    "                    iob_grount_truth.append('I')\n",
    "            else:\n",
    "                iob_grount_truth.append('O')\n",
    "            \n",
    "            if verbose: print('word: ', word, ' offset: ', word_interval, 'labels: ', iob_grount_truth[-1])\n",
    "        return iob_grount_truth\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 14, 24, 31, 40, 49, 58, 71, 80, 86, 92, 95, 102, 106, 108, 122, 131, 137, 140, 149, 152, 168, 172, 176, 182, 184, 191, 193, 196, 204]\n",
      "[0, 3, 14, 24, 31, 40, 49, 58, 71, 81, 86, 92, 95, 102, 106, 108, 122, 131, 137, 140, 149, 152, 168, 173, 176, 183, 184, 192, 193, 196, 204]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'end': 29, 'entity': 'survey', 'offset': [24, 29], 'start': 24},\n",
       " {'end': 38, 'entity': 'revealed', 'offset': [31, 38], 'start': 31},\n",
       " {'end': 56, 'entity': 'elevated', 'offset': [49, 56], 'start': 49},\n",
       " {'end': 78,\n",
       "  'entity': 'anti-nuclear antibody',\n",
       "  'offset': [58, 78],\n",
       "  'start': 58},\n",
       " {'end': 83, 'entity': 'ANA', 'offset': [81, 83], 'start': 81},\n",
       " {'end': 90, 'entity': 'titer', 'offset': [86, 90], 'start': 86},\n",
       " {'end': 100, 'entity': '1/1600', 'offset': [95, 100], 'start': 95},\n",
       " {'end': 170,\n",
       "  'entity': 'double-stranded DNA',\n",
       "  'offset': [152, 170],\n",
       "  'start': 152},\n",
       " {'end': 180, 'entity': '83 IU/mL', 'offset': [173, 180], 'start': 173},\n",
       " {'end': 189, 'entity': 'normal', 'offset': [184, 189], 'start': 184}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An additional serologic survey revealed markedly elevated anti-nuclear antibody (ANA) titer of 1/1600 and a significantly elevated titer of antibody to double-stranded DNA (83 IU/mL ; normal < 30 IU/mL).\n",
      "{'entities': ['survey', 'revealed', 'anti-nuclear antibody', 'ANA', 'titer', 'elevated', 'antibody', 'double-stranded DNA', '83 IU/mL', 'normal', '1/1600']}\n",
      "[('survey', 24, 29), ('revealed', 31, 38), ('elevated', 49, 56), ('anti-nuclear antibody', 58, 78), ('ANA', 81, 83), ('titer', 86, 90), ('1/1600', 95, 100), ('double-stranded DNA', 152, 170), ('83 IU/mL', 173, 180), ('normal', 184, 189)]\n",
      "word:  An  offset:  (0, 1) labels:  O\n",
      "word:  additional  offset:  (3, 12) labels:  O\n",
      "word:  serologic  offset:  (14, 22) labels:  O\n",
      "24 24\n",
      "word:  survey  offset:  (24, 29) labels:  B\n",
      "31 31\n",
      "word:  revealed  offset:  (31, 38) labels:  B\n",
      "word:  markedly  offset:  (40, 47) labels:  O\n",
      "49 49\n",
      "word:  elevated  offset:  (49, 56) labels:  B\n",
      "58 58\n",
      "word:  anti-nuclear  offset:  (58, 69) labels:  B\n",
      "58 71\n",
      "word:  antibody  offset:  (71, 78) labels:  I\n",
      "81 81\n",
      "word:  ANA  offset:  (81, 82) labels:  B\n",
      "86 86\n",
      "word:  titer  offset:  (86, 90) labels:  B\n",
      "word:  of  offset:  (92, 93) labels:  O\n",
      "95 95\n",
      "word:  1/1600  offset:  (95, 100) labels:  B\n",
      "word:  and  offset:  (102, 104) labels:  O\n",
      "word:  a  offset:  (106, 106) labels:  O\n",
      "word:  significantly  offset:  (108, 120) labels:  O\n",
      "word:  elevated  offset:  (122, 129) labels:  O\n",
      "word:  titer  offset:  (131, 135) labels:  O\n",
      "word:  of  offset:  (137, 138) labels:  O\n",
      "word:  antibody  offset:  (140, 147) labels:  O\n",
      "word:  to  offset:  (149, 150) labels:  O\n",
      "152 152\n",
      "word:  double-stranded  offset:  (152, 166) labels:  B\n",
      "152 168\n",
      "word:  DNA  offset:  (168, 170) labels:  I\n",
      "173 173\n",
      "word:  (83  offset:  (173, 174) labels:  B\n",
      "173 176\n",
      "word:  IU/mL  offset:  (176, 180) labels:  I\n",
      "word:    offset:  (183, 181) labels:  O\n",
      "184 184\n",
      "word:  normal  offset:  (184, 189) labels:  B\n",
      "word:    offset:  (192, 190) labels:  O\n",
      "word:  30  offset:  (193, 194) labels:  O\n",
      "word:  IU/mL  offset:  (196, 200) labels:  O\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'B',\n",
       " 'O',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'I',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_analist = OutputAnalist(data_parsed)\n",
    "output_analist.example_to_IOB (tmp2[72], 'model_output', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE: \n",
      " Treatment of pulmonary embolism was initiated with subcutaneous low molecular weight heparin (enoxaparin 0.1 ml/10 kg/12h) followed by antivitamin K. \n",
      " ['O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I', 'I', 'I', 'I', 'I', 'I', 'B', 'O', 'B', 'I', 'I', 'I', 'I', 'I'] \n",
      " {'entities': ['initiated', 'heparin', 'enoxaparin', 'followed', 'antivitamin K', 'pulmonary embolism', '10 kg/12h']}\n",
      "EXAMPLE: \n",
      " An additional serologic survey revealed markedly elevated anti-nuclear antibody (ANA) titer of 1/1600 and a significantly elevated titer of antibody to double-stranded DNA (83 IU/mL ; normal < 30 IU/mL). \n",
      " ['O', 'O', 'O', 'O', 'O', 'B', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'B', 'I', 'I', 'I', 'B', 'I', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'O', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I'] \n",
      " {'entities': ['survey', 'revealed', 'anti-nuclear antibody', 'ANA', 'titer', 'elevated', 'antibody', 'double-stranded DNA', '83 IU/mL', 'normal', '1/1600']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 681/681 [00:00<00:00, 3543.50 examples/s]\n"
     ]
=======
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da395ef53e14d369fcd773a5cb441ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/681 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0afea68b76a4e7b9cd56358516802a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/681 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4200e132f1c347c9ac5ceee096e9fe40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/681 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix responses\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TP': 77,\n",
       " 'FP': 200,\n",
       " 'FN': 2200,\n",
       " 'precision': 0.2779783393501805,\n",
       " 'recall': 0.033816425120772944,\n",
       " 'f1': 0.060297572435395456}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'O': {'O': 0.996, 'I': 0.0, 'B': 0.004},\n",
       " 'I': {'O': 0.6, 'I': 0.4, 'B': 0.0},\n",
       " 'B': {'O': 0.426, 'I': 0.393, 'B': 0.18}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix ground truth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'O': {'O': 0.768, 'I': 0.0, 'B': 0.232},\n",
       " 'I': {'O': 0.193, 'I': 0.736, 'B': 0.071},\n",
       " 'B': {'O': 0.238, 'I': 0.669, 'B': 0.092}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'An additional serologic survey revealed markedly elevated anti-nuclear antibody (ANA) titer of 1/1600 and a significantly elevated titer of antibody to double-stranded DNA (83 IU/mL ; normal < 30 IU/mL).',\n",
       " 'entities': \"[{'id': '9105', 'offsets': array([24, 30]), 'role': '', 'semantic_type_id': '', 'text': 'survey', 'type': 'EVENT'}\\n {'id': '9120', 'offsets': array([31, 39]), 'role': '', 'semantic_type_id': '', 'text': 'revealed', 'type': 'EVENT'}\\n {'id': '9135', 'offsets': array([86, 91]), 'role': '', 'semantic_type_id': '', 'text': 'titer', 'type': 'EVENT'}\\n {'id': '9150', 'offsets': array([131, 136]), 'role': '', 'semantic_type_id': '', 'text': 'titer', 'type': 'EVENT'}\\n {'id': '9690', 'offsets': array([71, 79]), 'role': '', 'semantic_type_id': '', 'text': 'antibody', 'type': 'BODYPART'}\\n {'id': '9696', 'offsets': array([81, 84]), 'role': '', 'semantic_type_id': '', 'text': 'ANA', 'type': 'BODYPART'}\\n {'id': '9702', 'offsets': array([140, 148]), 'role': '', 'semantic_type_id': '', 'text': 'antibody', 'type': 'BODYPART'}\\n {'id': '9879', 'offsets': array([ 95, 101]), 'role': '', 'semantic_type_id': '', 'text': '1/1600', 'type': 'RML'}\\n {'id': '9885', 'offsets': array([173, 181]), 'role': '', 'semantic_type_id': '', 'text': '83 IU/mL', 'type': 'RML'}\\n {'id': '9891', 'offsets': array([191, 201]), 'role': '', 'semantic_type_id': '', 'text': '< 30 IU/mL', 'type': 'RML'}]\",\n",
       " 'original_text': 'A 77-year-old Tunisian woman was hospitalized because of massive painful ascites. Her family history did not include any autoimmune disease. She denied a history of hepatitis, jaundice or alcohol use. She had a history of diabetes, hypertension treated by glinide and calcium blocker. She was explored 4 years prior to admission for exudative pleuritis of the right lung without any established diagnosis after multiple explorations including thoracoscopy with biopsies. On admission, blood pressure was 150/70 mmHg, her rate was 80 /mn and body temperature was 37°C. The physical examination showed only abdominal distension related to the important ascites without collateral venous circulation. She had no skin lesions, lymphadenopathy, or hepatosplenomegaly and lower extremities showed no edema. Laboratory investigations showed: leucopenia with white blood cell count = 3100/mm3, lymphopenia = 840/mm3, hemoglobin = 10.5g/dL ; low serum albumin level = 29g/L, 47;-globulin = 19g/L. blood glucose levels = 180 mg/dl and hemoglobin A1c = 8.6 %. Urine analysis showed trace protein (0.03g/24h). Platelet count, activated partial thromboplastin time, liver function tests, blood urea nitrogen, serum creatinine, erythrocyte sediment rate and total cholesterol were within normal limits. Tests for HBsAg and HCV were negative. Abdominal ultrasonography showed ascitic fluid without any sign of bowel loop thickening or enteritis. Neither lymphadenopathy nor liver abnormality was present. A chest X-ray film disclosed bilateral pleural effusion. Ascitic obtained by aspiration contained 170 cells mm3 (67% lymphocytes), 46g/L protein, but no malignant cells. Cultures for bacteria and mycobacteria gave no growth. Tuberculosis investigation including initial tuberculin skin test and the research of Koch bacilli in sputum and urine were negative. Echocardiogram and electrocardiogram were normal. Computed tomographic scan showed massive ascites, no dysmorphic liver, and a mild bilateral pleural effusion. Pelvic examination was normal. Oesogastroduodenoscopy showed hiatal hernia without oesophageal varices. An exploratory laparoscopy was performed, revealing a large amount of ascite, a normal liver appearance, and no granulations suggesting tuberculosis or peritoneal carcinosis. Histological examination of the peritoneum showed non specific chronic inflammation. Systemic lupus erythematosus was suspected based on pleuritis, lymphopenia and leucopenia. An additional serologic survey revealed markedly elevated anti-nuclear antibody (ANA) titer of 1/1600 and a significantly elevated titer of antibody to double-stranded DNA (83 IU/mL ; normal < 30 IU/mL). She had also positive serum antibody against the Smith antigen and low serum level of C3 complement component: 67 mg/dL (serum normal range: 84 – 151). Relying on these findings, the patient was diagnosed with SLE since 4 of the 11 diagnostic criteria of the American College of Rheumatology were met. The SLEDAI score according to Systemic Lupus Erythematosus Disease Activity Index was estimated to be 7 on admission. Hydroxychloroquine 200 mg daily in combination with diuretics was initiated. One month later, there was no detectable ascitic fluid and no pleural effusions. Five months later she remained free from symptoms while continuing to take Hydroxychloroquine\\r\\n',\n",
       " 'original_id': 'EN100114',\n",
       " 'prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<An additional serologic survey revealed markedly elevated anti-nuclear antibody (ANA) titer of 1/1600 and a significantly elevated titer of antibody to double-stranded DNA (83 IU/mL ; normal < 30 IU/mL).>>> [/INST][{\"entity\": \"survey\"}, {\"entity\": \"revealed\"}, {\"entity\": \"titer\"}, {\"entity\": \"titer\"}, {\"entity\": \"antibody\"}, {\"entity\": \"ANA\"}, {\"entity\": \"antibody\"}, {\"entity\": \"1/1600\"}, {\"entity\": \"83 IU/mL\"}, {\"entity\": \"< 30 IU/mL\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<An additional serologic survey revealed markedly elevated anti-nuclear antibody (ANA) titer of 1/1600 and a significantly elevated titer of antibody to double-stranded DNA (83 IU/mL ; normal < 30 IU/mL).>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"survey\"}, {\"entity\": \"revealed\"}, {\"entity\": \"titer\"}, {\"entity\": \"titer\"}, {\"entity\": \"antibody\"}, {\"entity\": \"ANA\"}, {\"entity\": \"antibody\"}, {\"entity\": \"1/1600\"}, {\"entity\": \"83 IU/mL\"}, {\"entity\": \"< 30 IU/mL\"}] ',\n",
       " 'model_responses': ' [{\"entity\": \"survey\"}, {\"entity\": \"revealed\"}, {\"entity\": \"anti-nuclear antibody\"}, {\"entity\": \"ANA\"}, {\"entity\": \"titer\"}, {\"entity\": \"elevated\"}, {\"entity\": \"titer\"}, {\"entity\": \"antibody\"}, {\"entity\": \"double-stranded DNA\"}, {\"entity\": \"83 IU/mL\"}, {\"entity\": \"normal\"}, {\"entity\": \"1/1600\"}]  [/INST][',\n",
       " 'model_output': \"[{'entity': 'survey'}, {'entity': 'revealed'}, {'entity': 'anti-nuclear antibody'}, {'entity': 'ANA'}, {'entity': 'titer'}, {'entity': 'elevated'}, {'entity': 'titer'}, {'entity': 'antibody'}, {'entity': 'double-stranded DNA'}, {'entity': '83 IU/mL'}, {'entity': 'normal'}, {'entity': '1/1600'}]\",\n",
       " 'model_output_parsed': {'entities': ['survey',\n",
       "   'revealed',\n",
       "   'anti-nuclear antibody',\n",
       "   'ANA',\n",
       "   'titer',\n",
       "   'elevated',\n",
       "   'antibody',\n",
       "   'double-stranded DNA',\n",
       "   '83 IU/mL',\n",
       "   'normal',\n",
       "   '1/1600']},\n",
       " 'ground_truth_parsed': {'entities': ['survey',\n",
       "   'revealed',\n",
       "   'titer',\n",
       "   'antibody',\n",
       "   'ANA',\n",
       "   '1/1600',\n",
       "   '83 IU/mL',\n",
       "   '< 30 IU/mL']},\n",
       " 'light_allucinations': [],\n",
       " 'heavy_allucinations': [],\n",
       " 'entities_with_offset': [{'end': 29,\n",
       "   'entity': 'survey',\n",
       "   'offset': [24, 29],\n",
       "   'start': 24},\n",
       "  {'end': 38, 'entity': 'revealed', 'offset': [31, 38], 'start': 31},\n",
       "  {'end': 56, 'entity': 'elevated', 'offset': [49, 56], 'start': 49},\n",
       "  {'end': 78,\n",
       "   'entity': 'anti-nuclear antibody',\n",
       "   'offset': [58, 78],\n",
       "   'start': 58},\n",
       "  {'end': 83, 'entity': 'ANA', 'offset': [81, 83], 'start': 81},\n",
       "  {'end': 90, 'entity': 'titer', 'offset': [86, 90], 'start': 86},\n",
       "  {'end': 100, 'entity': '1/1600', 'offset': [95, 100], 'start': 95},\n",
       "  {'end': 170,\n",
       "   'entity': 'double-stranded DNA',\n",
       "   'offset': [152, 170],\n",
       "   'start': 152},\n",
       "  {'end': 180, 'entity': '83 IU/mL', 'offset': [173, 180], 'start': 173},\n",
       "  {'end': 189, 'entity': 'normal', 'offset': [184, 189], 'start': 184}],\n",
       " 'gt_entities_with_offset': [{'end': 29,\n",
       "   'entity': 'survey',\n",
       "   'offset': [24, 29],\n",
       "   'start': 24},\n",
       "  {'end': 38, 'entity': 'revealed', 'offset': [31, 38], 'start': 31},\n",
       "  {'end': 78, 'entity': 'antibody', 'offset': [71, 78], 'start': 71},\n",
       "  {'end': 83, 'entity': 'ANA', 'offset': [81, 83], 'start': 81},\n",
       "  {'end': 90, 'entity': 'titer', 'offset': [86, 90], 'start': 86},\n",
       "  {'end': 100, 'entity': '1/1600', 'offset': [95, 100], 'start': 95},\n",
       "  {'end': 180, 'entity': '83 IU/mL', 'offset': [173, 180], 'start': 173},\n",
       "  {'end': 200, 'entity': '< 30 IU/mL', 'offset': [191, 200], 'start': 191}],\n",
       " 'word_labels_response': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'word_labels_ground_truth': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I'],\n",
       " 'words': ['An',\n",
       "  'additional',\n",
       "  'serologic',\n",
       "  'survey',\n",
       "  'revealed',\n",
       "  'markedly',\n",
       "  'elevated',\n",
       "  'anti-nuclear',\n",
       "  'antibody',\n",
       "  '(ANA)',\n",
       "  'titer',\n",
       "  'of',\n",
       "  '1/1600',\n",
       "  'and',\n",
       "  'a',\n",
       "  'significantly',\n",
       "  'elevated',\n",
       "  'titer',\n",
       "  'of',\n",
       "  'antibody',\n",
       "  'to',\n",
       "  'double-stranded',\n",
       "  'DNA',\n",
       "  '(83',\n",
       "  'IU/mL',\n",
       "  ';',\n",
       "  'normal',\n",
       "  '<',\n",
       "  '30',\n",
       "  'IU/mL).'],\n",
       " 'token_labels_response': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'token_labels_ground_truth': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'B',\n",
       "  'I',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I'],\n",
       " 'TP': 24,\n",
       " 'FP': 14,\n",
       " 'FN': 9,\n",
       " 'TN': 22,\n",
       " 'precision': 0.631578947368421,\n",
       " 'recall': 0.7272727272727273,\n",
       " 'f1': 0.676056338028169}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_analist = OutputAnalist(data_parsed)\n",
    "#output_analist.example_to_IOB(output_analist.data[72], 'model_output')\n",
    "output_analist.data = output_analist.remove_allucinations_from_computation(output_analist.data)\n",
    "output_analist.convert_to_IOB_tokenBased(tokenizer)\n",
<<<<<<< HEAD
    "transition_matrix_responses = output_analist.get_transition_matrix('token_labels_response')\n",
    "transition_matrix_gt = output_analist.get_transition_matrix('token_labels_ground_truth')\n",
=======
    "output_analist.get_transition_matrix('word_labels_response')\n",
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
    "output_analist.create_evaluation_table_tkn(prediction_col_name='token_labels_response', ground_truth_col_name='token_labels_ground_truth')\n",
    "display(output_analist.evaluation_table_tkn)\n",
    "print('Transition matrix responses')\n",
    "display(transition_matrix_responses['probability_matrix'])\n",
    "print('Transition matrix ground truth')\n",
    "display(transition_matrix_gt['probability_matrix'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 9,
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_parsed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
<<<<<<< HEAD
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m, token \u001b[38;5;241m=\u001b[39m HF_TOKEN)\n\u001b[1;32m      6\u001b[0m output_analist \u001b[38;5;241m=\u001b[39m OutputAnalist(data_parsed)\n\u001b[0;32m----> 7\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43moutput_analist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_IOB\u001b[49m(data_parsed, tokenizer)\n\u001b[1;32m      8\u001b[0m out[\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OutputAnalist' object has no attribute 'convert_to_IOB'"
=======
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m HF_TOKEN \u001b[38;5;241m=\u001b[39m dotenv_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.env.base\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m, token \u001b[38;5;241m=\u001b[39m HF_TOKEN)\n\u001b[0;32m----> 6\u001b[0m output_analist \u001b[38;5;241m=\u001b[39m OutputAnalist(\u001b[43mdata_parsed\u001b[49m)\n\u001b[1;32m      7\u001b[0m out \u001b[38;5;241m=\u001b[39m output_analist\u001b[38;5;241m.\u001b[39mconvert_to_IOB(data_parsed, tokenizer)\n\u001b[1;32m      8\u001b[0m out[\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_parsed' is not defined"
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from transformers import AutoTokenizer\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token = HF_TOKEN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "for i, el in enumerate(data_parsed):\n",
    "    if el['sentence'].startswith(\"An additional serologic survey reve\"):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 681/681 [00:00<00:00, 4694.35 examples/s]\n"
     ]
    },
    {
=======
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
     "data": {
      "text/plain": [
       "{'input_ids': [1, 518, 29914, 25580, 29962], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
<<<<<<< HEAD
     "execution_count": 4,
=======
     "execution_count": 52,
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id\n",
    "tokenizer('[/INST]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find '/home/pferrazzi/mistral_finetuning/'data/llama/7B_NoQuant_FT_cl_v2prompt/maxNewTokensFactor4_nShotsInference0_llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002_clent.csv''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_cleaner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputCleaner\n\u001b[1;32m      4\u001b[0m file \u001b[38;5;241m=\u001b[39m  data_path\n\u001b[0;32m----> 5\u001b[0m eval_data \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      7\u001b[0m output_cleaner \u001b[38;5;241m=\u001b[39m OutputCleaner(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m similar_is_equal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mistral_finetuning/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:1048\u001b[0m, in \u001b[0;36mDataset.from_csv\u001b[0;34m(path_or_paths, split, features, cache_dir, keep_in_memory, num_proc, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;66;03m# Dynamic import to avoid circular dependency\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CsvDatasetReader\n\u001b[0;32m-> 1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCsvDatasetReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/mistral_finetuning/.venv/lib/python3.12/site-packages/datasets/io/csv.py:38\u001b[0m, in \u001b[0;36mCsvDatasetReader.__init__\u001b[0;34m(self, path_or_paths, split, features, cache_dir, keep_in_memory, streaming, num_proc, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     28\u001b[0m     path_or_paths,\n\u001b[1;32m     29\u001b[0m     split\u001b[38;5;241m=\u001b[39msplit,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m path_or_paths \u001b[38;5;241m=\u001b[39m path_or_paths \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_paths, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit: path_or_paths}\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder \u001b[38;5;241m=\u001b[39m \u001b[43mCsv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mistral_finetuning/.venv/lib/python3.12/site-packages/datasets/builder.py:360\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer_batch_size \u001b[38;5;241m=\u001b[39m writer_batch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEFAULT_WRITER_BATCH_SIZE\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_files, DataFilesDict):\n\u001b[0;32m--> 360\u001b[0m     data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43msanitize_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDownloadConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Prepare config: DatasetConfig contains name, version and description but can be extended by each dataset\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIG_CLASS\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;129;01mand\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mistral_finetuning/.venv/lib/python3.12/site-packages/datasets/data_files.py:715\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    712\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    714\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 715\u001b[0m         \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m patterns_for_key\n\u001b[1;32m    723\u001b[0m     )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/mistral_finetuning/.venv/lib/python3.12/site-packages/datasets/data_files.py:620\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 620\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m         )\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/mistral_finetuning/.venv/lib/python3.12/site-packages/datasets/data_files.py:407\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/home/pferrazzi/mistral_finetuning/'data/llama/7B_NoQuant_FT_cl_v2prompt/maxNewTokensFactor4_nShotsInference0_llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002_clent.csv''"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "#from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "file =  data_path\n",
    "eval_data = Dataset.from_csv(file) \n",
    "\n",
    "output_cleaner = OutputCleaner(verbose=True)\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False) #.select(range(12,13))\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=cleaned_data)\n",
    "evaluator.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'])\n",
    "\n",
    "data_parsed = evaluator.data.map(lambda x: {'model_output_parsed':evaluator._parse_json(x['model_output']),\n",
    "                                            'ground_truth_parsed':evaluator._parse_json(x['ground_truth'])})\n",
    "evaluator.evaluation_table"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'entities', 'original_text', 'original_id', 'prompt', 'inference_prompt', 'ground_truth', 'model_responses'],\n",
       "    num_rows: 681\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'In addition to that, T2 weighted MRI shows extensive venous formations around corpus of right lateral ventricle and at Gallen vein localization and widespread vascular formations are seen at perivascular space, anterior to third ventricle at Willis polygon localization and at right temporooccipital area at quadrigeminal cistern localization.',\n",
       " 'entities': '[]',\n",
       " 'original_text': \"A 21 year old female patient with the diagnosis of SWS suffering from headaches admitted to our clinic. She had a 2 year history of frequent non-pulsating headaches. Her headache was relieving with non-steroidal anti-inflammatory drugs and was not worsening with physical activity. There was no nausea or aura like symptoms accompanying the headache. Headaches were lasting for hours. The pain was bilateral, generalized and pressing in quality. The family history for headache was negative. She had a history of seizures occurring in the fifteenth day of life described as attacks of tonic clonic contractions and that's when she was diagnosed with SWS. At the age of 6 she had a history of callosotomy to control her seizures. At the age of 18 during a laser treatment done in order to get rid of her port wine birthmark she had her first seizure since callosotomy. After that she was prescribed carbamazepine 400 mg at daily dose and never had a seizure since then. According to the story taken from her parents even though she had a normal development at infancy she barely graduated from elementary school and she's hardly literate. There was nothing significant on her family history except for her elder sister's port wine stain on her face. The elder sister had no feature of SWS and no researches were done regarding her stain. She was inscribed daily doses of ketiapin 25 mg for anxiety disorder and venlafaxine 75 mg for both anxiety disorder and the chronic headaches. She was also inscribed NSAID drugs. After the first week of this treatment her headaches were slightly decreased by heaviness but the frequency was the same. At her physical examination a facial nevus -occurred due to choroid angioma-on the right forehead, right eyelid, nasal wing and the cheek was observed. Intra oral examination showed a right sided overgrowth of gingiva. Gingival overgrowth was bright red in color and showed blanching on applying pressure suggesting angiomatous enlargement. On her extremities a mild asymmetry was visible. Her left arm and leg was slightly smaller in portions and showed hemiparesis both in the upper and lower extremities of the same size. On her ophthalmological evaluation she was diagnosed with glaucoma of the right eye. On her psychiatric examination she showed signs of anxiety disorder. Her neurological examination was not remarkable except for her hemiparesis. Cranial CT scans showed diffuse atrophy in the right hemisphere and irregular double-contoured gyriform cortical calcifications in the right occipital area. Gadolinium enhanced brain MRI revealed multiple dilated pial venous vascular structures on right hemisphere also with the diffuse atrophy on the same side. Axial T1 weighted cranial MRI shows right calvarial thickness compared to the left and right hemisphere is asymmetrically smaller than the left. In addition to that, T2 weighted MRI shows extensive venous formations around corpus of right lateral ventricle and at Gallen vein localization and widespread vascular formations are seen at perivascular space, anterior to third ventricle at Willis polygon localization and at right temporooccipital area at quadrigeminal cistern localization. She was performed a proteus intelligence test in which she had 75 points and accepted as mildly mentally retarded. Proteus intelligence test in which she had 75 points and accepted as mildly mentally retarded.\\r\\n\",\n",
       " 'original_id': 'EN100129',\n",
       " 'prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<In addition to that, T2 weighted MRI shows extensive venous formations around corpus of right lateral ventricle and at Gallen vein localization and widespread vascular formations are seen at perivascular space, anterior to third ventricle at Willis polygon localization and at right temporooccipital area at quadrigeminal cistern localization.>>> [/INST] []</s>',\n",
       " 'inference_prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<In addition to that, T2 weighted MRI shows extensive venous formations around corpus of right lateral ventricle and at Gallen vein localization and widespread vascular formations are seen at perivascular space, anterior to third ventricle at Willis polygon localization and at right temporooccipital area at quadrigeminal cistern localization.>>> [/INST]',\n",
       " 'ground_truth': '[]</s>',\n",
       " 'model_responses': '[]</s></s></s></s></s></s></s></s></s></s>'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  ' [{\"entity\": \"cervical compression\"}]</s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       "  '[]</s></s></s></s></s></s></s></s></s></s></s></s>'],\n",
       " ['[{\"entity\": \"new-onset diabetes mellitus\"}] ',\n",
       "  '[]',\n",
       "  '[{\"entity\": \"primary right parotid malignancy\"}, {\"entity\": \"liver metastases\"}] ',\n",
       "  '[{\"entity\": \"ACC\"}] ',\n",
       "  '[{\"entity\": \"hypercortisolism\"}] ',\n",
       "  '[{\"entity\": \"cervical mass\"}] ',\n",
       "  '[{\"entity\": \"MNG\"}] ',\n",
       "  '[{\"entity\": \"mass\"}, {\"entity\": \"cervical compression\"}, {\"entity\": \"respiratory, digestive, laryngeal, vascular or neurologic signs\"}, {\"entity\": \"digestive, laryngeal, vascular or neurologic signs\"}, {\"entity\": \"laryngeal, vascular or neurologic signs\"}, {\"entity\": \"vascular or neurologic signs\"}, {\"entity\": \"neurologic signs\"}] ',\n",
       "  '[{\"entity\": \"thyroid dysfunction\"}] ',\n",
       "  '[{\"entity\": \"mass\"}] '])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.data['model_responses'][:10], evaluator.data['ground_truth'][:10]"
   ]
  },
  {
>>>>>>> 034d187f475f6f1e69f3d240c35d18b72dbf00ac
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vediamo quante volte succede che il modello inventa entità che non son onel testo originario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 117 invented entities over 4589 extracted entities -> 2.5%\n"
     ]
    }
   ],
   "source": [
    "output_analist = OutputAnalist(data_parsed)\n",
    "\n",
    "allucinations = []\n",
    "for el in output_analist.data:\n",
    "    invented_entities = []\n",
    "    for extracted_entity in el['model_output_parsed']['entities']:\n",
    "        if extracted_entity.lower() not in el['sentence'].lower():\n",
    "            #print('EXTRACTED ENTITY NOT IN sentence: ', extracted_entity, '||||', el['sentence'])\n",
    "            invented_entities.append(extracted_entity)\n",
    "    allucinations.append(invented_entities)\n",
    "len1 = len([el for sublist in allucinations for el in sublist])\n",
    "len2 = len([el for sublist in output_analist.data['model_output_parsed'] for el in sublist['entities']])\n",
    "print(f\"There are {len1} invented entities over {len2} extracted entities -> {round(len1/len2*100,1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quante di queste allucinazioni sono però molto simili a qualcosa che c'è nel testo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 76 heavy allucinations over 117 allucinations -> 65.0%\n",
      "61 sentences are impacted by allucination out of 681 -> 11.2%\n"
     ]
    }
   ],
   "source": [
    "data_with_all_col = output_analist.create_allucinations_columns(data_parsed, verbose = False)\n",
    "\n",
    "len1 = len([el for sublist in allucinations for el in sublist])\n",
    "len2 = len([el for sublist in data_with_all_col['heavy_allucinations'] for el in sublist])\n",
    "print(f\"There are {len2} heavy allucinations over {len1} allucinations -> {round(len2/len1*100,1)}%\")\n",
    "print(f\"{len([sublist for sublist in data_with_all_col['heavy_allucinations'] if len(sublist)>0])} sentences are impacted by allucination out of 681 -> {round(len2/681*100,1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### quando il modello è allucinato le performances peggiorano? Non solo quello è sbagliato, ma magari anche le altre fanno casino..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO allucinations -> f1:0.695427538103849 recall: 0.7049581005586593, precision 0.6861512319456244\n",
      "   allucinations -> f1:0.6286057692307692 recall: 0.6705128205128205, precision 0.5916289592760181\n"
     ]
    }
   ],
   "source": [
    "data_allucinated = data_with_all_col.filter(lambda x: len(x['heavy_allucinations'])>0)\n",
    "evaluator_allucinations = Evaluator(data=data_allucinated, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_allucinations.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'])\n",
    "evaluator_sentences_with_no_allucinations = Evaluator(data=data_with_all_col.filter(lambda x: len(x['heavy_allucinations'])==0), offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_sentences_with_no_allucinations.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'])\n",
    "print(f\"NO allucinations -> f1:{evaluator_sentences_with_no_allucinations.evaluation_table['f1']} recall: {evaluator_sentences_with_no_allucinations.evaluation_table['recall']}, precision {evaluator_sentences_with_no_allucinations.evaluation_table['precision']}\")\n",
    "print(f\"   allucinations -> f1:{evaluator_allucinations.evaluation_table['f1']} recall: {evaluator_allucinations.evaluation_table['recall']}, precision {evaluator_allucinations.evaluation_table['precision']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cerchiamo di capire quale sia essere l'impatto delle allucinazioni, cioè cosa succede se le togliamo dal computo e laciamo il resto invariato. Per esempio, se le estratte sono 'Pietro' 'ferrazzi' e la frase originale è 'Pietro sta programmando', normalmente conteggio 'ferrazzi' come FP. Qui voglio vedere se escludendolo dal conteggio le performance sono comunque peggiori. In altre parole, voglio vedere se un'allucinazione ha l'effetto di modifcare anche quello che succede intorno ad essa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo è il confronto tra avere allucinazioni e dopo averle tolte considerando soltanto le frasi per cui sono state generate allucinazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allucinations removed -> f1:0.6591661151555261 recall: 0.6604774535809018, precision 0.6578599735799208\n",
      "allucinations         -> f1:0.6286057692307692 recall: 0.6705128205128205, precision 0.5916289592760181\n"
     ]
    }
   ],
   "source": [
    "output_analist = OutputAnalist(tmp)\n",
    "data_allucinated_removed = output_analist.remove_allucinations_from_computation(data_allucinated)\n",
    "\n",
    "evaluator_marginal_allucinations_removed = Evaluator(data_allucinated_removed, offset=False, output_cleaner=None)\n",
    "evaluator_marginal_allucinations_removed.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'], already_parsed_inputs=True)\n",
    "print(f\"allucinations removed -> f1:{evaluator_marginal_allucinations_removed.evaluation_table['f1']} recall: {evaluator_marginal_allucinations_removed.evaluation_table['recall']}, precision {evaluator_marginal_allucinations_removed.evaluation_table['precision']}\")\n",
    "\n",
    "evaluator_marginal_allucinations = Evaluator(data_allucinated, offset=False, output_cleaner=None)\n",
    "evaluator_marginal_allucinations.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, similarity_types=['case', 'subset', 'superset'], already_parsed_inputs=False)\n",
    "print(f\"allucinations         -> f1:{evaluator_marginal_allucinations.evaluation_table['f1']} recall: {evaluator_marginal_allucinations.evaluation_table['recall']}, precision {evaluator_marginal_allucinations.evaluation_table['precision']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sembra che le allucinazioni rendano le performances leggermente peggiori, anche una volta che le marginallizzi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un allucinazione è un FP. \n",
    "H0: p( TN | allucinazione ) < p( TN | ! allucinazione)  [cioè, il fatto che ci siano delle allucinazioni è correlato alla miglior comprensione del contesto da parte del modello, che 'esagera' a generare positivi, ma non sbaglia più i negativi]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "da qui si vede che in realtà non cambia molto -> le allucinazioni non sembrano impattare in maniera importante il resto del testo generato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary_all_removed = evaluator_marginal_allucinations_removed.evaluation_table['evaluation'].sum() / evaluator_marginal_allucinations_removed.data.num_rows\n",
    "summary_NO_all = evaluator_sentences_with_no_allucinations.evaluation_table['evaluation'].sum() / evaluator_sentences_with_no_allucinations.data.num_rows\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['TP', 'FP', 'FN']\n",
    "width = 0.35\n",
    "x = range(len(labels))\n",
    "rects1 = ax.bar(x, summary_all_removed, width, label='allucinations removed')\n",
    "rects2 = ax.bar([i + width for i in x], summary_NO_all, width, label='NO all')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('TP, FP, FN (per sentence) for allucinated and non allucinated sentences')\n",
    "ax.set_xticks([i + width/2 for i in x])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vediamo cosa succede se tolgo dalle entità estratte quelle allucinate, e valuto le performances come se il modello quelle non le avesse estratte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light allucinations removed -> f1:0.6911910009880672\n",
      "heavy allucinations removed -> f1:0.6885841981668055 \n",
      "no allucination removed     -> f1:0.6870527980718536\n"
     ]
    }
   ],
   "source": [
    "output_analist = OutputAnalist(data_parsed)\n",
    "data_allucinated_removed_only_heavy = output_analist.remove_allucinations_from_computation(data_parsed, only_heavy=False)\n",
    "data_allucinated_removed_light = output_analist.remove_allucinations_from_computation(data_parsed, only_heavy=True)\n",
    "\n",
    "\n",
    "evaluator_light = Evaluator(data=data_allucinated_removed_light, offset=False, output_cleaner=None)\n",
    "evaluator_light.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                    words_level=True, \n",
    "                                    similarity_types=['case', 'subset', 'superset'],\n",
    "                                    already_parsed_inputs=True,\n",
    "                                    add_TP_FP_TN_FN_to_data=True)\n",
    "\n",
    "evaluator_heavy =  Evaluator(data_allucinated_removed_only_heavy, offset=False, output_cleaner=None)\n",
    "evaluator_heavy.generate_evaluation_table(similar_is_equal_threshold=100,\n",
    "                                                                   words_level=True, \n",
    "                                                                   similarity_types=['case', 'subset', 'superset'], \n",
    "                                                                   already_parsed_inputs=True,\n",
    "                                                                   add_TP_FP_TN_FN_to_data=True\n",
    "                                                                   )\n",
    "print(f\"light allucinations removed -> f1:{evaluator_light.evaluation_table['f1']}\")\n",
    "print(f\"heavy allucinations removed -> f1:{evaluator_heavy.evaluation_table['f1']} \")\n",
    "print(f\"no allucination removed     -> f1:{ evaluator.evaluation_table['f1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### guardiamo quante volte è successo che entità duplicate (perfect match) sono state estratte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_duplicated_ent: 2536, n_extracted_ent: 7125, n_extracted_deduplicated_ent: 4589\n",
      " the percentage of duplicated entities over the total of extracted is 35.6%\n",
      " the percentage of duplicated entities over the total of valid entities is 64.4%\n"
     ]
    }
   ],
   "source": [
    "res = output_analist.count_repetitions_in_extraction()\n",
    "print(f\"n_duplicated_ent: {res['n_duplicated_ent']}, n_extracted_ent: {res['n_extracted_ent']}, n_extracted_deduplicated_ent: {res['n_extracted_deduplicated_ent']}\\n the percentage of duplicated entities over the total of extracted is {round(res['n_duplicated_ent']/res['n_extracted_ent']*100,1)}%\\n the percentage of duplicated entities over the total of valid entities is {round(res['n_extracted_deduplicated_ent']/res['n_extracted_ent']*100,1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOINT ANALYSIS with seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.11k/1.11k [00:00<00:00, 6.98MB/s]\n",
      "Downloading data: 100%|██████████| 333k/333k [00:00<00:00, 743kB/s]\n",
      "Generating test split: 100%|██████████| 681/681 [00:00<00:00, 63478.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "checkpoint = \"ferrazzipietro/bestResults_LS_Llama-2-7b-hf_adapters_en.layer1_NoQuant_16_32_0.05_2_0.0002_3EpochsLast_eval\"\n",
    "data_seq2seq = load_dataset(checkpoint, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary_gen = output_analist.data.to_pandas()[['TP', 'FP', 'FN']].sum() / output_analist.data.num_rows\n",
    "summary_seq2seq = data_seq2seq.to_pandas()[['TP', 'FP', 'FN']].sum() / data_seq2seq.num_rows\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['TP', 'FP', 'FN']\n",
    "width = 0.35\n",
    "x = range(len(labels))\n",
    "rects1 = ax.bar(x, summary_gen, width, label='gen')\n",
    "rects2 = ax.bar([i + width for i in x], summary_seq2seq, width, label='s2s')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('TP, FP, FN (per sentence) for gen and seq2seq')\n",
    "ax.set_xticks([i + width/2 for i in x])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- togliere le allucinazioni fa fare le performance dell'altro s2s? Se sì, allora le allucinazioni sono IL problema, altrimenti è il modello\n",
    "- grafico lunghezza in token delle entità estratte e relativo f1\n",
    "- rapport tra allucinazioni e FP. \n",
    "- le allucinazioni da dove vengono fuori? Sono sinonimi, acronomi di entità vere? le all. sono risolvibili o no?\n",
    "- capita che si siano allcuniazioni intra parola (es. \"covid-20\" invece di \"covid-19\")?\n",
    "\n",
    "- test significatività f1 vs f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
