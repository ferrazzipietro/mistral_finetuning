{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 2.97k/2.97k [00:00<00:00, 4.54MB/s]\n",
      "Downloading data: 100%|██████████| 414k/414k [00:00<00:00, 594kB/s]\n",
      "Downloading data: 100%|██████████| 527k/527k [00:00<00:00, 1.23MB/s]s]\n",
      "Downloading data: 100%|██████████| 69.8k/69.8k [00:00<00:00, 201kB/s]]\n",
      "Downloading data: 100%|██████████| 4.45M/4.45M [00:00<00:00, 6.85MB/s]\n",
      "Downloading data: 100%|██████████| 394k/394k [00:00<00:00, 840kB/s]/s]\n",
      "Downloading data: 100%|██████████| 545k/545k [00:00<00:00, 984kB/s]/s]\n",
      "Downloading data: 100%|██████████| 76.9k/76.9k [00:00<00:00, 165kB/s]]\n",
      "Downloading data: 100%|██████████| 3.86M/3.86M [00:00<00:00, 5.74MB/s]\n",
      "Downloading data: 100%|██████████| 594k/594k [00:00<00:00, 1.20MB/s]s]\n",
      "Downloading data: 100%|██████████| 196k/196k [00:00<00:00, 494kB/s]/s]\n",
      "Downloading data: 100%|██████████| 64.5k/64.5k [00:00<00:00, 183kB/s]s]\n",
      "Downloading data: 100%|██████████| 2.76M/2.76M [00:00<00:00, 4.59MB/s]]\n",
      "Downloading data: 100%|██████████| 373k/373k [00:00<00:00, 604kB/s]t/s]\n",
      "Downloading data: 100%|██████████| 563k/563k [00:00<00:00, 1.22MB/s]/s]\n",
      "Downloading data: 100%|██████████| 80.4k/80.4k [00:00<00:00, 221kB/s]s]\n",
      "Downloading data: 100%|██████████| 37.0M/37.0M [00:04<00:00, 7.60MB/s]]\n",
      "Downloading data: 100%|██████████| 385k/385k [00:00<00:00, 975kB/s]/it]\n",
      "Downloading data: 100%|██████████| 534k/534k [00:00<00:00, 1.13MB/s]it]\n",
      "Downloading data: 100%|██████████| 81.7k/81.7k [00:00<00:00, 194kB/s]t]\n",
      "Downloading data: 100%|██████████| 190M/190M [00:22<00:00, 8.52MB/s]/s]\n",
      "Downloading data files: 100%|██████████| 20/20 [00:36<00:00,  1.82s/it]\n",
      "Extracting data files: 100%|██████████| 20/20 [00:00<00:00, 1037.71it/s]\n",
      "Generating en.layer1 split: 100%|██████████| 1519/1519 [00:00<00:00, 109405.98 examples/s]\n",
      "Generating en.layer2 split: 100%|██████████| 2872/2872 [00:00<00:00, 255722.01 examples/s]\n",
      "Generating en.layer2.validation split: 100%|██████████| 333/333 [00:00<00:00, 155743.00 examples/s]\n",
      "Generating en.layer3 split: 100%|██████████| 9778/9778 [00:00<00:00, 582373.47 examples/s]\n",
      "Generating es.layer1 split: 100%|██████████| 1133/1133 [00:00<00:00, 160779.05 examples/s]\n",
      "Generating es.layer2 split: 100%|██████████| 2346/2346 [00:00<00:00, 340690.99 examples/s]\n",
      "Generating es.layer2.validation split: 100%|██████████| 260/260 [00:00<00:00, 161798.08 examples/s]\n",
      "Generating es.layer3 split: 100%|██████████| 1875/1875 [00:00<00:00, 167529.13 examples/s]\n",
      "Generating eu.layer1 split: 100%|██████████| 3125/3125 [00:00<00:00, 297640.62 examples/s]\n",
      "Generating eu.layer2 split: 100%|██████████| 1593/1593 [00:00<00:00, 499852.34 examples/s]\n",
      "Generating eu.layer2.validation split: 100%|██████████| 467/467 [00:00<00:00, 172835.08 examples/s]\n",
      "Generating eu.layer3 split: 100%|██████████| 1231/1231 [00:00<00:00, 135555.89 examples/s]\n",
      "Generating it.layer1 split: 100%|██████████| 1145/1145 [00:00<00:00, 119759.56 examples/s]\n",
      "Generating it.layer2 split: 100%|██████████| 2435/2435 [00:00<00:00, 102225.35 examples/s]\n",
      "Generating it.layer2.validation split: 100%|██████████| 274/274 [00:00<00:00, 48037.09 examples/s]\n",
      "Generating it.layer3 split: 100%|██████████| 10212/10212 [00:00<00:00, 96567.52 examples/s]\n",
      "Generating fr.layer1 split: 100%|██████████| 1108/1108 [00:00<00:00, 76518.73 examples/s]\n",
      "Generating fr.layer2 split: 100%|██████████| 2388/2388 [00:00<00:00, 305888.04 examples/s]\n",
      "Generating fr.layer2.validation split: 100%|██████████| 292/292 [00:00<00:00, 143917.36 examples/s]\n",
      "Generating fr.layer3 split: 100%|██████████| 25739/25739 [00:00<00:00, 42288.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from dotenv import dotenv_values\n",
    "from utils.data_generation import DataGenerator \n",
    "from transformers import AutoTokenizer\n",
    "from config import config\n",
    "#from utils.data_preprocessor import DataPreprocessor\n",
    "\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "#DATASET_CHEKPOINT = dotenv_values(\".env.base\")['DATASET_CHEKPOINT']\n",
    "hf_e3c = load_dataset(\"ferrazzipietro/e3c-sentences\", token = HF_TOKEN)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.BASE_MODEL_CHECKPOINT, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_h3c = hf_e3c.to_pandas()\n",
    "#pd_h3c['entities'] = pd_h3c['entities'].apply(lambda x: ent['text'] for ent in x)\n",
    "\n",
    "data_ft = pd.DataFrame(columns=['document_id', 'layer', 'prompt', 'answer', 'concatenation', 'original_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token\n",
    "tokenizer.bos_token\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.one_shot_example = \"\"\"\n",
    "[INST]\n",
    "Extract the entities contained in the text and the offset, i.e. the position of that entity in the string. Extract only entities contained in the text.\n",
    "{instruction_on_response_format}\n",
    "Text: <<<{example_query}>>> [/INST]\n",
    "{example_response}\n",
    "\"\"\"\n",
    "        self.one_shot_example_no_offset = \"\"\"\n",
    "[INST]\n",
    "Extract the entities contained in the text. Extract only entities contained in the text.\n",
    "{instruction_on_response_format}\n",
    "Text: <<<{example_query}>>> [/INST]\n",
    "{example_response}\n",
    "\"\"\"\n",
    "\n",
    "        self.prompt_template = \"\"\"\n",
    "[INST]\n",
    "Extract the entities contained in the text and the offset, i.e. the position of that entity in the string. Extract only entities contained in the text.\n",
    "{instruction_on_response_format}\n",
    "Text: <<{query}>>> [/INST]\n",
    "\"\"\"\n",
    "\n",
    "        self.prompt_template_no_offset = \"\"\"\n",
    "<s>\n",
    "[INST]\n",
    "Extract the entities contained in the text. Extract only entities contained in the text.\n",
    "{instruction_on_response_format}\n",
    "Text: <<{query}>>> [/INST]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    def _formatting_prompt(self, task: str, input: str, instruction_on_response_format:str, n_shots:int, offset: bool, tokenizer=None, output:str='', list_of_examples: [str]=[], list_of_responses:[str]=[]) -> str:\n",
    "        \"\"\"\n",
    "        Format the input and output into a prompt for the finetuning\n",
    "\n",
    "        Args:\n",
    "            task: the task for which the prompt is generated, either 'finetuning' or 'inference'\n",
    "            input: the input text\n",
    "            instruction_on_response_format: the instruction on the response format. E.g. \"The response must be a list of dictionaries, where each dictionary contains the keys 'text' and 'offset'\"\n",
    "            n_shots: the number of examples to provide as few shot prompting\n",
    "            offset: whether to require the offset in the response\n",
    "            tokenizer: the tokenizer to use\n",
    "            output: the output text\n",
    "            list_of_examples: the list of examples to provide as few shot prompting\n",
    "            list_of_responses: the list of responses to provide as few shot prompting\n",
    "\n",
    "        Returns:\n",
    "            the formatted prompt\n",
    "        \"\"\"\n",
    "        if task == 'finetuning':\n",
    "            if n_shots > 0:\n",
    "                raise ValueError(\"The numebr of shot in generating prompts for the finetuning must be 0\")\n",
    "            if tokenizer is None:\n",
    "                raise ValueError(\"The tokenizer must be provided\")\n",
    "            if output == '':\n",
    "                raise ValueError(\"The output must be provided when generating prompts for the finetuning\")\n",
    "\n",
    "        elif task == 'inference':\n",
    "            if output != '':\n",
    "                raise ValueError(\"The output must be an empty string when generating prompts for the inference\")\n",
    "        else:\n",
    "            raise ValueError(\"The task must be either 'finetuning' or 'inference'\")\n",
    "\n",
    "\n",
    "        if len(list_of_examples) != len(list_of_responses):\n",
    "            raise ValueError(\"The number of examples and responses must be the same\")\n",
    "        if n_shots != len(list_of_examples):\n",
    "            raise ValueError(\"The number of examples and shots must be the same\")\n",
    "        if n_shots != len(list_of_responses):\n",
    "            raise ValueError(\"The number of responses and shots must be the same\")\n",
    "        \n",
    "        if offset:\n",
    "            base_prompt = self.prompt_template.format(\n",
    "                instruction_on_response_format=instruction_on_response_format, \n",
    "                query=input) \n",
    "            one_shot_example = self.one_shot_example\n",
    "        else:\n",
    "            base_prompt = self.prompt_template_no_offset.format(\n",
    "                instruction_on_response_format=instruction_on_response_format, \n",
    "                query=input)\n",
    "            one_shot_example = self.one_shot_example_no_offset\n",
    "            \n",
    "        prompt = ''\n",
    "        for shot_example in range(n_shots):\n",
    "            prompt += one_shot_example.format(\n",
    "                instruction_on_response_format=instruction_on_response_format, \n",
    "                example_query=list_of_examples[shot_example], \n",
    "                example_response=list_of_responses[shot_example])\n",
    "        \n",
    "        bos_token = tokenizer.bos_token\n",
    "        eos_token = ''\n",
    "        if task == 'finetuning':\n",
    "            eos_token = tokenizer.eos_token\n",
    "        prompt = bos_token + prompt + base_prompt + output + eos_token\n",
    "                            \n",
    "        return prompt\n",
    "\n",
    "\n",
    "    def _format_entities_in_response(self, entities_list: [dict], offset: bool) -> str:\n",
    "        \"\"\"\n",
    "        Format the response into a string\n",
    "\n",
    "        Args:\n",
    "            response: the response to format\n",
    "            offset: whether to require the offset in the response\n",
    "\n",
    "        Returns:\n",
    "            the formatted response\n",
    "        \"\"\"\n",
    "        formatted_response = '['\n",
    "        if offset:\n",
    "            for entity in entities_list:\n",
    "                formatted_response = formatted_response + '{\"entity\": \"' + entity['text'] + f'\", \"offset\": {entity[\"offsets\"]}' + '}, '\n",
    "        else:\n",
    "            for entity in entities_list: \n",
    "                formatted_response = formatted_response + '{\"entity\": \"' + entity['text'] + '\"}, '\n",
    "        formatted_response = formatted_response[:-2]\n",
    "        formatted_response = formatted_response + '] '\n",
    "        return formatted_response\n",
    "    \n",
    "    def _apply_to_one_example(self, example, task: str, instruction_on_response_format:str, n_shots:int, offset: bool, tokenizer=None, list_of_examples: [str]=[], list_of_responses:[str]=[]) -> dict:\n",
    "        \"\"\"\n",
    "        Apply the data preprocessing to one example\n",
    "\n",
    "        Args:\n",
    "            example: the example (data row) to preprocess\n",
    "            task: the task for which the prompt is generated, either 'finetuning' or 'inference'\n",
    "            instruction_on_response_format: the instruction on the response format. E.g. \"The response must be a list of dictionaries, where each dictionary contains the keys 'text' and 'offset'\"\n",
    "            n_shots: the number of examples to provide as few shot prompting\n",
    "            offset: whether to require the offset in the response\n",
    "            tokenizer: the tokenizer to use\n",
    "            list_of_examples: the list of examples to provide as few shot prompting\n",
    "            list_of_responses: the list of responses to provide as few shot prompting\n",
    "\n",
    "        Returns:\n",
    "            the preprocessed example\n",
    "        \"\"\"\n",
    "        output = self._format_entities_in_response(entities_list=example['entities'], offset=offset)\n",
    "        prompt = self._formatting_prompt(task, input=example['sentence'], instruction_on_response_format=instruction_on_response_format, n_shots=n_shots, offset=offset, tokenizer=tokenizer, output=output, list_of_examples=list_of_examples, list_of_responses=list_of_responses)\n",
    "        example['prompt'] = prompt\n",
    "        return example\n",
    "    \n",
    "    def apply(self, data: Dataset):\n",
    "        \"\"\"\n",
    "        Apply the data preprocessing to the dataset\n",
    "\n",
    "        Args:\n",
    "            data: the dataset to preprocess\n",
    "\n",
    "        Returns:\n",
    "            the preprocessed dataset\n",
    "        \"\"\"\n",
    "        data = data.map(self._preprocess_function, batched=True)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '7509', 'offsets': [2663, 2671], 'role': '', 'semantic_type_id': '', 'text': 'collapse', 'type': 'EVENT'}, {'id': '7524', 'offsets': [2702, 2712], 'role': '', 'semantic_type_id': '', 'text': 'dobutamine', 'type': 'EVENT'}, {'id': '7806', 'offsets': [2651, 2671], 'role': '', 'semantic_type_id': 'C0948268', 'text': 'hemodynamic collapse', 'type': 'CLINENTITY'}, {'id': '8051', 'offsets': [2629, 2640], 'role': 'PATIENT', 'semantic_type_id': '', 'text': 'the patient', 'type': 'ACTOR'}, {'id': '8089', 'offsets': [2597, 2627], 'role': '', 'semantic_type_id': '', 'text': 'immediate postoperative period', 'type': 'TIMEX3'}]\n",
      "[{\"entity\": \"collapse\", \"offset\": [2663, 2671]}, {\"entity\": \"dobutamine\", \"offset\": [2702, 2712]}, {\"entity\": \"hemodynamic collapse\", \"offset\": [2651, 2671]}, {\"entity\": \"the patient\", \"offset\": [2629, 2640]}, {\"entity\": \"immediate postoperative period\", \"offset\": [2597, 2627]}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[{\"entity\": \"collapse\", \"offset\": [2663, 2671]}, {\"entity\": \"dobutamine\", \"offset\": [2702, 2712]}, {\"entity\": \"hemodynamic collapse\", \"offset\": [2651, 2671]}, {\"entity\": \"the patient\", \"offset\": [2629, 2640]}, {\"entity\": \"immediate postoperative period\", \"offset\": [2597, 2627]}]'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hf_e3c['en.layer1']['entities'][100])\n",
    "data_preprocessor = DataPreprocessor()\n",
    "data_preprocessor._format_entities_in_response(hf_e3c['en.layer1']['entities'][100], offset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hormonal study and dynamic biochemical tests performed indicated ECS.',\n",
       " 'entities': [{'id': '1704',\n",
       "   'offsets': [208, 213],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'study',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1719',\n",
       "   'offsets': [238, 243],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'tests',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1734',\n",
       "   'offsets': [254, 263],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'indicated',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1749',\n",
       "   'offsets': [264, 267],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'ECS',\n",
       "   'type': 'EVENT'}],\n",
       " 'original_text': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia. Hormonal study and dynamic biochemical tests performed indicated ECS. Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases. Somatostatin receptor scintigraphy has shown an increased uptake in the parotid gland and mild expression in liver metastasis. The patient underwent right parotidectomy, and histopathologic examination confirmed ACC. Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide. Despite chemotherapy onset, a rapid disease progression and clinical course deterioration was observed.\\r\\n',\n",
       " 'original_id': 'EN101783',\n",
       " 'prompt': '<s>\\n[INST]\\nExtract the entities contained in the text and the offset, i.e. the position of that entity in the string. Extract only entities contained in the text.\\nThe response must be a list of dictionaries, where each dictionary contains the keys \"text\" and \"offset\"\\nText: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST]\\n[{\"entity\": \"study\", \"offset\": [208, 213]}, {\"entity\": \"tests\", \"offset\": [238, 243]}, {\"entity\": \"indicated\", \"offset\": [254, 263]}, {\"entity\": \"ECS\", \"offset\": [264, 267]}]</s>'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessor = DataPreprocessor()\n",
    "tmp = data_preprocessor._apply_to_one_example(hf_e3c['en.layer1'][0], task='finetuning', instruction_on_response_format='The response must be a list of dictionaries, where each dictionary contains the keys \"text\" and \"offset\"', n_shots=0, offset=True, tokenizer=tokenizer, list_of_examples=[], list_of_responses=[])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_shot_example = 'We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.'\n",
    "second_shot_example = 'Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.'\n",
    "instruction_on_response_format = 'Return the result in a json format.'\n",
    "first_response = '[{\"entity\": \"present\", \"offset\": [3, 10]}, {\"entity\": \"history\", \"offset\": [48, 55]}, {\"entity\": \"enlargement\", \"offset\": [67, 78]}]'\n",
    "second_response = '[{\"entity\": \"presented\", \"offset\": [39, 48]}, {\"entity\": \"refusal\", \"offset\": [95, 102]}, {\"entity\": \"bear\", \"offset\": [106, 110]}, {\"entity\": \"peaks\", \"offset\": [159, 164]}]'\n",
    "input = \"A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia\"\n",
    "output = '[{\"entity\": \"hypertension\", \"offset\": [13, 25]}, {\"entity\": \"dyslipidemia\", \"offset\": [30, 42]}, {\"entity\": \"diabetes mellitus\", \"offset\": [74, 91]}, {\"entity\": \"hypokalemia\", \"offset\": [143, 154]}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "[INST]\n",
      "Extract the entities contained in the text and the offset, i.e. the position of that entity in the string. Extract only entities contained in the text.\n",
      "Return the result in a json format.\n",
      "Text: <<A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia>>> [/INST]\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "data_preprocessor = DataPreprocessor()\n",
    "tmp = data_preprocessor.formatting_prompt(input=input, task='finetuning', instruction_on_response_format=instruction_on_response_format, offset=True, n_shots=0, tokenizer = tokenizer)#, output='', list_of_examples=[first_shot_example, second_shot_example], list_of_responses=[first_response, second_response])\n",
    "print(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
