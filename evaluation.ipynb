{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from config import evaluation_params_all\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_threshold_list = evaluation_params_all.similar_is_equal_threshold_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL NoQuant FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor8_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n",
      "FILE:  data/mistral/noQuant/maxNewTokensFactor2_nShotsInference0_mistral-7b-instruct-v0.2_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "Extra data: line 1 column 281 (char 280)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_threshold_list = [100]\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/noQuant/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "output_cleaner = OutputCleaner(verbose=False)\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if file.strip().endswith('0.0008.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "        # print(f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\")\n",
    "        evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "        try:\n",
    "            evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                                words_level=True, \n",
    "                                                similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "            evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "        #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "        # print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago.',\n",
       " 'entities': \"[{'id': '6759', 'offsets': array([22, 34]), 'role': '', 'semantic_type_id': '', 'text': 'hypertensive', 'type': 'EVENT'}\\n {'id': '6774', 'offsets': array([36, 48]), 'role': '', 'semantic_type_id': '', 'text': 'hospitalized', 'type': 'EVENT'}\\n {'id': '7666', 'offsets': array([61, 74]), 'role': '', 'semantic_type_id': 'C0149736', 'text': 'cervical mass', 'type': 'CLINENTITY'}\\n {'id': '7820', 'offsets': array([55, 74]), 'role': '', 'semantic_type_id': '', 'text': 'large cervical mass', 'type': 'BODYPART'}\\n {'id': '7988', 'offsets': array([ 0, 20]), 'role': 'PATIENT', 'semantic_type_id': '', 'text': 'A 50-years-old woman', 'type': 'ACTOR'}\\n {'id': '8071', 'offsets': array([84, 92]), 'role': '', 'semantic_type_id': '', 'text': '30 years', 'type': 'TIMEX3'}]\",\n",
       " 'original_text': 'A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago. In the family history, her mother, sisters and cousins underwent a surgery for MNG. Despite of the large volume of the mass, the patient never described signs of cervical compression whatsoever respiratory, digestive, laryngeal, vascular or neurologic signs. She never suffered from thyroid dysfunction. Her neck was deformed by the voluminous formation classified grade III according to the WHO modified classification. The mass took the front and the two sides of the neck. Its surface was embossed and covered by a thin normal skin. There were some veins of the collateral circulation limited to the neck. The goiter measured 18 x 11 cm. The mass was firm, painless, and mobile with the swallowing movements. Lymphadenopathy research was difficult and found no palpable lymph nodes. The laboratory tests (T 3, T 4 and TSH) were normal. Thoracic radiography showed a large cervical opacity roughly round and strewn with microcalcifications associated with a right eccentricity of the trachea. Cervical and chest CT revealed the presence of a partially calcified thyroid mass slightly plunging in the anterior mediastinum. It took heterogeneously the contrast and then evocate a large MNG. The trachea was surrounded by the goiter, slightly narrowed and right deviated as well as the lower part of the larynx. The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward. The patient underwent a surgery for her enormous MNG slightly plunging in the mediastinum. Endotracheal intubation was relatively easy by the laryngoscope. The incision performed was a Kocher cervicotomy. There was a multinodular, hypervascularized goiter. Its lower end plunges behind the sternal manubrium. The larynx was deviated towards the right side. The total thyroidectomy was performed in two steps: initially a right lobo-isthmectomy, then the left lobectomy. The retrosternal part of the goiter was released using the finger by the same incision. Both recurrent laryngeal nerves (RLN) were not identified because of the hemorrhage. One parathyroid gland was accidently devascularized and was autotransplanted to the ipsilateral sternocleidomastoid muscle. The operation was finished by double aspiration drainage. In the first hours after surgery, the patient developed a large cervical hematoma. She was readmitted to the operating room, and after evacuation of the hematoma there was no vessels bleeding. The operation was completed with a double suction drainage. In the immediate postoperative period, the patient developed hemodynamic collapse requiring the introduction of dobutamine. After 48 hours of hemodynamic support, the blood pressure stabilized and dobutamine was stopped. Histological study concluded in multinodular colloid goiter. The patient was discharged from the hospital after 20 days in good health.\\r\\n',\n",
       " 'original_id': 'EN100067',\n",
       " 'prompt': '<s>[INST]A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago.[/INST][{\"entity\": \"hypertensive\"}, {\"entity\": \"hospitalized\"}, {\"entity\": \"cervical mass\"}, {\"entity\": \"large cervical mass\"}, {\"entity\": \"A 50-years-old woman\"}, {\"entity\": \"30 years\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST]  <<A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago.>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"hypertensive\"}, {\"entity\": \"hospitalized\"}, {\"entity\": \"cervical mass\"}, {\"entity\": \"large cervical mass\"}, {\"entity\": \"A 50-years-old woman\"}, {\"entity\": \"30 years\"}] </s>',\n",
       " 'model_responses': \"It seems like you're describing a woman who is currently 50 years old and was hospitalized three decades ago due to a large\",\n",
       " 'model_output': '[]'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, similar_is_equal_threshold, f1_score, precision, recall]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 100].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_threshold_list = [100]\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/noInstr_8bit/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "output_cleaner = OutputCleaner(verbose=False)\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if file.strip().endswith('0.0008.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "        # print(f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\")\n",
    "        evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "        try:\n",
    "            evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                                words_level=True, \n",
    "                                                similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "            evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "        # print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.649890</td>\n",
       "      <td>0.602338</td>\n",
       "      <td>0.705594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.639212</td>\n",
       "      <td>0.634080</td>\n",
       "      <td>0.644426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.638999</td>\n",
       "      <td>0.583906</td>\n",
       "      <td>0.705571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.635105</td>\n",
       "      <td>0.597381</td>\n",
       "      <td>0.677914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.626520</td>\n",
       "      <td>0.596308</td>\n",
       "      <td>0.659957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.580823</td>\n",
       "      <td>0.556810</td>\n",
       "      <td>0.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.574688</td>\n",
       "      <td>0.593377</td>\n",
       "      <td>0.557141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.571382</td>\n",
       "      <td>0.595527</td>\n",
       "      <td>0.549118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.559085</td>\n",
       "      <td>0.555629</td>\n",
       "      <td>0.562583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.552100</td>\n",
       "      <td>0.578281</td>\n",
       "      <td>0.528186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.540846</td>\n",
       "      <td>0.624475</td>\n",
       "      <td>0.476970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.498482</td>\n",
       "      <td>0.543720</td>\n",
       "      <td>0.460194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.493319</td>\n",
       "      <td>0.506590</td>\n",
       "      <td>0.480726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.488295</td>\n",
       "      <td>0.495600</td>\n",
       "      <td>0.481203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.483162</td>\n",
       "      <td>0.502771</td>\n",
       "      <td>0.465024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.465817</td>\n",
       "      <td>0.550430</td>\n",
       "      <td>0.403752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/mistral/noInstr_8bit/maxNewTokensFactor8_...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.465539</td>\n",
       "      <td>0.453627</td>\n",
       "      <td>0.478094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  \\\n",
       "7   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "1   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "6   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "5   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "13  data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "8   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "16  data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "15  data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "2   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "4   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "12  data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "11  data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "9   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "3   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "0   data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "10  data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "14  data/mistral/noInstr_8bit/maxNewTokensFactor8_...   \n",
       "\n",
       "    similar_is_equal_threshold  f1_score  precision    recall  \n",
       "7                          100  0.649890   0.602338  0.705594  \n",
       "1                          100  0.639212   0.634080  0.644426  \n",
       "6                          100  0.638999   0.583906  0.705571  \n",
       "5                          100  0.635105   0.597381  0.677914  \n",
       "13                         100  0.626520   0.596308  0.659957  \n",
       "8                          100  0.580823   0.556810  0.607000  \n",
       "16                         100  0.574688   0.593377  0.557141  \n",
       "15                         100  0.571382   0.595527  0.549118  \n",
       "2                          100  0.559085   0.555629  0.562583  \n",
       "4                          100  0.552100   0.578281  0.528186  \n",
       "12                         100  0.540846   0.624475  0.476970  \n",
       "11                         100  0.498482   0.543720  0.460194  \n",
       "9                          100  0.493319   0.506590  0.480726  \n",
       "3                          100  0.488295   0.495600  0.481203  \n",
       "0                          100  0.483162   0.502771  0.465024  \n",
       "10                         100  0.465817   0.550430  0.403752  \n",
       "14                         100  0.465539   0.453627  0.478094  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 100].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA 13B 4bit FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing_params_llama as postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_threshold_list = [100]\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/13B_4bit_FT/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "output_cleaner = OutputCleaner(verbose=False)\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if file.strip().endswith('0.0008.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "        # print(f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\")\n",
    "        evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "        evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                            words_level=True, \n",
    "                                            similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "        #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "        evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "        # print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.701161</td>\n",
       "      <td>0.746585</td>\n",
       "      <td>0.660948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.699127</td>\n",
       "      <td>0.742332</td>\n",
       "      <td>0.660673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.696993</td>\n",
       "      <td>0.726827</td>\n",
       "      <td>0.669513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.695955</td>\n",
       "      <td>0.746409</td>\n",
       "      <td>0.651890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.732376</td>\n",
       "      <td>0.660495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.689118</td>\n",
       "      <td>0.717028</td>\n",
       "      <td>0.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.685441</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.672050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.681304</td>\n",
       "      <td>0.688892</td>\n",
       "      <td>0.673880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.680618</td>\n",
       "      <td>0.685274</td>\n",
       "      <td>0.676024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.680400</td>\n",
       "      <td>0.689366</td>\n",
       "      <td>0.671664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.674146</td>\n",
       "      <td>0.685475</td>\n",
       "      <td>0.663184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.670785</td>\n",
       "      <td>0.683175</td>\n",
       "      <td>0.658836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.648507</td>\n",
       "      <td>0.777455</td>\n",
       "      <td>0.556248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.648104</td>\n",
       "      <td>0.765802</td>\n",
       "      <td>0.561765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.646816</td>\n",
       "      <td>0.765112</td>\n",
       "      <td>0.560202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.643847</td>\n",
       "      <td>0.786310</td>\n",
       "      <td>0.545088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.641329</td>\n",
       "      <td>0.658668</td>\n",
       "      <td>0.624880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.640984</td>\n",
       "      <td>0.774693</td>\n",
       "      <td>0.546637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.640460</td>\n",
       "      <td>0.765173</td>\n",
       "      <td>0.550702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.639858</td>\n",
       "      <td>0.647040</td>\n",
       "      <td>0.632835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.636783</td>\n",
       "      <td>0.658050</td>\n",
       "      <td>0.616848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.635164</td>\n",
       "      <td>0.656607</td>\n",
       "      <td>0.615077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.634536</td>\n",
       "      <td>0.654520</td>\n",
       "      <td>0.615736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.634370</td>\n",
       "      <td>0.734537</td>\n",
       "      <td>0.558243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.633818</td>\n",
       "      <td>0.738854</td>\n",
       "      <td>0.554929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.633654</td>\n",
       "      <td>0.732711</td>\n",
       "      <td>0.558191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>0.642637</td>\n",
       "      <td>0.624036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.632291</td>\n",
       "      <td>0.737603</td>\n",
       "      <td>0.553294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.631171</td>\n",
       "      <td>0.732255</td>\n",
       "      <td>0.554610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.622437</td>\n",
       "      <td>0.735375</td>\n",
       "      <td>0.539571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.611843</td>\n",
       "      <td>0.692840</td>\n",
       "      <td>0.547802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.610803</td>\n",
       "      <td>0.697639</td>\n",
       "      <td>0.543191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.605781</td>\n",
       "      <td>0.698097</td>\n",
       "      <td>0.535030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.583366</td>\n",
       "      <td>0.695806</td>\n",
       "      <td>0.502211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.579733</td>\n",
       "      <td>0.690207</td>\n",
       "      <td>0.499744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.577159</td>\n",
       "      <td>0.684877</td>\n",
       "      <td>0.498719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.452696</td>\n",
       "      <td>0.810620</td>\n",
       "      <td>0.314036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.452252</td>\n",
       "      <td>0.773668</td>\n",
       "      <td>0.319513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.448733</td>\n",
       "      <td>0.809569</td>\n",
       "      <td>0.310389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.447607</td>\n",
       "      <td>0.778578</td>\n",
       "      <td>0.314089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.447302</td>\n",
       "      <td>0.824536</td>\n",
       "      <td>0.306895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.446806</td>\n",
       "      <td>0.820488</td>\n",
       "      <td>0.306990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.446786</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.446200</td>\n",
       "      <td>0.805516</td>\n",
       "      <td>0.308561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.445671</td>\n",
       "      <td>0.806851</td>\n",
       "      <td>0.307860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.443858</td>\n",
       "      <td>0.811776</td>\n",
       "      <td>0.305429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.441396</td>\n",
       "      <td>0.819891</td>\n",
       "      <td>0.301987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.438473</td>\n",
       "      <td>0.812223</td>\n",
       "      <td>0.300292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.437670</td>\n",
       "      <td>0.778855</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.436865</td>\n",
       "      <td>0.822256</td>\n",
       "      <td>0.297450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.432882</td>\n",
       "      <td>0.815976</td>\n",
       "      <td>0.294579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.416985</td>\n",
       "      <td>0.770468</td>\n",
       "      <td>0.285843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.403411</td>\n",
       "      <td>0.759659</td>\n",
       "      <td>0.274624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.392332</td>\n",
       "      <td>0.758351</td>\n",
       "      <td>0.264615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  \\\n",
       "45  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "9   data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "26  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "46  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "10  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "29  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "40  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "14  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "43  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "42  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "24  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "19  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "35  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "36  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "30  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "52  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "39  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "33  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "28  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "20  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "31  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "7   data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "12  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "47  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "51  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "53  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "15  data/llama/13B_4bit_FT/maxNewTokensFactor8_nSh...   \n",
       "1   data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "3   data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "37  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "17  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "2   data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "13  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "49  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "5   data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "27  data/llama/13B_4bit_FT/maxNewTokensFactor4_nSh...   \n",
       "21  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "0   data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "25  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "11  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "38  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "41  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "32  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "48  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "8   data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "16  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "22  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "18  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "34  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "6   data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "23  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "4   data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "50  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "44  data/llama/13B_4bit_FT/maxNewTokensFactor2_nSh...   \n",
       "\n",
       "    similar_is_equal_threshold  f1_score  precision    recall  \n",
       "45                         100  0.701161   0.746585  0.660948  \n",
       "9                          100  0.699127   0.742332  0.660673  \n",
       "26                         100  0.696993   0.726827  0.669513  \n",
       "46                         100  0.695955   0.746409  0.651890  \n",
       "10                         100  0.694581   0.732376  0.660495  \n",
       "29                         100  0.689118   0.717028  0.663300  \n",
       "40                         100  0.685441   0.699376  0.672050  \n",
       "14                         100  0.681304   0.688892  0.673880  \n",
       "43                         100  0.680618   0.685274  0.676024  \n",
       "42                         100  0.680400   0.689366  0.671664  \n",
       "24                         100  0.674146   0.685475  0.663184  \n",
       "19                         100  0.670785   0.683175  0.658836  \n",
       "35                         100  0.648507   0.777455  0.556248  \n",
       "36                         100  0.648104   0.765802  0.561765  \n",
       "30                         100  0.646816   0.765112  0.560202  \n",
       "52                         100  0.643847   0.786310  0.545088  \n",
       "39                         100  0.641329   0.658668  0.624880  \n",
       "33                         100  0.640984   0.774693  0.546637  \n",
       "28                         100  0.640460   0.765173  0.550702  \n",
       "20                         100  0.639858   0.647040  0.632835  \n",
       "31                         100  0.636783   0.658050  0.616848  \n",
       "7                          100  0.635164   0.656607  0.615077  \n",
       "12                         100  0.634536   0.654520  0.615736  \n",
       "47                         100  0.634370   0.734537  0.558243  \n",
       "51                         100  0.633818   0.738854  0.554929  \n",
       "53                         100  0.633654   0.732711  0.558191  \n",
       "15                         100  0.633200   0.642637  0.624036  \n",
       "1                          100  0.632291   0.737603  0.553294  \n",
       "3                          100  0.631171   0.732255  0.554610  \n",
       "37                         100  0.622437   0.735375  0.539571  \n",
       "17                         100  0.611843   0.692840  0.547802  \n",
       "2                          100  0.610803   0.697639  0.543191  \n",
       "13                         100  0.605781   0.698097  0.535030  \n",
       "49                         100  0.583366   0.695806  0.502211  \n",
       "5                          100  0.579733   0.690207  0.499744  \n",
       "27                         100  0.577159   0.684877  0.498719  \n",
       "21                         100  0.452696   0.810620  0.314036  \n",
       "0                          100  0.452252   0.773668  0.319513  \n",
       "25                         100  0.448733   0.809569  0.310389  \n",
       "11                         100  0.447607   0.778578  0.314089  \n",
       "38                         100  0.447302   0.824536  0.306895  \n",
       "41                         100  0.446806   0.820488  0.306990  \n",
       "32                         100  0.446786   0.815385  0.307692  \n",
       "48                         100  0.446200   0.805516  0.308561  \n",
       "8                          100  0.445671   0.806851  0.307860  \n",
       "16                         100  0.443858   0.811776  0.305429  \n",
       "22                         100  0.441396   0.819891  0.301987  \n",
       "18                         100  0.438473   0.812223  0.300292  \n",
       "34                         100  0.437670   0.778855  0.304348  \n",
       "6                          100  0.436865   0.822256  0.297450  \n",
       "23                         100  0.432882   0.815976  0.294579  \n",
       "4                          100  0.416985   0.770468  0.285843  \n",
       "50                         100  0.403411   0.759659  0.274624  \n",
       "44                         100  0.392332   0.758351  0.264615  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 100].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                                        words_level=True, \n",
    "                                                        similarity_types=['case', 'stop_words', 'subset', 'superset'])#,'leveshtein'])\n",
    "                    # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>65</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "482  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "480  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "478  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "485  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "484  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "..                                                 ...               ...   \n",
       "598  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "599  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "600  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "601  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "595  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "482                          70  0.635337   0.614908  0.657171  \n",
       "480                          80  0.635337   0.614908  0.657171  \n",
       "478                          90  0.635337   0.614908  0.657171  \n",
       "485                         100  0.635337   0.614908  0.657171  \n",
       "484                          60  0.635337   0.614908  0.657171  \n",
       "..                          ...       ...        ...       ...  \n",
       "598                          75  0.008748   0.033635  0.005028  \n",
       "599                          70  0.008748   0.033635  0.005028  \n",
       "600                          65  0.008748   0.033635  0.005028  \n",
       "601                          60  0.008748   0.033635  0.005028  \n",
       "595                          90  0.008748   0.033635  0.005028  \n",
       "\n",
       "[621 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 60].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation_results.to_csv('data/mistral/evaluation_results/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test_data_processed/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 100].sort_values(by='f1_score', ascending=False)['file'].to_list()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Its surface was embossed and covered by a thin normal skin.',\n",
       " 'entities': \"[{'id': '6969', 'offsets': array([16, 24]), 'role': '', 'semantic_type_id': '', 'text': 'embossed', 'type': 'EVENT'}\\n {'id': '6984', 'offsets': array([29, 36]), 'role': '', 'semantic_type_id': '', 'text': 'covered', 'type': 'EVENT'}\\n {'id': '7850', 'offsets': array([40, 58]), 'role': '', 'semantic_type_id': '', 'text': 'a thin normal skin', 'type': 'BODYPART'}]\",\n",
       " 'original_text': 'A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago. In the family history, her mother, sisters and cousins underwent a surgery for MNG. Despite of the large volume of the mass, the patient never described signs of cervical compression whatsoever respiratory, digestive, laryngeal, vascular or neurologic signs. She never suffered from thyroid dysfunction. Her neck was deformed by the voluminous formation classified grade III according to the WHO modified classification. The mass took the front and the two sides of the neck. Its surface was embossed and covered by a thin normal skin. There were some veins of the collateral circulation limited to the neck. The goiter measured 18 x 11 cm. The mass was firm, painless, and mobile with the swallowing movements. Lymphadenopathy research was difficult and found no palpable lymph nodes. The laboratory tests (T 3, T 4 and TSH) were normal. Thoracic radiography showed a large cervical opacity roughly round and strewn with microcalcifications associated with a right eccentricity of the trachea. Cervical and chest CT revealed the presence of a partially calcified thyroid mass slightly plunging in the anterior mediastinum. It took heterogeneously the contrast and then evocate a large MNG. The trachea was surrounded by the goiter, slightly narrowed and right deviated as well as the lower part of the larynx. The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward. The patient underwent a surgery for her enormous MNG slightly plunging in the mediastinum. Endotracheal intubation was relatively easy by the laryngoscope. The incision performed was a Kocher cervicotomy. There was a multinodular, hypervascularized goiter. Its lower end plunges behind the sternal manubrium. The larynx was deviated towards the right side. The total thyroidectomy was performed in two steps: initially a right lobo-isthmectomy, then the left lobectomy. The retrosternal part of the goiter was released using the finger by the same incision. Both recurrent laryngeal nerves (RLN) were not identified because of the hemorrhage. One parathyroid gland was accidently devascularized and was autotransplanted to the ipsilateral sternocleidomastoid muscle. The operation was finished by double aspiration drainage. In the first hours after surgery, the patient developed a large cervical hematoma. She was readmitted to the operating room, and after evacuation of the hematoma there was no vessels bleeding. The operation was completed with a double suction drainage. In the immediate postoperative period, the patient developed hemodynamic collapse requiring the introduction of dobutamine. After 48 hours of hemodynamic support, the blood pressure stabilized and dobutamine was stopped. Histological study concluded in multinodular colloid goiter. The patient was discharged from the hospital after 20 days in good health.\\r\\n',\n",
       " 'original_id': 'EN100067',\n",
       " 'prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<Its surface was embossed and covered by a thin normal skin.>>> [/INST][{\"entity\": \"embossed\"}, {\"entity\": \"covered\"}, {\"entity\": \"a thin normal skin\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. <<Its surface was embossed and covered by a thin normal skin.>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"embossed\"}, {\"entity\": \"covered\"}, {\"entity\": \"a thin normal skin\"}] </s>',\n",
       " 'model_responses': '[{\"entity\":\"surface\"}, {\"entity\":\"thin normal skin\"}]</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5833.52it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 721.29it/s]\n",
      "Generating train split: 681 examples [00:00, 21108.68 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 11876.94 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 6140.25 examples/s]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 281 (char 280)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m cleaned_data \u001b[38;5;241m=\u001b[39m output_cleaner\u001b[38;5;241m.\u001b[39mapply_cleaning(eval_data, wrong_keys_to_entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;66;03m#.select(range(138,139))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator(data\u001b[38;5;241m=\u001b[39mcleaned_data, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, output_cleaner\u001b[38;5;241m=\u001b[39moutput_cleaner)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_evaluation_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop_words\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuperset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleveshtein\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:463\u001b[0m, in \u001b[0;36mEvaluator.generate_evaluation_table\u001b[0;34m(self, similar_is_equal_threshold, words_level, similarity_types)\u001b[0m\n\u001b[1;32m    461\u001b[0m metrics_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m--> 463\u001b[0m     metrics_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_TP_FP_FN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mground_truth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    465\u001b[0m metrics_dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metrics_list, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    466\u001b[0m summary \u001b[38;5;241m=\u001b[39m metrics_dataframe\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:408\u001b[0m, in \u001b[0;36mEvaluator._extract_TP_FP_FN\u001b[0;34m(self, model_response, ground_truth, similar_is_equal, similar_is_equal_threshold, similarity_types, words_level)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaner\u001b[38;5;241m.\u001b[39mverbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGINAL model_response: \u001b[39m\u001b[38;5;124m'\u001b[39m, model_response)\n\u001b[1;32m    407\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json(model_response)\n\u001b[0;32m--> 408\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m model_response \u001b[38;5;241m=\u001b[39m model_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    410\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m ground_truth[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:101\u001b[0m, in \u001b[0;36mEvaluator._parse_json\u001b[0;34m(self, model_response, drop_duplicates)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m: entities, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m\"\u001b[39m: offsets}\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset) \u001b[38;5;129;01mand\u001b[39;00m good_format:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# print('ORA STO PARSANDO: ', model_response)\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# print('OUTPUT: ', type(output))\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_duplicates:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 281 (char 280)"
     ]
    }
   ],
   "source": [
    "file ='/home/pferrazzi/mistral_finetuning/data/TMP_maxNewTokensFactor6_nShotsInference0_Mistral-7B-Instruct-v0.2_adapters_en.layer1.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                    words_level=False, similarity_types=['case', 'stop_words', 'subset', 'superset', 'leveshtein'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.',\n",
       " 'entities': \"[{'id': '1614', 'offsets': array([23, 35]), 'role': '', 'semantic_type_id': '', 'text': 'hypertension', 'type': 'EVENT'}\\n {'id': '1629', 'offsets': array([40, 52]), 'role': '', 'semantic_type_id': '', 'text': 'dyslipidemia', 'type': 'EVENT'}\\n {'id': '1644', 'offsets': array([53, 62]), 'role': '', 'semantic_type_id': '', 'text': 'diagnosed', 'type': 'EVENT'}\\n {'id': '1659', 'offsets': array([110, 118]), 'role': '', 'semantic_type_id': '', 'text': 'mellitus', 'type': 'EVENT'}\\n {'id': '1674', 'offsets': array([149, 157]), 'role': '', 'semantic_type_id': '', 'text': 'referred', 'type': 'EVENT'}\\n {'id': '1689', 'offsets': array([186, 197]), 'role': '', 'semantic_type_id': '', 'text': 'hypokalemia', 'type': 'EVENT'}\\n {'id': '1996', 'offsets': array([ 91, 118]), 'role': '', 'semantic_type_id': 'C0743128', 'text': 'new-onset diabetes mellitus', 'type': 'CLINENTITY'}\\n {'id': '2076', 'offsets': array([ 0, 17]), 'role': 'PATIENT', 'semantic_type_id': '', 'text': 'A 46-year-old man', 'type': 'ACTOR'}\\n {'id': '2090', 'offsets': array([63, 71]), 'role': '', 'semantic_type_id': '', 'text': '4-months', 'type': 'TIMEX3'}\\n {'id': '2099', 'offsets': array([128, 135]), 'role': '', 'semantic_type_id': '', 'text': '1-month', 'type': 'TIMEX3'}]\",\n",
       " 'original_text': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia. Hormonal study and dynamic biochemical tests performed indicated ECS. Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases. Somatostatin receptor scintigraphy has shown an increased uptake in the parotid gland and mild expression in liver metastasis. The patient underwent right parotidectomy, and histopathologic examination confirmed ACC. Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide. Despite chemotherapy onset, a rapid disease progression and clinical course deterioration was observed.\\r\\n',\n",
       " 'original_id': 'EN101783',\n",
       " 'prompt': '<s>[INST]A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.[/INST][{\"entity\": \"hypertension\"}, {\"entity\": \"dyslipidemia\"}, {\"entity\": \"diagnosed\"}, {\"entity\": \"mellitus\"}, {\"entity\": \"referred\"}, {\"entity\": \"hypokalemia\"}, {\"entity\": \"new-onset diabetes mellitus\"}, {\"entity\": \"A 46-year-old man\"}, {\"entity\": \"4-months\"}, {\"entity\": \"1-month\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST]  <<A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"hypertension\"}, {\"entity\": \"dyslipidemia\"}, {\"entity\": \"diagnosed\"}, {\"entity\": \"mellitus\"}, {\"entity\": \"referred\"}, {\"entity\": \"hypokalemia\"}, {\"entity\": \"new-onset diabetes mellitus\"}, {\"entity\": \"A 46-year-old man\"}, {\"entity\": \"4-months\"}, {\"entity\": \"1-month\"}] </s>',\n",
       " 'model_responses': 'This is a case of a 46-year-old man who has been diagnosed with hypertension, dyslipidemia, and new-onset diabetes mellitus within the past 4-5 months. He presented to the emergency department due to hypokalemia, which is a condition characterized by low potassium levels in the blood.\\n\\nHypokalemia',\n",
       " 'model_output': '[]'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/TMP_maxNewTokensFactor6_nShotsInference0_Mistral-7B-Instruct-v0.2_adapters_en.layer1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m eval_data \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_csv(file) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#display(eval_data.to_pandas().head(3))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m output_cleaner \u001b[38;5;241m=\u001b[39m OutputCleaner()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "file ='data/TMP_maxNewTokensFactor6_nShotsInference0_Mistral-7B-Instruct-v0.2_adapters_en.layer1.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                    words_level=True, similarity_types=['case', 'stop_words', 'subset', 'superset'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE MODEL MISTRAL 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit_base/*.csv') \n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.333916</td>\n",
       "      <td>0.260224</td>\n",
       "      <td>0.465835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.321196</td>\n",
       "      <td>0.250189</td>\n",
       "      <td>0.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>0.243325</td>\n",
       "      <td>0.437364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.309780</td>\n",
       "      <td>0.241062</td>\n",
       "      <td>0.433297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.308811</td>\n",
       "      <td>0.240308</td>\n",
       "      <td>0.431941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.128506</td>\n",
       "      <td>0.281651</td>\n",
       "      <td>0.083243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.127428</td>\n",
       "      <td>0.085827</td>\n",
       "      <td>0.247289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.127009</td>\n",
       "      <td>0.085545</td>\n",
       "      <td>0.246475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.126729</td>\n",
       "      <td>0.085357</td>\n",
       "      <td>0.245933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>0.070487</td>\n",
       "      <td>0.203091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "133  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "132  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "131  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "130  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "138  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "..                                                 ...               ...   \n",
       "19   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "31   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "30   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "38   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "39   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "133                          80  0.333916   0.260224  0.465835  \n",
       "132                          85  0.321196   0.250189  0.448482  \n",
       "131                          90  0.312688   0.243325  0.437364  \n",
       "130                          95  0.309780   0.241062  0.433297  \n",
       "138                         100  0.308811   0.240308  0.431941  \n",
       "..                          ...       ...        ...       ...  \n",
       "19                          100  0.128506   0.281651  0.083243  \n",
       "31                           90  0.127428   0.085827  0.247289  \n",
       "30                           95  0.127009   0.085545  0.246475  \n",
       "38                          100  0.126729   0.085357  0.245933  \n",
       "39                          100  0.104653   0.070487  0.203091  \n",
       "\n",
       "[84 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 80].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE MODEL MISTRAL 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference1_BaseModel.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/4bit_base/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if not file.strip().endswith('BaseModel.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.466546</td>\n",
       "      <td>0.445486</td>\n",
       "      <td>0.489696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.463026</td>\n",
       "      <td>0.446798</td>\n",
       "      <td>0.480477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.461848</td>\n",
       "      <td>0.456885</td>\n",
       "      <td>0.466920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.451200</td>\n",
       "      <td>0.434859</td>\n",
       "      <td>0.468818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.446995</td>\n",
       "      <td>0.426217</td>\n",
       "      <td>0.469902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.445845</td>\n",
       "      <td>0.440880</td>\n",
       "      <td>0.450922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.442473</td>\n",
       "      <td>0.426345</td>\n",
       "      <td>0.459870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.441708</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.437636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.440010</td>\n",
       "      <td>0.423869</td>\n",
       "      <td>0.457430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.438910</td>\n",
       "      <td>0.422758</td>\n",
       "      <td>0.456345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.437484</td>\n",
       "      <td>0.416953</td>\n",
       "      <td>0.460141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.437148</td>\n",
       "      <td>0.432167</td>\n",
       "      <td>0.442245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.435309</td>\n",
       "      <td>0.414784</td>\n",
       "      <td>0.457972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.434021</td>\n",
       "      <td>0.413556</td>\n",
       "      <td>0.456616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.433548</td>\n",
       "      <td>0.428496</td>\n",
       "      <td>0.438720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.432744</td>\n",
       "      <td>0.427701</td>\n",
       "      <td>0.437907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.424508</td>\n",
       "      <td>0.428256</td>\n",
       "      <td>0.420824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.414114</td>\n",
       "      <td>0.417770</td>\n",
       "      <td>0.410521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.410832</td>\n",
       "      <td>0.414459</td>\n",
       "      <td>0.407267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.409408</td>\n",
       "      <td>0.412966</td>\n",
       "      <td>0.405911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.391293</td>\n",
       "      <td>0.376757</td>\n",
       "      <td>0.406996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.375886</td>\n",
       "      <td>0.358037</td>\n",
       "      <td>0.395607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.372990</td>\n",
       "      <td>0.368644</td>\n",
       "      <td>0.377440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.341763</td>\n",
       "      <td>0.344637</td>\n",
       "      <td>0.338937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  similar_is_equal  \\\n",
       "13  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "23  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "33  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "22  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "12  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "32  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "21  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "43  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "20  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "28  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "11  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "31  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "10  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "18  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "30  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "38  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "42  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "41  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "40  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "48  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "29  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "19  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "39  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "49  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "1   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "8   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "3   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "2   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "0   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "9   data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "\n",
       "    similar_is_equal_threshold  f1_score  precision    recall  \n",
       "13                          80  0.466546   0.445486  0.489696  \n",
       "23                          80  0.463026   0.446798  0.480477  \n",
       "33                          80  0.461848   0.456885  0.466920  \n",
       "22                          85  0.451200   0.434859  0.468818  \n",
       "12                          85  0.446995   0.426217  0.469902  \n",
       "32                          85  0.445845   0.440880  0.450922  \n",
       "21                          90  0.442473   0.426345  0.459870  \n",
       "43                          80  0.441708   0.445856  0.437636  \n",
       "20                          95  0.440010   0.423869  0.457430  \n",
       "28                         100  0.438910   0.422758  0.456345  \n",
       "11                          90  0.437484   0.416953  0.460141  \n",
       "31                          90  0.437148   0.432167  0.442245  \n",
       "10                          95  0.435309   0.414784  0.457972  \n",
       "18                         100  0.434021   0.413556  0.456616  \n",
       "30                          95  0.433548   0.428496  0.438720  \n",
       "38                         100  0.432744   0.427701  0.437907  \n",
       "42                          85  0.424508   0.428256  0.420824  \n",
       "41                          90  0.414114   0.417770  0.410521  \n",
       "40                          95  0.410832   0.414459  0.407267  \n",
       "48                         100  0.409408   0.412966  0.405911  \n",
       "29                         100  0.391293   0.376757  0.406996  \n",
       "19                         100  0.375886   0.358037  0.395607  \n",
       "39                         100  0.372990   0.368644  0.377440  \n",
       "49                         100  0.341763   0.344637  0.338937  \n",
       "1                           90  0.005207   0.065359  0.002711  \n",
       "8                          100  0.005207   0.065359  0.002711  \n",
       "3                           80  0.005207   0.065359  0.002711  \n",
       "2                           85  0.005207   0.065359  0.002711  \n",
       "0                           95  0.005207   0.065359  0.002711  \n",
       "9                          100  0.005206   0.064935  0.002711  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 80].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/mistral_4bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL BASE 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference1_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference1_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference1_BaseModel.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit_base/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if not file.strip().endswith('BaseModel.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.333916</td>\n",
       "      <td>0.260224</td>\n",
       "      <td>0.465835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.321196</td>\n",
       "      <td>0.250189</td>\n",
       "      <td>0.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>0.243325</td>\n",
       "      <td>0.437364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.309780</td>\n",
       "      <td>0.241062</td>\n",
       "      <td>0.433297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.308811</td>\n",
       "      <td>0.240308</td>\n",
       "      <td>0.431941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.128506</td>\n",
       "      <td>0.281651</td>\n",
       "      <td>0.083243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.127428</td>\n",
       "      <td>0.085827</td>\n",
       "      <td>0.247289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.127009</td>\n",
       "      <td>0.085545</td>\n",
       "      <td>0.246475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.126729</td>\n",
       "      <td>0.085357</td>\n",
       "      <td>0.245933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>0.070487</td>\n",
       "      <td>0.203091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "133  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "132  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "131  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "130  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "138  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "..                                                 ...               ...   \n",
       "19   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "31   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "30   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "38   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "39   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "133                          80  0.333916   0.260224  0.465835  \n",
       "132                          85  0.321196   0.250189  0.448482  \n",
       "131                          90  0.312688   0.243325  0.437364  \n",
       "130                          95  0.309780   0.241062  0.433297  \n",
       "138                         100  0.308811   0.240308  0.431941  \n",
       "..                          ...       ...        ...       ...  \n",
       "19                          100  0.128506   0.281651  0.083243  \n",
       "31                           90  0.127428   0.085827  0.247289  \n",
       "30                           95  0.127009   0.085545  0.246475  \n",
       "38                          100  0.126729   0.085357  0.245933  \n",
       "39                          100  0.104653   0.070487  0.203091  \n",
       "\n",
       "[84 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 80].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/mistral_8bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    # if file.strip().endswith('0.002.csv'):\n",
    "    #     continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/mistral_8bit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.648048</td>\n",
       "      <td>0.633049</td>\n",
       "      <td>0.663774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.641816</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.686280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.638147</td>\n",
       "      <td>0.598386</td>\n",
       "      <td>0.683568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.638144</td>\n",
       "      <td>0.631369</td>\n",
       "      <td>0.645065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.631801</td>\n",
       "      <td>0.615860</td>\n",
       "      <td>0.648590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.002440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "535  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "54   data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "555  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "164  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "534  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "..                                                 ...               ...   \n",
       "669  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "663  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "662  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "661  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "670  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "535                          75  0.648048   0.633049  0.663774  \n",
       "54                           75  0.641816   0.602763  0.686280  \n",
       "555                          75  0.638147   0.598386  0.683568  \n",
       "164                          75  0.638144   0.631369  0.645065  \n",
       "534                          80  0.631801   0.615860  0.648590  \n",
       "..                          ...       ...        ...       ...  \n",
       "669                         100  0.005189   0.019928  0.002983  \n",
       "663                          85  0.005189   0.019928  0.002983  \n",
       "662                          90  0.005189   0.019928  0.002983  \n",
       "661                          95  0.005189   0.019928  0.002983  \n",
       "670                         100  0.004245   0.016304  0.002440  \n",
       "\n",
       "[484 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/8bit/*.csv') \n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hormonal study and dynamic biochemical tests performed indicated ECS.',\n",
       " 'entities': \"[{'id': '1704', 'offsets': array([ 9, 14]), 'role': '', 'semantic_type_id': '', 'text': 'study', 'type': 'EVENT'}\\n {'id': '1719', 'offsets': array([39, 44]), 'role': '', 'semantic_type_id': '', 'text': 'tests', 'type': 'EVENT'}\\n {'id': '1734', 'offsets': array([55, 64]), 'role': '', 'semantic_type_id': '', 'text': 'indicated', 'type': 'EVENT'}\\n {'id': '1749', 'offsets': array([65, 68]), 'role': '', 'semantic_type_id': '', 'text': 'ECS', 'type': 'EVENT'}]\",\n",
       " 'original_text': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia. Hormonal study and dynamic biochemical tests performed indicated ECS. Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases. Somatostatin receptor scintigraphy has shown an increased uptake in the parotid gland and mild expression in liver metastasis. The patient underwent right parotidectomy, and histopathologic examination confirmed ACC. Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide. Despite chemotherapy onset, a rapid disease progression and clinical course deterioration was observed.\\r\\n',\n",
       " 'original_id': 'EN101783',\n",
       " 'prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST][{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"indicated\"}, {\"entity\": \"ECS\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"indicated\"}, {\"entity\": \"ECS\"}]',\n",
       " 'model_responses': '[{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST] [{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"ECS\"}, {\"entity\": \"indicated\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<A 1-year-old boy presented with a 2-day history of fever and vomiting.>>> [/INST][{\"entity\": \"presented\"}, {\"entity',\n",
       " 'model_output': \"[{'entity': 'present'}, {'entity': 'history'}, {'entity': 'enlargement'}, {'entity': 'entity_name'}, {'entity': 'presented'}, {'entity': 'refusal'}, {'entity': 'bear'}, {'entity': 'peaks'}, {'entity': 'entity_name'}, {'entity': 'study'}, {'entity': 'tests'}, {'entity': 'ECS'}, {'entity': 'indicated'}, {'entity': 'entity_name'}, {'entity': 'presented'}]\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.405388</td>\n",
       "      <td>0.277098</td>\n",
       "      <td>0.754881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.404637</td>\n",
       "      <td>0.276725</td>\n",
       "      <td>0.752440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.398314</td>\n",
       "      <td>0.272060</td>\n",
       "      <td>0.743221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.396249</td>\n",
       "      <td>0.271486</td>\n",
       "      <td>0.733189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.396191</td>\n",
       "      <td>0.270660</td>\n",
       "      <td>0.738883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.250214</td>\n",
       "      <td>0.182912</td>\n",
       "      <td>0.395879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.248097</td>\n",
       "      <td>0.181227</td>\n",
       "      <td>0.393167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>0.180477</td>\n",
       "      <td>0.391540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.180080</td>\n",
       "      <td>0.390727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.240294</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.380965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "354  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "104  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "353  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "374  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "103  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "..                                                 ...               ...   \n",
       "272  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "271  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "270  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "278  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "279  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "354                          75  0.405388   0.277098  0.754881  \n",
       "104                          75  0.404637   0.276725  0.752440  \n",
       "353                          80  0.398314   0.272060  0.743221  \n",
       "374                          75  0.396249   0.271486  0.733189  \n",
       "103                          80  0.396191   0.270660  0.738883  \n",
       "..                          ...       ...        ...       ...  \n",
       "272                          85  0.250214   0.182912  0.395879  \n",
       "271                          90  0.248097   0.181227  0.393167  \n",
       "270                          95  0.247070   0.180477  0.391540  \n",
       "278                         100  0.246536   0.180080  0.390727  \n",
       "279                         100  0.240294   0.175493  0.380965  \n",
       "\n",
       "[280 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/llama7b_8bit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAM7 BASE 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/7B_4bit_base/*.csv') \n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.271827</td>\n",
       "      <td>0.230436</td>\n",
       "      <td>0.331345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.261285</td>\n",
       "      <td>0.221447</td>\n",
       "      <td>0.318601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.254501</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>0.310466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.248140</td>\n",
       "      <td>0.210160</td>\n",
       "      <td>0.302874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.247668</td>\n",
       "      <td>0.209744</td>\n",
       "      <td>0.302332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "144  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "143  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "142  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "141  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "140  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "..                                                 ...               ...   \n",
       "12   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "13   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "18   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "10   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "19   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "144                          75  0.271827   0.230436  0.331345  \n",
       "143                          80  0.261285   0.221447  0.318601  \n",
       "142                          85  0.254501   0.215631  0.310466  \n",
       "141                          90  0.248140   0.210160  0.302874  \n",
       "140                          95  0.247668   0.209744  0.302332  \n",
       "..                          ...       ...        ...       ...  \n",
       "12                           85  0.003781   0.466667  0.001898  \n",
       "13                           80  0.003781   0.466667  0.001898  \n",
       "18                          100  0.003781   0.466667  0.001898  \n",
       "10                           95  0.003781   0.466667  0.001898  \n",
       "19                          100  0.003241   0.400000  0.001627  \n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/llama7b_4bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA7 BASE 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference1_BaseModel.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/7B_8bit_base/*.csv') \n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.244096</td>\n",
       "      <td>0.350325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.285771</td>\n",
       "      <td>0.532939</td>\n",
       "      <td>0.195228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.276906</td>\n",
       "      <td>0.234850</td>\n",
       "      <td>0.337310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.271771</td>\n",
       "      <td>0.506282</td>\n",
       "      <td>0.185738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.271473</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>0.330803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.265436</td>\n",
       "      <td>0.225052</td>\n",
       "      <td>0.323482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.264457</td>\n",
       "      <td>0.224170</td>\n",
       "      <td>0.322397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.263790</td>\n",
       "      <td>0.223605</td>\n",
       "      <td>0.321584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.479351</td>\n",
       "      <td>0.176247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.252131</td>\n",
       "      <td>0.468681</td>\n",
       "      <td>0.172451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.251338</td>\n",
       "      <td>0.467207</td>\n",
       "      <td>0.171909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.250545</td>\n",
       "      <td>0.465733</td>\n",
       "      <td>0.171367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.239001</td>\n",
       "      <td>0.176236</td>\n",
       "      <td>0.371204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.237282</td>\n",
       "      <td>0.171588</td>\n",
       "      <td>0.384490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.234052</td>\n",
       "      <td>0.172565</td>\n",
       "      <td>0.363612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.232185</td>\n",
       "      <td>0.171146</td>\n",
       "      <td>0.360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.231104</td>\n",
       "      <td>0.170215</td>\n",
       "      <td>0.359816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.231064</td>\n",
       "      <td>0.170172</td>\n",
       "      <td>0.359816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.230890</td>\n",
       "      <td>0.170044</td>\n",
       "      <td>0.359544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.229322</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.371746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228203</td>\n",
       "      <td>0.193439</td>\n",
       "      <td>0.278200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.224191</td>\n",
       "      <td>0.162054</td>\n",
       "      <td>0.363612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.222037</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>0.360629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.221666</td>\n",
       "      <td>0.160116</td>\n",
       "      <td>0.360087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.221499</td>\n",
       "      <td>0.159995</td>\n",
       "      <td>0.359816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.217134</td>\n",
       "      <td>0.159913</td>\n",
       "      <td>0.338124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.202180</td>\n",
       "      <td>0.375829</td>\n",
       "      <td>0.138286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.198798</td>\n",
       "      <td>0.143598</td>\n",
       "      <td>0.322939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  similar_is_equal  \\\n",
       "34  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "4   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "33  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "3   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "32  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "31  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "30  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "38  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "2   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "1   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "0   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "8   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "14  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "24  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "13  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "12  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "11  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "10  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "18  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "23  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "39  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "22  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "21  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "20  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "28  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "19  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "9   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "29  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "\n",
       "    similar_is_equal_threshold  f1_score  precision    recall  \n",
       "34                          75  0.287719   0.244096  0.350325  \n",
       "4                           75  0.285771   0.532939  0.195228  \n",
       "33                          80  0.276906   0.234850  0.337310  \n",
       "3                           80  0.271771   0.506282  0.185738  \n",
       "32                          85  0.271473   0.230189  0.330803  \n",
       "31                          90  0.265436   0.225052  0.323482  \n",
       "30                          95  0.264457   0.224170  0.322397  \n",
       "38                         100  0.263790   0.223605  0.321584  \n",
       "2                           85  0.257732   0.479351  0.176247  \n",
       "1                           90  0.252131   0.468681  0.172451  \n",
       "0                           95  0.251338   0.467207  0.171909  \n",
       "8                          100  0.250545   0.465733  0.171367  \n",
       "14                          75  0.239001   0.176236  0.371204  \n",
       "24                          75  0.237282   0.171588  0.384490  \n",
       "13                          80  0.234052   0.172565  0.363612  \n",
       "12                          85  0.232185   0.171146  0.360900  \n",
       "11                          90  0.231104   0.170215  0.359816  \n",
       "10                          95  0.231064   0.170172  0.359816  \n",
       "18                         100  0.230890   0.170044  0.359544  \n",
       "23                          80  0.229322   0.165800  0.371746  \n",
       "39                         100  0.228203   0.193439  0.278200  \n",
       "22                          85  0.224191   0.162054  0.363612  \n",
       "21                          90  0.222037   0.160396  0.360629  \n",
       "20                          95  0.221666   0.160116  0.360087  \n",
       "28                         100  0.221499   0.159995  0.359816  \n",
       "19                         100  0.217134   0.159913  0.338124  \n",
       "9                          100  0.202180   0.375829  0.138286  \n",
       "29                         100  0.198798   0.143598  0.322939  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/llama7b_8bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL BASE simplest_prompt one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1050.15it/s]\n",
      "Generating train split: 681 examples [00:00, 20161.65 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 10661.97 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 6854.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evaluation':      TP  FP  FN\n",
      "0     0   0  10\n",
      "1     0   1   4\n",
      "2     0   0   4\n",
      "3     5   0   0\n",
      "4     1   0   1\n",
      "..   ..  ..  ..\n",
      "676   0   0   4\n",
      "677   3   0   1\n",
      "678   3   0   0\n",
      "679   3   1   2\n",
      "680   0   0   4\n",
      "\n",
      "[681 rows x 3 columns], 'precision': 0.7130730050933786, 'recall': 0.34164859002169196, 'f1': 0.46196150320806595}\n",
      "{'evaluation':      TP  FP  FN\n",
      "0     2   0   8\n",
      "1     3   0   1\n",
      "2     2   1   2\n",
      "3     3   0   2\n",
      "4     2   1   0\n",
      "..   ..  ..  ..\n",
      "676   2   1   2\n",
      "677   3   0   1\n",
      "678   2   1   1\n",
      "679   2   1   3\n",
      "680   3   0   1\n",
      "\n",
      "[681 rows x 3 columns], 'precision': 0.6405353728489483, 'recall': 0.2725054229934924, 'f1': 0.3823473463952825}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "\n",
    "file = 'data/test_data_processed/maxNewTokensFactor6_nShotsInference0_Mistral-7B-v0.1_simplest_prompt_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 80\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator_mistral_base = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_mistral_base.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "\n",
    "\n",
    "file = 'data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 80\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator_mistral_instruct = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_mistral_instruct.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "\n",
    "print(evaluator_mistral_instruct.evaluation_table)\n",
    "print(evaluator_mistral_base.evaluation_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases.',\n",
       " 'entities': \"[{'id': '1764', 'offsets': array([24, 32]), 'role': '', 'semantic_type_id': '', 'text': 'findings', 'type': 'EVENT'}\\n {'id': '1779', 'offsets': array([33, 40]), 'role': '', 'semantic_type_id': '', 'text': 'pointed', 'type': 'EVENT'}\\n {'id': '2010', 'offsets': array([57, 89]), 'role': '', 'semantic_type_id': 'C1306459', 'text': 'primary right parotid malignancy', 'type': 'CLINENTITY'}\\n {'id': '2017', 'offsets': array([ 95, 111]), 'role': '', 'semantic_type_id': 'C0494165', 'text': 'liver metastases', 'type': 'CLINENTITY'}\\n {'id': '2052', 'offsets': array([57, 89]), 'role': '', 'semantic_type_id': '', 'text': 'primary right parotid malignancy', 'type': 'BODYPART'}\\n {'id': '2058', 'offsets': array([ 95, 111]), 'role': '', 'semantic_type_id': '', 'text': 'liver metastases', 'type': 'BODYPART'}]\",\n",
       " 'original_text': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia. Hormonal study and dynamic biochemical tests performed indicated ECS. Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases. Somatostatin receptor scintigraphy has shown an increased uptake in the parotid gland and mild expression in liver metastasis. The patient underwent right parotidectomy, and histopathologic examination confirmed ACC. Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide. Despite chemotherapy onset, a rapid disease progression and clinical course deterioration was observed.\\r\\n',\n",
       " 'original_id': 'EN101783',\n",
       " 'prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases.>>> [/INST][{\"entity\": \"findings\"}, {\"entity\": \"pointed\"}, {\"entity\": \"primary right parotid malignancy\"}, {\"entity\": \"liver metastases\"}, {\"entity\": \"primary right parotid malignancy\"}, {\"entity\": \"liver metastases\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases.>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"findings\"}, {\"entity\": \"pointed\"}, {\"entity\": \"primary right parotid malignancy\"}, {\"entity\": \"liver metastases\"}, {\"entity\": \"primary right parotid malignancy\"}, {\"entity\": \"liver metastases\"}]',\n",
       " 'model_responses': '[{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases.>>> [/INST] [{\"entity\": \"findings\"}, {\"entity\": \"pointed\"}, {\"entity\": \"malignancy\"}, {\"entity\": \"metastases\"}, {\"entity\": \"malignancy\"}, {\"entity\": \"metastases\"}, {\"entity\": \"a likely primary right parotid malignancy with liver metastases\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text:'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file ='data/llama/7B_8bit/maxNewTokensFactor8_nShotsInference2_Llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_2_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "cleaned_data[3]\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                    words_level=True, similarity_types=['case', 'stop_words', 'subset', 'superset', 'leveshtein'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "# from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "file ='data/mistral/noInstr_8bit/maxNewTokensFactor8_nShotsInference0_Mistral-7B-v0.1_simplest_prompt_adapters_en.layer1_8_torch.bfloat16_16_32_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                    words_level=False, similarity_types=['case', 'stop_words', 'subset', 'superset', 'leveshtein'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate\n",
    "\n",
    "\n",
    "res = evaluate('data/mistral/noInstr_8bit',\n",
    "         'data/evaluation_results/mistral_noInstr_8bit.csv',\n",
    "         words_level=True,\n",
    "         similar_is_equal_threshold_list=[80, 100],\n",
    "         similarity_types=['case', 'stop_words', 'subset', 'superset'],\n",
    "         wrong_keys_to_entity=False,\n",
    "         offset=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA 13B 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "# from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_threshold_list = [100]\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/13B_4bit/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "output_cleaner = OutputCleaner(verbose=False)\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if file.strip().endswith('0.0008.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "        # print(f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\")\n",
    "        evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "        evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                            words_level=True, \n",
    "                                            similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "        #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "        evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "        # print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation_results.to_csv('data/evaluation_results/llama13B_4bit_wordsLevelTrue_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.708628</td>\n",
       "      <td>0.752786</td>\n",
       "      <td>0.669364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.704166</td>\n",
       "      <td>0.748645</td>\n",
       "      <td>0.664676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.695741</td>\n",
       "      <td>0.736405</td>\n",
       "      <td>0.659334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.693492</td>\n",
       "      <td>0.725360</td>\n",
       "      <td>0.664306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.691360</td>\n",
       "      <td>0.721092</td>\n",
       "      <td>0.663983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.690166</td>\n",
       "      <td>0.699494</td>\n",
       "      <td>0.681084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.689516</td>\n",
       "      <td>0.695189</td>\n",
       "      <td>0.683935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.687684</td>\n",
       "      <td>0.700227</td>\n",
       "      <td>0.675583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.685843</td>\n",
       "      <td>0.687754</td>\n",
       "      <td>0.683942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.682525</td>\n",
       "      <td>0.739965</td>\n",
       "      <td>0.633361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.680199</td>\n",
       "      <td>0.684116</td>\n",
       "      <td>0.676327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.678705</td>\n",
       "      <td>0.681144</td>\n",
       "      <td>0.676283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.647152</td>\n",
       "      <td>0.659901</td>\n",
       "      <td>0.634887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.643864</td>\n",
       "      <td>0.643967</td>\n",
       "      <td>0.643761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.643092</td>\n",
       "      <td>0.657364</td>\n",
       "      <td>0.629427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.640791</td>\n",
       "      <td>0.653986</td>\n",
       "      <td>0.628118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.639482</td>\n",
       "      <td>0.660105</td>\n",
       "      <td>0.620109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.632250</td>\n",
       "      <td>0.652913</td>\n",
       "      <td>0.612856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.415050</td>\n",
       "      <td>0.337071</td>\n",
       "      <td>0.539968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.412403</td>\n",
       "      <td>0.332305</td>\n",
       "      <td>0.543376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.402671</td>\n",
       "      <td>0.328287</td>\n",
       "      <td>0.520638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.523268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.397437</td>\n",
       "      <td>0.320614</td>\n",
       "      <td>0.522676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.395474</td>\n",
       "      <td>0.321188</td>\n",
       "      <td>0.514462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.392368</td>\n",
       "      <td>0.319932</td>\n",
       "      <td>0.507205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.389236</td>\n",
       "      <td>0.315655</td>\n",
       "      <td>0.507550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.388281</td>\n",
       "      <td>0.319202</td>\n",
       "      <td>0.495517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.387373</td>\n",
       "      <td>0.315411</td>\n",
       "      <td>0.501878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.379329</td>\n",
       "      <td>0.310018</td>\n",
       "      <td>0.488554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.374050</td>\n",
       "      <td>0.307743</td>\n",
       "      <td>0.476778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.361809</td>\n",
       "      <td>0.245992</td>\n",
       "      <td>0.683709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.361152</td>\n",
       "      <td>0.246551</td>\n",
       "      <td>0.674820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.356160</td>\n",
       "      <td>0.244377</td>\n",
       "      <td>0.656420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.351276</td>\n",
       "      <td>0.239060</td>\n",
       "      <td>0.662047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.351229</td>\n",
       "      <td>0.238026</td>\n",
       "      <td>0.669759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.348859</td>\n",
       "      <td>0.237140</td>\n",
       "      <td>0.659609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.348227</td>\n",
       "      <td>0.236073</td>\n",
       "      <td>0.663392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.347967</td>\n",
       "      <td>0.235478</td>\n",
       "      <td>0.666230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.347226</td>\n",
       "      <td>0.237351</td>\n",
       "      <td>0.646515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.343463</td>\n",
       "      <td>0.233625</td>\n",
       "      <td>0.648216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.341568</td>\n",
       "      <td>0.233393</td>\n",
       "      <td>0.636649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.341219</td>\n",
       "      <td>0.232668</td>\n",
       "      <td>0.639644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.324549</td>\n",
       "      <td>0.269388</td>\n",
       "      <td>0.408116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.320809</td>\n",
       "      <td>0.267020</td>\n",
       "      <td>0.401737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>0.258682</td>\n",
       "      <td>0.389057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.309113</td>\n",
       "      <td>0.258248</td>\n",
       "      <td>0.384928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.308024</td>\n",
       "      <td>0.256275</td>\n",
       "      <td>0.385959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.305491</td>\n",
       "      <td>0.254576</td>\n",
       "      <td>0.381863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.296181</td>\n",
       "      <td>0.201465</td>\n",
       "      <td>0.558972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.293454</td>\n",
       "      <td>0.200061</td>\n",
       "      <td>0.550391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.280351</td>\n",
       "      <td>0.191497</td>\n",
       "      <td>0.523038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.279068</td>\n",
       "      <td>0.189307</td>\n",
       "      <td>0.530700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.275578</td>\n",
       "      <td>0.188498</td>\n",
       "      <td>0.512195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.185057</td>\n",
       "      <td>0.512086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  \\\n",
       "51  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "8   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "11  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "27  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "28  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "44  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "40  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "21  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "43  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "52  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "26  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "16  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "29  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "18  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "37  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "24  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "13  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "5   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "7   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "31  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "30  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "17  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "4   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "33  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "9   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "0   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "12  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "3   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "38  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "32  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "2   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "39  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "45  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "6   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "49  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "19  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "22  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "25  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "35  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "42  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "20  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "50  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "48  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "46  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "41  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "10  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "23  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "14  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "36  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "15  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "1   data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "34  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "47  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "53  data/llama/13B_4bit/maxNewTokensFactor8_nShots...   \n",
       "\n",
       "    similar_is_equal_threshold  f1_score  precision    recall  \n",
       "51                         100  0.708628   0.752786  0.669364  \n",
       "8                          100  0.704166   0.748645  0.664676  \n",
       "11                         100  0.695741   0.736405  0.659334  \n",
       "27                         100  0.693492   0.725360  0.664306  \n",
       "28                         100  0.691360   0.721092  0.663983  \n",
       "44                         100  0.690166   0.699494  0.681084  \n",
       "40                         100  0.689516   0.695189  0.683935  \n",
       "21                         100  0.687684   0.700227  0.675583  \n",
       "43                         100  0.685843   0.687754  0.683942  \n",
       "52                         100  0.682525   0.739965  0.633361  \n",
       "26                         100  0.680199   0.684116  0.676327  \n",
       "16                         100  0.678705   0.681144  0.676283  \n",
       "29                         100  0.647152   0.659901  0.634887  \n",
       "18                         100  0.643864   0.643967  0.643761  \n",
       "37                         100  0.643092   0.657364  0.629427  \n",
       "24                         100  0.640791   0.653986  0.628118  \n",
       "13                         100  0.639482   0.660105  0.620109  \n",
       "5                          100  0.632250   0.652913  0.612856  \n",
       "7                          100  0.415050   0.337071  0.539968  \n",
       "31                         100  0.412403   0.332305  0.543376  \n",
       "30                         100  0.402671   0.328287  0.520638  \n",
       "17                         100  0.402482   0.327001  0.523268  \n",
       "4                          100  0.397437   0.320614  0.522676  \n",
       "33                         100  0.395474   0.321188  0.514462  \n",
       "9                          100  0.392368   0.319932  0.507205  \n",
       "0                          100  0.389236   0.315655  0.507550  \n",
       "12                         100  0.388281   0.319202  0.495517  \n",
       "3                          100  0.387373   0.315411  0.501878  \n",
       "38                         100  0.379329   0.310018  0.488554  \n",
       "32                         100  0.374050   0.307743  0.476778  \n",
       "2                          100  0.361809   0.245992  0.683709  \n",
       "39                         100  0.361152   0.246551  0.674820  \n",
       "45                         100  0.356160   0.244377  0.656420  \n",
       "6                          100  0.351276   0.239060  0.662047  \n",
       "49                         100  0.351229   0.238026  0.669759  \n",
       "19                         100  0.348859   0.237140  0.659609  \n",
       "22                         100  0.348227   0.236073  0.663392  \n",
       "25                         100  0.347967   0.235478  0.666230  \n",
       "35                         100  0.347226   0.237351  0.646515  \n",
       "42                         100  0.343463   0.233625  0.648216  \n",
       "20                         100  0.341568   0.233393  0.636649  \n",
       "50                         100  0.341219   0.232668  0.639644  \n",
       "48                         100  0.324549   0.269388  0.408116  \n",
       "46                         100  0.320809   0.267020  0.401737  \n",
       "41                         100  0.310748   0.258682  0.389057  \n",
       "10                         100  0.309113   0.258248  0.384928  \n",
       "23                         100  0.308024   0.256275  0.385959  \n",
       "14                         100  0.305491   0.254576  0.381863  \n",
       "36                         100  0.296181   0.201465  0.558972  \n",
       "15                         100  0.293454   0.200061  0.550391  \n",
       "1                          100  0.280351   0.191497  0.523038  \n",
       "34                         100  0.279068   0.189307  0.530700  \n",
       "47                         100  0.275578   0.188498  0.512195  \n",
       "53                         100  0.271867   0.185057  0.512086  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference0_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False).iloc[i]['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'data/mistral/8bit_base': IndexError('list index out of range')}, \n",
    "{'data/mistral/8bit': IndexError('list index out of range')}, \n",
    "{'data/qwen/7B_8bit_base': JSONDecodeError('Extra data: line 1 column 281 (char 280)')}, \n",
    "{'data/qwen/14B_4bit_base': JSONDecodeError('Extra data: line 1 column 281 (char 280)')}, \n",
    "{'data/qwen/14B_8bit_base': JSONDecodeError('Extra data: line 1 column 281 (char 280)')}, \n",
    "{'data/qwen/7B_4bit_base': JSONDecodeError('Extra data: line 1 column 281 (char 280)')}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/llama/13B_NoQuantbit_base/maxNewTokensFactor2_nShotsInference4_BaseModel_Llama-2-13b-chat-hf_NoQuant.csv\n",
      "ORIGINAL model_response:  [{'entity': 'man'}, {'entity': 'hypertension'}, {'entity': 'dyslipidemia'}]\n",
      "ORIGINAL model_response:  [{'entity': 'hormonal'}, {'entity': 'study'}, {'entity': 'dynamic'}]\n",
      "ORIGINAL model_response:  [{'entity': 'imaging'}, {'entity': 'cytological'}, {'entity': 'findings'}]\n",
      "ORIGINAL model_response:  [{'entity': 'patient'}, {'entity': 'underwent'}, {'entity': 'right parotidectomy'}]\n",
      "ORIGINAL model_response:  [{'entity': 'managed'}, {'entity': 'hypercortisolism'}, {'entity': 'metyrapone'}]\n",
      "ORIGINAL model_response:  [{'entity': 'woman'}, {'entity': 'hypertensive'}, {'entity': 'hospitalized'}]\n",
      "ORIGINAL model_response:  [{'entity': 'history'}, {'entity': 'mother'}, {'entity': 'sisters'}]\n",
      "ORIGINAL model_response:  [{'entity': 'volume'}, {'entity': 'mass'}, {'entity': 'signs'}]\n",
      "ORIGINAL model_response:  [{'entity': 'suffered'}, {'entity': 'thyroid dysfunction'}]\n",
      "ORIGINAL model_response:  [{'entity': 'mass'}, {'entity': 'took'}, {'entity': 'front'}, {'entity': 'sides'}]\n",
      "ORIGINAL model_response:  [{'entity': 'surface'}, {'entity': 'embossed'}, {'entity': 'covered'}]\n",
      "ORIGINAL model_response:  [{'entity': 'veins'}, {'entity': 'collateral circulation'}, {'entity': 'neck'}]\n",
      "ORIGINAL model_response:  [{'entity': 'goiter'}, {'entity': 'measured'}]\n",
      "ORIGINAL model_response:  [{'entity': 'mass'}, {'entity': 'firm'}, {'entity': 'painless'}, {'entity': 'mobile'}]\n",
      "ORIGINAL model_response:  [{'entity': 'research'}, {'entity': 'difficult'}, {'entity': 'lymphadenopathy'}]\n",
      "ORIGINAL model_response:  [{'entity': 'laboratory'}, {'entity': 'tests'}, {'entity': 'normal'}]\n",
      "ORIGINAL model_response:  [{'entity': 'thoracic radiography'}, {'entity': 'cervical opacity'}]\n",
      "ORIGINAL model_response:  [{'entity': 'revealed'}, {'entity': 'presence'}, {'entity': 'partially calcified'}]\n",
      "ORIGINAL model_response:  [{'entity': 'took'}, {'entity': 'heterogeneously'}, {'entity': 'contrast'}]\n",
      "ORIGINAL model_response:  [{'entity': 'trachea'}, {'entity': 'goiter'}, {'entity': 'narrowed'}]\n",
      "ORIGINAL model_response:  [{'entity': 'right'}, {'entity': 'left'}, {'entity': 'vascular'}, {'entity': 'axes'}]\n",
      "ORIGINAL model_response:  [{'entity': 'patient'}, {'entity': 'underwent'}, {'entity': 'surgery'}]\n",
      "ORIGINAL model_response:  [{'entity': 'incision'}, {'entity': 'Kocher cervicotomy'}]\n",
      "ORIGINAL model_response:  [{'entity': 'lower'}, {'entity': 'end'}, {'entity': 'plunges'}]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m similar_is_equal_threshold \u001b[38;5;129;01min\u001b[39;00m similar_is_equal_threshold_list:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# print(f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\")\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m Evaluator(data\u001b[38;5;241m=\u001b[39mcleaned_data, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, output_cleaner\u001b[38;5;241m=\u001b[39moutput_cleaner)\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_evaluation_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop_words\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuperset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     evaluation_results\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(evaluation_results)] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m: file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilar_is_equal_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m: similar_is_equal_threshold, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m: evaluator\u001b[38;5;241m.\u001b[39mevaluation_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: evaluator\u001b[38;5;241m.\u001b[39mevaluation_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: evaluator\u001b[38;5;241m.\u001b[39mevaluation_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:463\u001b[0m, in \u001b[0;36mEvaluator.generate_evaluation_table\u001b[0;34m(self, similar_is_equal_threshold, words_level, similarity_types)\u001b[0m\n\u001b[1;32m    461\u001b[0m metrics_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m--> 463\u001b[0m     metrics_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_TP_FP_FN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mground_truth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    465\u001b[0m metrics_dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metrics_list, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    466\u001b[0m summary \u001b[38;5;241m=\u001b[39m metrics_dataframe\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:408\u001b[0m, in \u001b[0;36mEvaluator._extract_TP_FP_FN\u001b[0;34m(self, model_response, ground_truth, similar_is_equal, similar_is_equal_threshold, similarity_types, words_level)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaner\u001b[38;5;241m.\u001b[39mverbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGINAL model_response: \u001b[39m\u001b[38;5;124m'\u001b[39m, model_response)\n\u001b[1;32m    407\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json(model_response)\n\u001b[0;32m--> 408\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m model_response \u001b[38;5;241m=\u001b[39m model_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    410\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m ground_truth[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:101\u001b[0m, in \u001b[0;36mEvaluator._parse_json\u001b[0;34m(self, model_response, drop_duplicates)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m: entities, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m\"\u001b[39m: offsets}\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset) \u001b[38;5;129;01mand\u001b[39;00m good_format:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# print('ORA STO PARSANDO: ', model_response)\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# print('OUTPUT: ', type(output))\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_duplicates:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from utils.evaluator import Evaluator\n",
    "# from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_threshold_list = [100]\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/13B_NoQuantbit_base/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "output_cleaner = OutputCleaner(verbose=True)\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if file.strip().endswith('0.0008.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "        # print(f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\")\n",
    "        evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "        evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                            words_level=True, \n",
    "                                            similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "        #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "        evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "        # print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '][/INST][/INST][/INST][/INST][/][/][/][/][/][/][/][/][/][/][/][/][/][',\n",
       " 'entities': None,\n",
       " 'original_text': None,\n",
       " 'original_id': None,\n",
       " 'prompt': None,\n",
       " 'inference_prompt': None,\n",
       " 'ground_truth': None,\n",
       " 'model_responses': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[549]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(682, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 681/681 [00:00<00:00, 8734.90 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 5037.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = 'data/mistral/NoQuant_FT/maxNewTokensFactor4_nShotsInference0_mistral-7b-instruct-v0.2__adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "print(eval_data.shape)\n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner(verbose=False)\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False) #.select(range(12,13))\n",
    "print(cleaned_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Il ragazzo manifestava da circa una settimana vomiti ripetuti accompagnati da coliche addominali, inappetenza e vistoso calo ponderale (4 kg circa in una settimana).',\n",
       " 'entities': \"[{'id': '5355', 'offsets': array([46, 52]), 'role': '', 'semantic_type_id': 'C0042963', 'text': 'vomiti', 'type': 'CLINENTITY'}\\n {'id': '5363', 'offsets': array([78, 96]), 'role': '', 'semantic_type_id': 'C0232488', 'text': 'coliche addominali', 'type': 'CLINENTITY'}\\n {'id': '5371', 'offsets': array([ 98, 109]), 'role': '', 'semantic_type_id': 'C0232462', 'text': 'inappetenza', 'type': 'CLINENTITY'}\\n {'id': '5379', 'offsets': array([120, 134]), 'role': '', 'semantic_type_id': 'C1262477', 'text': 'calo ponderale', 'type': 'CLINENTITY'}]\",\n",
       " 'original_text': 'Il caso riguarda un ragazzo di 12 anni, ricoverato presso l’UOC di Chirurgia Pediatrica di Treviso per addome acuto. Il ragazzo manifestava da circa una settimana vomiti ripetuti accompagnati da coliche addominali, inappetenza e vistoso calo ponderale (4 kg circa in una settimana). Al ricovero il paziente si presentava molto sofferente, astenico, disidratato, apiretico, con addome globoso, trattabile ma dolente alla palpazione profonda elettivamente in fossa iliaca destra; all’ascoltazione si percepiva una peristalsi metallica. Un’ecografia eseguita in pronto soccorso poneva la diagnosi di una peritonite da verosimile appendicite acuta complicata. Il ragazzo era quindi sottoposto in urgenza a una laparoscopia esplorativa, subito convertita per impossibilità di acquisire una camera laparoscopica sufficiente con le pressioni usuali, a causa dell’estrema distensione delle anse ileali, riscontrando una matassa ileale diffusamente dilatata e infiammata fino all’ileo terminale. A livello del medio-ileo si trovava un DM con al suo interno una massa palpabile occludente. Durante la resezione del diverticolo si apprezzava la fuoriuscita di abbondante materiale simil legnoso che successivamente risultava trattarsi di residui di semi di girasole che il ragazzo aveva ingerito interi volontariamente in grande quantità circa 10 giorni prima. L’intervento si concludeva con un’anastomosi ileo-ileale e con un’appendicectomia d’occasione. L’esame istologico del tratto intestinale asportato ha confermato trattarsi di una malformazione diverticolare del piccolo intestino. In quarta giornata post-operatoria il ragazzo manifestava nuovamente un quadro clinico addominale peritonitico da perforazione intestinale su deiscenza dell’anastomosi con abbondante dispersione di altro materiale ligneo nel peritoneo. Ripulita la cavità addominale e riconfezionata l’anastomosi intestinale, il ragazzo presentava in dodicesima giornata una fistola enterica con fuoriuscita di materiale biliare frammisto ancora a materiale ligneo. Il terzo approccio chirurgico evidenziava una peritonite plastica con parziale deiscenza dell’anastomosi. Il solo confezionamento di un’ileostomia a doppia canna di fucile a fronte delle precedenti anastomosi garantiva il successivo regolare decorso post-operatorio: all’alimentazione enterale era affiancata una nutrizione parenterale notturna con ripresa graduale del peso corporeo del paziente che a fronte dei 3 interventi aveva perso quasi 6 kg di peso corporeo. La ricanalizzazione intestinale veniva confezionata a distanza di altri 2 mesi dall’ultimo intervento.\\r\\n',\n",
       " 'original_id': 'IT101154',\n",
       " 'prompt': '<s><|user|> Estrai le entità contenute nel testo.\\nRiporta i risultati in formato json: [{\"entity\":\"nome_entità\"}]. <<Il ragazzo manifestava da circa una settimana vomiti ripetuti accompagnati da coliche addominali, inappetenza e vistoso calo ponderale (4 kg circa in una settimana).>>> </s><|assistant|>[{\"entity\": \"vomiti\"}, {\"entity\": \"coliche addominali\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}] </s></s>',\n",
       " 'inference_prompt': '<s><|user|> Estrai le entità contenute nel testo.\\nRiporta i risultati in formato json: [{\"entity\":\"nome_entità\"}]. <<Il ragazzo manifestava da circa una settimana vomiti ripetuti accompagnati da coliche addominali, inappetenza e vistoso calo ponderale (4 kg circa in una settimana).>>> </s><|assistant|>',\n",
       " 'ground_truth': '[{\"entity\": \"vomiti\"}, {\"entity\": \"coliche addominali\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}] ',\n",
       " 'model_responses': '[{\"entity\": \"vomiti\"}, {\"entity\": \"coliche\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo\"}, {\"entity\": \"una settimana\"}] 6] 7] 8] 9] 1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL model_output:  [{'entity': 'ricovero'}, {'entity': 'addome'}, {'entity': 'Il ragazzo'}]\n",
      "in parse_json model_response =  [{'entity': 'ricovero'}, {'entity': 'addome'}, {'entity': 'Il ragazzo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"addome\"}, {\"entity\": \"Il ragazzo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"addome\"}, {\"entity\": \"Il ragazzo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ricovero\"}, {\"entity\": \"addome\"}, {\"entity\": \"Il ragazzo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"addome acuto\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"addome acuto\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"addome acuto\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"addome acuto\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'vomiti'}, {'entity': 'coliche'}, {'entity': 'inappetenza'}, {'entity': 'calo ponderale'}, {'entity': 'Il ragastro'}, {'entity': \"un'età di circa una settimana\"}]\n",
      "in parse_json model_response =  [{'entity': 'vomiti'}, {'entity': 'coliche'}, {'entity': 'inappetenza'}, {'entity': 'calo ponderale'}, {'entity': 'Il ragastro'}, {'entity': \"un'età di circa una settimana\"}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"vomiti\"}, {\"entity\": \"coliche\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}, {\"entity\": \"Il ragastro\"}, {\"entity\": \"un'età di circa una settimana\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"vomiti\"}, {\"entity\": \"coliche\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}, {\"entity\": \"Il ragastro\"}, {\"entity\": \"un'età di circa una settimana\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"vomiti\"}, {\"entity\": \"coliche\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}, {\"entity\": \"Il ragastro\"}, {\"entity\": \"un'età di circa una settimana\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"vomiti\"}, {\"entity\": \"coliche addominali\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"vomiti\"}, {\"entity\": \"coliche addominali\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"vomiti\"}, {\"entity\": \"coliche addominali\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"vomiti\"}, {\"entity\": \"coliche addominali\"}, {\"entity\": \"inappetenza\"}, {\"entity\": \"calo ponderale\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'sofferente'}, {'entity': 'astenico'}, {'entity': 'disidratato'}, {'entity': 'astiretico'}, {'entity': 'trattabile'}, {'entity': 'dolente'}, {'entity': 'ascoltazione'}, {'entity': 'percepiva'}, {'entity': 'un paziente'}]\n",
      "in parse_json model_response =  [{'entity': 'sofferente'}, {'entity': 'astenico'}, {'entity': 'disidratato'}, {'entity': 'astiretico'}, {'entity': 'trattabile'}, {'entity': 'dolente'}, {'entity': 'ascoltazione'}, {'entity': 'percepiva'}, {'entity': 'un paziente'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"sofferente\"}, {\"entity\": \"astenico\"}, {\"entity\": \"disidratato\"}, {\"entity\": \"astiretico\"}, {\"entity\": \"trattabile\"}, {\"entity\": \"dolente\"}, {\"entity\": \"ascoltazione\"}, {\"entity\": \"percepiva\"}, {\"entity\": \"un paziente\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"sofferente\"}, {\"entity\": \"astenico\"}, {\"entity\": \"disidratato\"}, {\"entity\": \"astiretico\"}, {\"entity\": \"trattabile\"}, {\"entity\": \"dolente\"}, {\"entity\": \"ascoltazione\"}, {\"entity\": \"percepiva\"}, {\"entity\": \"un paziente\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"sofferente\"}, {\"entity\": \"astenico\"}, {\"entity\": \"disidratato\"}, {\"entity\": \"astiretico\"}, {\"entity\": \"trattabile\"}, {\"entity\": \"dolente\"}, {\"entity\": \"ascoltazione\"}, {\"entity\": \"percepiva\"}, {\"entity\": \"un paziente\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"astenico\"}, {\"entity\": \"disidratato\"}, {\"entity\": \"peristalsi\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"astenico\"}, {\"entity\": \"disidratato\"}, {\"entity\": \"peristalsi\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"astenico\"}, {\"entity\": \"disidratato\"}, {\"entity\": \"peristalsi\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"astenico\"}, {\"entity\": \"disidratato\"}, {\"entity\": \"peristalsi\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'laparoscopia'}, {'entity': 'convertita'}, {'entity': 'acquisire'}, {'entity': 'matastia'}, {'entity': 'fino all’ileo terminale'}]\n",
      "in parse_json model_response =  [{'entity': 'laparoscopia'}, {'entity': 'convertita'}, {'entity': 'acquisire'}, {'entity': 'matastia'}, {'entity': 'fino all’ileo terminale'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"laparoscopia\"}, {\"entity\": \"convertita\"}, {\"entity\": \"acquisire\"}, {\"entity\": \"matastia\"}, {\"entity\": \"fino all’ileo terminale\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"laparoscopia\"}, {\"entity\": \"convertita\"}, {\"entity\": \"acquisire\"}, {\"entity\": \"matastia\"}, {\"entity\": \"fino all’ileo terminale\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"laparoscopia\"}, {\"entity\": \"convertita\"}, {\"entity\": \"acquisire\"}, {\"entity\": \"matastia\"}, {\"entity\": \"fino all’ileo terminale\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'trovata'}, {'entity': 'massa palpabile'}, {'entity': 'occludente'}]\n",
      "in parse_json model_response =  [{'entity': 'trovata'}, {'entity': 'massa palpabile'}, {'entity': 'occludente'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"trovata\"}, {\"entity\": \"massa palpabile\"}, {\"entity\": \"occludente\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"trovata\"}, {\"entity\": \"massa palpabile\"}, {\"entity\": \"occludente\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"trovata\"}, {\"entity\": \"massa palpabile\"}, {\"entity\": \"occludente\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'intervento'}, {'entity': 'anastomosi'}, {'entity': 'appendicectomia'}]\n",
      "in parse_json model_response =  [{'entity': 'intervento'}, {'entity': 'anastomosi'}, {'entity': 'appendicectomia'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"anastomosi\"}, {\"entity\": \"appendicectomia\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"anastomosi\"}, {\"entity\": \"appendicectomia\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"intervento\"}, {\"entity\": \"anastomosi\"}, {\"entity\": \"appendicectomia\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'esame'}, {'entity': 'confermato'}]\n",
      "in parse_json model_response =  [{'entity': 'esame'}, {'entity': 'confermato'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"confermato\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"confermato\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"confermato\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'manifestava'}, {'entity': 'quarter'}, {'entity': 'peritonitico'}, {'entity': 'perforazione intestinale su deiscenza'}, {'entity': 'sparsione di altro materiale ligneo nel peritoneo'}]\n",
      "in parse_json model_response =  [{'entity': 'manifestava'}, {'entity': 'quarter'}, {'entity': 'peritonitico'}, {'entity': 'perforazione intestinale su deiscenza'}, {'entity': 'sparsione di altro materiale ligneo nel peritoneo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"manifestava\"}, {\"entity\": \"quarter\"}, {\"entity\": \"peritonitico\"}, {\"entity\": \"perforazione intestinale su deiscenza\"}, {\"entity\": \"sparsione di altro materiale ligneo nel peritoneo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"manifestava\"}, {\"entity\": \"quarter\"}, {\"entity\": \"peritonitico\"}, {\"entity\": \"perforazione intestinale su deiscenza\"}, {\"entity\": \"sparsione di altro materiale ligneo nel peritoneo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"manifestava\"}, {\"entity\": \"quarter\"}, {\"entity\": \"peritonitico\"}, {\"entity\": \"perforazione intestinale su deiscenza\"}, {\"entity\": \"sparsione di altro materiale ligneo nel peritoneo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Ripulita'}, {'entity': 'riconfezionata'}, {'entity': 'fistola'}, {'entity': 'fuoriuscita'}, {'entity': 'il ragazzo'}]\n",
      "in parse_json model_response =  [{'entity': 'Ripulita'}, {'entity': 'riconfezionata'}, {'entity': 'fistola'}, {'entity': 'fuoriuscita'}, {'entity': 'il ragazzo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Ripulita\"}, {\"entity\": \"riconfezionata\"}, {\"entity\": \"fistola\"}, {\"entity\": \"fuoriuscita\"}, {\"entity\": \"il ragazzo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Ripulita\"}, {\"entity\": \"riconfezionata\"}, {\"entity\": \"fistola\"}, {\"entity\": \"fuoriuscita\"}, {\"entity\": \"il ragazzo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Ripulita\"}, {\"entity\": \"riconfezionata\"}, {\"entity\": \"fistola\"}, {\"entity\": \"fuoriuscita\"}, {\"entity\": \"il ragazzo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'anastomosi'}, {'entity': 'garantiva'}, {'entity': 'regolare'}, {'entity': 'all’alimentazione'}, {'entity': 'nutrizione'}, {'entity': 'ripresa'}, {'entity': 'un’ileostomia a doppia canna'}]\n",
      "in parse_json model_response =  [{'entity': 'anastomosi'}, {'entity': 'garantiva'}, {'entity': 'regolare'}, {'entity': 'all’alimentazione'}, {'entity': 'nutrizione'}, {'entity': 'ripresa'}, {'entity': 'un’ileostomia a doppia canna'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anastomosi\"}, {\"entity\": \"garantiva\"}, {\"entity\": \"regolare\"}, {\"entity\": \"all’alimentazione\"}, {\"entity\": \"nutrizione\"}, {\"entity\": \"ripresa\"}, {\"entity\": \"un’ileostomia a doppia canna\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anastomosi\"}, {\"entity\": \"garantiva\"}, {\"entity\": \"regolare\"}, {\"entity\": \"all’alimentazione\"}, {\"entity\": \"nutrizione\"}, {\"entity\": \"ripresa\"}, {\"entity\": \"un’ileostomia a doppia canna\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"anastomosi\"}, {\"entity\": \"garantiva\"}, {\"entity\": \"regolare\"}, {\"entity\": \"all’alimentazione\"}, {\"entity\": \"nutrizione\"}, {\"entity\": \"ripresa\"}, {\"entity\": \"un’ileostomia a doppia canna\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'ricanalizzazione'}, {'entity': 'intervento'}, {'entity': 'La ricanalizzazione intestinale veniva confezionata a distanza di altri 2 mesi'}]\n",
      "in parse_json model_response =  [{'entity': 'ricanalizzazione'}, {'entity': 'intervento'}, {'entity': 'La ricanalizzazione intestinale veniva confezionata a distanza di altri 2 mesi'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ricanalizzazione\"}, {\"entity\": \"intervento\"}, {\"entity\": \"La ricanalizzazione intestinale veniva confezionata a distanza di altri 2 mesi\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ricanalizzazione\"}, {\"entity\": \"intervento\"}, {\"entity\": \"La ricanalizzazione intestinale veniva confezionata a distanza di altri 2 mesi\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ricanalizzazione\"}, {\"entity\": \"intervento\"}, {\"entity\": \"La ricanalizzazione intestinale veniva confezionata a distanza di altri 2 mesi\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'giunta'}, {'entity': 'osservazione'}, {'entity': 'episodio'}, {'entity': 'sospetto'}]\n",
      "in parse_json model_response =  [{'entity': 'giunta'}, {'entity': 'osservazione'}, {'entity': 'episodio'}, {'entity': 'sospetto'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"giunta\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"episodio\"}, {\"entity\": \"sospetto\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"giunta\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"episodio\"}, {\"entity\": \"sospetto\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"giunta\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"episodio\"}, {\"entity\": \"sospetto\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"giungeva\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"perdita\"}, {\"entity\": \"T.I.A\"}, {\"entity\": \"perdita di coscienza\"}, {\"entity\": \"Uomo di 76 anni\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"giungeva\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"perdita\"}, {\"entity\": \"T.I.A\"}, {\"entity\": \"perdita di coscienza\"}, {\"entity\": \"Uomo di 76 anni\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"giungeva\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"perdita\"}, {\"entity\": \"T.I.A\"}, {\"entity\": \"perdita di coscienza\"}, {\"entity\": \"Uomo di 76 anni\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"giungeva\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"perdita\"}, {\"entity\": \"T.I.A\"}, {\"entity\": \"perdita di coscienza\"}, {\"entity\": \"Uomo di 76 anni\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'riferito'}, {'entity': 'decadimento'}, {'entity': 'iniziato'}, {'entity': 'circa 2 anni'}]\n",
      "in parse_json model_response =  [{'entity': 'riferito'}, {'entity': 'decadimento'}, {'entity': 'iniziato'}, {'entity': 'circa 2 anni'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riferito\"}, {\"entity\": \"decadimento\"}, {\"entity\": \"iniziato\"}, {\"entity\": \"circa 2 anni\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riferito\"}, {\"entity\": \"decadimento\"}, {\"entity\": \"iniziato\"}, {\"entity\": \"circa 2 anni\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"riferito\"}, {\"entity\": \"decadimento\"}, {\"entity\": \"iniziato\"}, {\"entity\": \"circa 2 anni\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"riferito\"}, {\"entity\": \"decadimento\"}, {\"entity\": \"iniziato\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"idee\"}, {\"entity\": \"decadimento cognitivo\"}, {\"entity\": \"allucinazioni visive\"}, {\"entity\": \"dai familiari\"}, {\"entity\": \"2 anni prima\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riferito\"}, {\"entity\": \"decadimento\"}, {\"entity\": \"iniziato\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"idee\"}, {\"entity\": \"decadimento cognitivo\"}, {\"entity\": \"allucinazioni visive\"}, {\"entity\": \"dai familiari\"}, {\"entity\": \"2 anni prima\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riferito\"}, {\"entity\": \"decadimento\"}, {\"entity\": \"iniziato\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"idee\"}, {\"entity\": \"decadimento cognitivo\"}, {\"entity\": \"allucinazioni visive\"}, {\"entity\": \"dai familiari\"}, {\"entity\": \"2 anni prima\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"riferito\"}, {\"entity\": \"decadimento\"}, {\"entity\": \"iniziato\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"idee\"}, {\"entity\": \"decadimento cognitivo\"}, {\"entity\": \"allucinazioni visive\"}, {\"entity\": \"dai familiari\"}, {\"entity\": \"2 anni prima\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'esame'}, {'entity': 'esami'}, {'entity': 'EEG'}, {'entity': 'TAC cranio'}, {'entity': 'ecocardio'}, {'entity': 'rx torace'}, {'entity': 'VMD'}, {'entity': 'Torche'}, {'entity': 'inoltre'}, {'entity': 'Dopo'}]\n",
      "in parse_json model_response =  [{'entity': 'esame'}, {'entity': 'esami'}, {'entity': 'EEG'}, {'entity': 'TAC cranio'}, {'entity': 'ecocardio'}, {'entity': 'rx torace'}, {'entity': 'VMD'}, {'entity': 'Torche'}, {'entity': 'inoltre'}, {'entity': 'Dopo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"esami\"}, {\"entity\": \"EEG\"}, {\"entity\": \"TAC cranio\"}, {\"entity\": \"ecocardio\"}, {\"entity\": \"rx torace\"}, {\"entity\": \"VMD\"}, {\"entity\": \"Torche\"}, {\"entity\": \"inoltre\"}, {\"entity\": \"Dopo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"esami\"}, {\"entity\": \"EEG\"}, {\"entity\": \"TAC cranio\"}, {\"entity\": \"ecocardio\"}, {\"entity\": \"rx torace\"}, {\"entity\": \"VMD\"}, {\"entity\": \"Torche\"}, {\"entity\": \"inoltre\"}, {\"entity\": \"Dopo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"esami\"}, {\"entity\": \"EEG\"}, {\"entity\": \"TAC cranio\"}, {\"entity\": \"ecocardio\"}, {\"entity\": \"rx torace\"}, {\"entity\": \"VMD\"}, {\"entity\": \"Torche\"}, {\"entity\": \"inoltre\"}, {\"entity\": \"Dopo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"esami\"}, {\"entity\": \"EEG\"}, {\"entity\": \"TAC\"}, {\"entity\": \"ecocolordoppler\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"rx\"}, {\"entity\": \"VMD\"}, {\"entity\": \"cranio\"}, {\"entity\": \"torace\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"esami\"}, {\"entity\": \"EEG\"}, {\"entity\": \"TAC\"}, {\"entity\": \"ecocolordoppler\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"rx\"}, {\"entity\": \"VMD\"}, {\"entity\": \"cranio\"}, {\"entity\": \"torace\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"esami\"}, {\"entity\": \"EEG\"}, {\"entity\": \"TAC\"}, {\"entity\": \"ecocolordoppler\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"rx\"}, {\"entity\": \"VMD\"}, {\"entity\": \"cranio\"}, {\"entity\": \"torace\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"esami\"}, {\"entity\": \"EEG\"}, {\"entity\": \"TAC\"}, {\"entity\": \"ecocolordoppler\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"rx\"}, {\"entity\": \"VMD\"}, {\"entity\": \"cranio\"}, {\"entity\": \"torace\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'evidenziava'}, {'entity': 'malattia di Fahr'}]\n",
      "in parse_json model_response =  [{'entity': 'evidenziava'}, {'entity': 'malattia di Fahr'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"evidenziava\"}, {\"entity\": \"malattia di Fahr\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"evidenziava\"}, {\"entity\": \"malattia di Fahr\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"evidenziava\"}, {\"entity\": \"malattia di Fahr\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"TAC\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"calcificazioni\"}, {\"entity\": \"Fahr\"}, {\"entity\": \"malattia di Fahr\"}, {\"entity\": \"dei nuclei lenticolari\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"TAC\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"calcificazioni\"}, {\"entity\": \"Fahr\"}, {\"entity\": \"malattia di Fahr\"}, {\"entity\": \"dei nuclei lenticolari\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"TAC\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"calcificazioni\"}, {\"entity\": \"Fahr\"}, {\"entity\": \"malattia di Fahr\"}, {\"entity\": \"dei nuclei lenticolari\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"TAC\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"calcificazioni\"}, {\"entity\": \"Fahr\"}, {\"entity\": \"malattia di Fahr\"}, {\"entity\": \"dei nuclei lenticolari\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Veniva'}, {'entity': 'terapia'}]\n",
      "in parse_json model_response =  [{'entity': 'Veniva'}, {'entity': 'terapia'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Veniva\"}, {\"entity\": \"terapia\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Veniva\"}, {\"entity\": \"terapia\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Veniva\"}, {\"entity\": \"terapia\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"iniziata\"}, {\"entity\": \"citicolina\"}, {\"entity\": \"Aloperidolo\"}, {\"entity\": \"riduzione\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"die\"}, {\"entity\": \"die\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"iniziata\"}, {\"entity\": \"citicolina\"}, {\"entity\": \"Aloperidolo\"}, {\"entity\": \"riduzione\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"die\"}, {\"entity\": \"die\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"iniziata\"}, {\"entity\": \"citicolina\"}, {\"entity\": \"Aloperidolo\"}, {\"entity\": \"riduzione\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"die\"}, {\"entity\": \"die\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"iniziata\"}, {\"entity\": \"citicolina\"}, {\"entity\": \"Aloperidolo\"}, {\"entity\": \"riduzione\"}, {\"entity\": \"allucinazioni\"}, {\"entity\": \"die\"}, {\"entity\": \"die\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'giunge'}, {'entity': 'febbicola'}, {'entity': 'dolor'}]\n",
      "in parse_json model_response =  [{'entity': 'giunge'}, {'entity': 'febbicola'}, {'entity': 'dolor'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"giunge\"}, {\"entity\": \"febbicola\"}, {\"entity\": \"dolor\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"giunge\"}, {\"entity\": \"febbicola\"}, {\"entity\": \"dolor\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"giunge\"}, {\"entity\": \"febbicola\"}, {\"entity\": \"dolor\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"febbricola\"}, {\"entity\": \"dolore in regione laterocervicale\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"febbricola\"}, {\"entity\": \"dolore in regione laterocervicale\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"febbricola\"}, {\"entity\": \"dolore in regione laterocervicale\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"febbricola\"}, {\"entity\": \"dolore in regione laterocervicale\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'riferisce'}, {'entity': 'valori'}, {'entity': 'eseguiti'}]\n",
      "in parse_json model_response =  [{'entity': 'riferisce'}, {'entity': 'valori'}, {'entity': 'eseguiti'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riferisce\"}, {\"entity\": \"valori\"}, {\"entity\": \"eseguiti\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riferisce\"}, {\"entity\": \"valori\"}, {\"entity\": \"eseguiti\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"riferisce\"}, {\"entity\": \"valori\"}, {\"entity\": \"eseguiti\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'mostrano'}, {'entity': 'incremento'}, {'entity': 'positivi'}, {'entity': 'ANA'}, {'entity': 'pattern'}, {'entity': 'titolo'}, {'entity': '83 mm/1h'}, {'entity': '41 mg/L'}]\n",
      "in parse_json model_response =  [{'entity': 'mostrano'}, {'entity': 'incremento'}, {'entity': 'positivi'}, {'entity': 'ANA'}, {'entity': 'pattern'}, {'entity': 'titolo'}, {'entity': '83 mm/1h'}, {'entity': '41 mg/L'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"mostrano\"}, {\"entity\": \"incremento\"}, {\"entity\": \"positivi\"}, {\"entity\": \"ANA\"}, {\"entity\": \"pattern\"}, {\"entity\": \"titolo\"}, {\"entity\": \"83 mm/1h\"}, {\"entity\": \"41 mg/L\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"mostrano\"}, {\"entity\": \"incremento\"}, {\"entity\": \"positivi\"}, {\"entity\": \"ANA\"}, {\"entity\": \"pattern\"}, {\"entity\": \"titolo\"}, {\"entity\": \"83 mm/1h\"}, {\"entity\": \"41 mg/L\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"mostrano\"}, {\"entity\": \"incremento\"}, {\"entity\": \"positivi\"}, {\"entity\": \"ANA\"}, {\"entity\": \"pattern\"}, {\"entity\": \"titolo\"}, {\"entity\": \"83 mm/1h\"}, {\"entity\": \"41 mg/L\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'esame'}, {'entity': 'evidenzia'}, {'entity': 'riduzione'}, {'entity': 'del polso radiale destro'}]\n",
      "in parse_json model_response =  [{'entity': 'esame'}, {'entity': 'evidenzia'}, {'entity': 'riduzione'}, {'entity': 'del polso radiale destro'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"riduzione\"}, {\"entity\": \"del polso radiale destro\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"riduzione\"}, {\"entity\": \"del polso radiale destro\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"riduzione\"}, {\"entity\": \"del polso radiale destro\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"riduzione del polso radiale destro\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riduzione del polso radiale destro\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riduzione del polso radiale destro\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"riduzione del polso radiale destro\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'misurata'}, {'entity': '60 mmHg'}, {'entity': '100/60 mmHg'}, {'entity': 'al braccio sinistro'}, {'entity': '155/85 mmHg'}]\n",
      "in parse_json model_response =  [{'entity': 'misurata'}, {'entity': '60 mmHg'}, {'entity': '100/60 mmHg'}, {'entity': 'al braccio sinistro'}, {'entity': '155/85 mmHg'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"misurata\"}, {\"entity\": \"60 mmHg\"}, {\"entity\": \"100/60 mmHg\"}, {\"entity\": \"al braccio sinistro\"}, {\"entity\": \"155/85 mmHg\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"misurata\"}, {\"entity\": \"60 mmHg\"}, {\"entity\": \"100/60 mmHg\"}, {\"entity\": \"al braccio sinistro\"}, {\"entity\": \"155/85 mmHg\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"misurata\"}, {\"entity\": \"60 mmHg\"}, {\"entity\": \"100/60 mmHg\"}, {\"entity\": \"al braccio sinistro\"}, {\"entity\": \"155/85 mmHg\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'paralisi degli AAII'}]\n",
      "in parse_json model_response =  [{'entity': 'paralisi degli AAII'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"paralisi degli AAII\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"paralisi degli AAII\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"paralisi degli AAII\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"paralisi degli AAII\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"paralisi degli AAII\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"paralisi degli AAII\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"paralisi degli AAII\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Pochi giorni'}, {'entity': 'recidiva'}]\n",
      "in parse_json model_response =  [{'entity': 'Pochi giorni'}, {'entity': 'recidiva'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Pochi giorni\"}, {\"entity\": \"recidiva\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Pochi giorni\"}, {\"entity\": \"recidiva\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Pochi giorni\"}, {\"entity\": \"recidiva\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'impostata'}, {'entity': 'somministrato'}, {'entity': 'Risposta'}]\n",
      "in parse_json model_response =  [{'entity': 'impostata'}, {'entity': 'somministrato'}, {'entity': 'Risposta'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"impostata\"}, {\"entity\": \"somministrato\"}, {\"entity\": \"Risposta\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"impostata\"}, {\"entity\": \"somministrato\"}, {\"entity\": \"Risposta\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"impostata\"}, {\"entity\": \"somministrato\"}, {\"entity\": \"Risposta\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'RMN'}, {'entity': 'rachicentesi'}, {'entity': 'dosaggio'}, {'entity': 'recerca'}, {'entity': 'diagnosi'}]\n",
      "in parse_json model_response =  [{'entity': 'RMN'}, {'entity': 'rachicentesi'}, {'entity': 'dosaggio'}, {'entity': 'recerca'}, {'entity': 'diagnosi'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"RMN\"}, {\"entity\": \"rachicentesi\"}, {\"entity\": \"dosaggio\"}, {\"entity\": \"recerca\"}, {\"entity\": \"diagnosi\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"RMN\"}, {\"entity\": \"rachicentesi\"}, {\"entity\": \"dosaggio\"}, {\"entity\": \"recerca\"}, {\"entity\": \"diagnosi\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"RMN\"}, {\"entity\": \"rachicentesi\"}, {\"entity\": \"dosaggio\"}, {\"entity\": \"recerca\"}, {\"entity\": \"diagnosi\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Vittoria'}, {'entity': 'parto'}, {'entity': 'condizioni'}, {'entity': 'APGAR score'}, {'entity': 'anamnesi'}, {'entity': 'parto spontaneo'}, {'entity': 'buone'}]\n",
      "in parse_json model_response =  [{'entity': 'Vittoria'}, {'entity': 'parto'}, {'entity': 'condizioni'}, {'entity': 'APGAR score'}, {'entity': 'anamnesi'}, {'entity': 'parto spontaneo'}, {'entity': 'buone'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Vittoria\"}, {\"entity\": \"parto\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"APGAR score\"}, {\"entity\": \"anamnesi\"}, {\"entity\": \"parto spontaneo\"}, {\"entity\": \"buone\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Vittoria\"}, {\"entity\": \"parto\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"APGAR score\"}, {\"entity\": \"anamnesi\"}, {\"entity\": \"parto spontaneo\"}, {\"entity\": \"buone\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Vittoria\"}, {\"entity\": \"parto\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"APGAR score\"}, {\"entity\": \"anamnesi\"}, {\"entity\": \"parto spontaneo\"}, {\"entity\": \"buone\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"parto\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"APGAR\"}, {\"entity\": \"anamnesi\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"una bimba\"}, {\"entity\": \"9/9\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"parto\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"APGAR\"}, {\"entity\": \"anamnesi\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"una bimba\"}, {\"entity\": \"9/9\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"parto\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"APGAR\"}, {\"entity\": \"anamnesi\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"una bimba\"}, {\"entity\": \"9/9\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"parto\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"APGAR\"}, {\"entity\": \"anamnesi\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"una bimba\"}, {\"entity\": \"9/9\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'contabilizzata'}]\n",
      "in parse_json model_response =  [{'entity': 'contabilizzata'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"contabilizzata\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"contabilizzata\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"contabilizzata\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"conta\"}, {\"entity\": \"globuli\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"esami\"}, {\"entity\": \"PT\"}, {\"entity\": \"INR\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"fibrinogeno\"}, {\"entity\": \"7000/mmc\"}, {\"entity\": \"10500/mmc\"}, {\"entity\": \"16.6 g/dl\"}, {\"entity\": \"67%\"}, {\"entity\": \"1.3\"}, {\"entity\": \"38.9 sec\"}, {\"entity\": \"1.3\"}, {\"entity\": \"266 mg/dl\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"conta\"}, {\"entity\": \"globuli\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"esami\"}, {\"entity\": \"PT\"}, {\"entity\": \"INR\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"fibrinogeno\"}, {\"entity\": \"7000/mmc\"}, {\"entity\": \"10500/mmc\"}, {\"entity\": \"16.6 g/dl\"}, {\"entity\": \"67%\"}, {\"entity\": \"1.3\"}, {\"entity\": \"38.9 sec\"}, {\"entity\": \"1.3\"}, {\"entity\": \"266 mg/dl\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"conta\"}, {\"entity\": \"globuli\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"esami\"}, {\"entity\": \"PT\"}, {\"entity\": \"INR\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"fibrinogeno\"}, {\"entity\": \"7000/mmc\"}, {\"entity\": \"10500/mmc\"}, {\"entity\": \"16.6 g/dl\"}, {\"entity\": \"67%\"}, {\"entity\": \"1.3\"}, {\"entity\": \"38.9 sec\"}, {\"entity\": \"1.3\"}, {\"entity\": \"266 mg/dl\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"conta\"}, {\"entity\": \"globuli\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"esami\"}, {\"entity\": \"PT\"}, {\"entity\": \"INR\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"aPTT\"}, {\"entity\": \"fibrinogeno\"}, {\"entity\": \"7000/mmc\"}, {\"entity\": \"10500/mmc\"}, {\"entity\": \"16.6 g/dl\"}, {\"entity\": \"67%\"}, {\"entity\": \"1.3\"}, {\"entity\": \"38.9 sec\"}, {\"entity\": \"1.3\"}, {\"entity\": \"266 mg/dl\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'il diametro della milza risulta aumentato'}, {'entity': 'con flusso portale preservato'}, {'entity': '7.5 cm'}]\n",
      "in parse_json model_response =  [{'entity': 'il diametro della milza risulta aumentato'}, {'entity': 'con flusso portale preservato'}, {'entity': '7.5 cm'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"il diametro della milza risulta aumentato\"}, {\"entity\": \"con flusso portale preservato\"}, {\"entity\": \"7.5 cm\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"il diametro della milza risulta aumentato\"}, {\"entity\": \"con flusso portale preservato\"}, {\"entity\": \"7.5 cm\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"il diametro della milza risulta aumentato\"}, {\"entity\": \"con flusso portale preservato\"}, {\"entity\": \"7.5 cm\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"ecografia\"}, {\"entity\": \"diametro\"}, {\"entity\": \"aumentato\"}, {\"entity\": \"flusso\"}, {\"entity\": \"addome\"}, {\"entity\": \"della milza\"}, {\"entity\": \"7.5 cm\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ecografia\"}, {\"entity\": \"diametro\"}, {\"entity\": \"aumentato\"}, {\"entity\": \"flusso\"}, {\"entity\": \"addome\"}, {\"entity\": \"della milza\"}, {\"entity\": \"7.5 cm\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ecografia\"}, {\"entity\": \"diametro\"}, {\"entity\": \"aumentato\"}, {\"entity\": \"flusso\"}, {\"entity\": \"addome\"}, {\"entity\": \"della milza\"}, {\"entity\": \"7.5 cm\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"ecografia\"}, {\"entity\": \"diametro\"}, {\"entity\": \"aumentato\"}, {\"entity\": \"flusso\"}, {\"entity\": \"addome\"}, {\"entity\": \"della milza\"}, {\"entity\": \"7.5 cm\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'sospetto'}, {'entity': 'eseguite'}, {'entity': 'sierologie'}, {'entity': ' risulteranno'}, {'entity': 'Negative'}]\n",
      "in parse_json model_response =  [{'entity': 'sospetto'}, {'entity': 'eseguite'}, {'entity': 'sierologie'}, {'entity': ' risulteranno'}, {'entity': 'Negative'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"sospetto\"}, {\"entity\": \"eseguite\"}, {\"entity\": \"sierologie\"}, {\"entity\": \" risulteranno\"}, {\"entity\": \"Negative\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"sospetto\"}, {\"entity\": \"eseguite\"}, {\"entity\": \"sierologie\"}, {\"entity\": \" risulteranno\"}, {\"entity\": \"Negative\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"sospetto\"}, {\"entity\": \"eseguite\"}, {\"entity\": \"sierologie\"}, {\"entity\": \" risulteranno\"}, {\"entity\": \"Negative\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"causa\"}, {\"entity\": \"Toxoplasma\"}, {\"entity\": \"Rosolia\"}, {\"entity\": \"EBV\"}, {\"entity\": \"CMV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"Listeria\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"negative\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"causa\"}, {\"entity\": \"Toxoplasma\"}, {\"entity\": \"Rosolia\"}, {\"entity\": \"EBV\"}, {\"entity\": \"CMV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"Listeria\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"negative\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"causa\"}, {\"entity\": \"Toxoplasma\"}, {\"entity\": \"Rosolia\"}, {\"entity\": \"EBV\"}, {\"entity\": \"CMV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"Listeria\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"negative\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"causa\"}, {\"entity\": \"Toxoplasma\"}, {\"entity\": \"Rosolia\"}, {\"entity\": \"EBV\"}, {\"entity\": \"CMV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"Listeria\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"negative\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'escludere'}, {'entity': 'ricerca'}, {'entity': 'risultano'}, {'entity': 'anticorpi'}, {'entity': 'piastrinopenia'}, {'entity': 'negativi'}]\n",
      "in parse_json model_response =  [{'entity': 'escludere'}, {'entity': 'ricerca'}, {'entity': 'risultano'}, {'entity': 'anticorpi'}, {'entity': 'piastrinopenia'}, {'entity': 'negativi'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"escludere\"}, {\"entity\": \"ricerca\"}, {\"entity\": \"risultano\"}, {\"entity\": \"anticorpi\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"negativi\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"escludere\"}, {\"entity\": \"ricerca\"}, {\"entity\": \"risultano\"}, {\"entity\": \"anticorpi\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"negativi\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"escludere\"}, {\"entity\": \"ricerca\"}, {\"entity\": \"risultano\"}, {\"entity\": \"anticorpi\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"negativi\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"escludere\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"anticorpi\"}, {\"entity\": \"piastrinopenia da causa autoimmune\"}, {\"entity\": \"negativi\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"escludere\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"anticorpi\"}, {\"entity\": \"piastrinopenia da causa autoimmune\"}, {\"entity\": \"negativi\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"escludere\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"anticorpi\"}, {\"entity\": \"piastrinopenia da causa autoimmune\"}, {\"entity\": \"negativi\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"escludere\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"anticorpi\"}, {\"entity\": \"piastrinopenia da causa autoimmune\"}, {\"entity\": \"negativi\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Vittoria'}, {'entity': 'trasfusioni'}, {'entity': 'segue'}, {'entity': 'incremento'}, {'entity': '14000/mmc'}, {'entity': '16000/mmc'}]\n",
      "in parse_json model_response =  [{'entity': 'Vittoria'}, {'entity': 'trasfusioni'}, {'entity': 'segue'}, {'entity': 'incremento'}, {'entity': '14000/mmc'}, {'entity': '16000/mmc'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Vittoria\"}, {\"entity\": \"trasfusioni\"}, {\"entity\": \"segue\"}, {\"entity\": \"incremento\"}, {\"entity\": \"14000/mmc\"}, {\"entity\": \"16000/mmc\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Vittoria\"}, {\"entity\": \"trasfusioni\"}, {\"entity\": \"segue\"}, {\"entity\": \"incremento\"}, {\"entity\": \"14000/mmc\"}, {\"entity\": \"16000/mmc\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Vittoria\"}, {\"entity\": \"trasfusioni\"}, {\"entity\": \"segue\"}, {\"entity\": \"incremento\"}, {\"entity\": \"14000/mmc\"}, {\"entity\": \"16000/mmc\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"piastrine\"}, {\"entity\": \"incremento\"}, {\"entity\": \"trasfusione\"}, {\"entity\": \"seconda\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"14000/mmc\"}, {\"entity\": \"16000/mmc\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"piastrine\"}, {\"entity\": \"incremento\"}, {\"entity\": \"trasfusione\"}, {\"entity\": \"seconda\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"14000/mmc\"}, {\"entity\": \"16000/mmc\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"piastrine\"}, {\"entity\": \"incremento\"}, {\"entity\": \"trasfusione\"}, {\"entity\": \"seconda\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"14000/mmc\"}, {\"entity\": \"16000/mmc\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"piastrine\"}, {\"entity\": \"incremento\"}, {\"entity\": \"trasfusione\"}, {\"entity\": \"seconda\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"14000/mmc\"}, {\"entity\": \"16000/mmc\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'infuse'}, {'entity': 'immunoglobuline'}, {'entity': 'miglioramento'}]\n",
      "in parse_json model_response =  [{'entity': 'infuse'}, {'entity': 'immunoglobuline'}, {'entity': 'miglioramento'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"infuse\"}, {\"entity\": \"immunoglobuline\"}, {\"entity\": \"miglioramento\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"infuse\"}, {\"entity\": \"immunoglobuline\"}, {\"entity\": \"miglioramento\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"infuse\"}, {\"entity\": \"immunoglobuline\"}, {\"entity\": \"miglioramento\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"infuse\"}, {\"entity\": \"immunoglobuline\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"24h\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"infuse\"}, {\"entity\": \"immunoglobuline\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"24h\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"infuse\"}, {\"entity\": \"immunoglobuline\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"24h\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"infuse\"}, {\"entity\": \"immunoglobuline\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"24h\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'trasferita'}, {'entity': 'persistenza'}, {'entity': 'riceve'}, {'entity': 'trasmissioni'}]\n",
      "in parse_json model_response =  [{'entity': 'trasferita'}, {'entity': 'persistenza'}, {'entity': 'riceve'}, {'entity': 'trasmissioni'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"trasferita\"}, {\"entity\": \"persistenza\"}, {\"entity\": \"riceve\"}, {\"entity\": \"trasmissioni\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"trasferita\"}, {\"entity\": \"persistenza\"}, {\"entity\": \"riceve\"}, {\"entity\": \"trasmissioni\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"trasferita\"}, {\"entity\": \"persistenza\"}, {\"entity\": \"riceve\"}, {\"entity\": \"trasmissioni\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"trasferita\"}, {\"entity\": \"persistenza\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"riceve\"}, {\"entity\": \"trasfusioni\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"La bambina\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"trasferita\"}, {\"entity\": \"persistenza\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"riceve\"}, {\"entity\": \"trasfusioni\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"La bambina\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"trasferita\"}, {\"entity\": \"persistenza\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"riceve\"}, {\"entity\": \"trasfusioni\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"La bambina\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"trasferita\"}, {\"entity\": \"persistenza\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"riceve\"}, {\"entity\": \"trasfusioni\"}, {\"entity\": \"trombocitopenia\"}, {\"entity\": \"La bambina\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  []\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"dimensioni\"}, {\"entity\": \"monitorate\"}, {\"entity\": \"incremento\"}, {\"entity\": \"diametro\"}, {\"entity\": \"ascite\"}, {\"entity\": \"splenomegalia\"}, {\"entity\": \"ascite periepatica\"}, {\"entity\": \"della milza\"}, {\"entity\": \"12 centimetri\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"dimensioni\"}, {\"entity\": \"monitorate\"}, {\"entity\": \"incremento\"}, {\"entity\": \"diametro\"}, {\"entity\": \"ascite\"}, {\"entity\": \"splenomegalia\"}, {\"entity\": \"ascite periepatica\"}, {\"entity\": \"della milza\"}, {\"entity\": \"12 centimetri\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"dimensioni\"}, {\"entity\": \"monitorate\"}, {\"entity\": \"incremento\"}, {\"entity\": \"diametro\"}, {\"entity\": \"ascite\"}, {\"entity\": \"splenomegalia\"}, {\"entity\": \"ascite periepatica\"}, {\"entity\": \"della milza\"}, {\"entity\": \"12 centimetri\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"dimensioni\"}, {\"entity\": \"monitorate\"}, {\"entity\": \"incremento\"}, {\"entity\": \"diametro\"}, {\"entity\": \"ascite\"}, {\"entity\": \"splenomegalia\"}, {\"entity\": \"ascite periepatica\"}, {\"entity\": \"della milza\"}, {\"entity\": \"12 centimetri\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'riscontro'}, {'entity': 'ipoperfusione'}, {'entity': 'ipotrofia'}, {'entity': 'sindrome'}, {'entity': 'indagini'}, {'entity': 'del lobo epatico sinistro'}]\n",
      "in parse_json model_response =  [{'entity': 'riscontro'}, {'entity': 'ipoperfusione'}, {'entity': 'ipotrofia'}, {'entity': 'sindrome'}, {'entity': 'indagini'}, {'entity': 'del lobo epatico sinistro'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riscontro\"}, {\"entity\": \"ipoperfusione\"}, {\"entity\": \"ipotrofia\"}, {\"entity\": \"sindrome\"}, {\"entity\": \"indagini\"}, {\"entity\": \"del lobo epatico sinistro\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riscontro\"}, {\"entity\": \"ipoperfusione\"}, {\"entity\": \"ipotrofia\"}, {\"entity\": \"sindrome\"}, {\"entity\": \"indagini\"}, {\"entity\": \"del lobo epatico sinistro\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"riscontro\"}, {\"entity\": \"ipoperfusione\"}, {\"entity\": \"ipotrofia\"}, {\"entity\": \"sindrome\"}, {\"entity\": \"indagini\"}, {\"entity\": \"del lobo epatico sinistro\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"riscontro\"}, {\"entity\": \"ipoperfusione\"}, {\"entity\": \"ipotrofia\"}, {\"entity\": \"sospettata\"}, {\"entity\": \"Budd-Chiari\"}, {\"entity\": \"confermata\"}, {\"entity\": \"indagini\"}, {\"entity\": \"sindrome di Budd-Chiari\"}, {\"entity\": \"del lobo epatico sinistro\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riscontro\"}, {\"entity\": \"ipoperfusione\"}, {\"entity\": \"ipotrofia\"}, {\"entity\": \"sospettata\"}, {\"entity\": \"Budd-Chiari\"}, {\"entity\": \"confermata\"}, {\"entity\": \"indagini\"}, {\"entity\": \"sindrome di Budd-Chiari\"}, {\"entity\": \"del lobo epatico sinistro\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riscontro\"}, {\"entity\": \"ipoperfusione\"}, {\"entity\": \"ipotrofia\"}, {\"entity\": \"sospettata\"}, {\"entity\": \"Budd-Chiari\"}, {\"entity\": \"confermata\"}, {\"entity\": \"indagini\"}, {\"entity\": \"sindrome di Budd-Chiari\"}, {\"entity\": \"del lobo epatico sinistro\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"riscontro\"}, {\"entity\": \"ipoperfusione\"}, {\"entity\": \"ipotrofia\"}, {\"entity\": \"sospettata\"}, {\"entity\": \"Budd-Chiari\"}, {\"entity\": \"confermata\"}, {\"entity\": \"indagini\"}, {\"entity\": \"sindrome di Budd-Chiari\"}, {\"entity\": \"del lobo epatico sinistro\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'dosaggio'}, {'entity': 'metaboliche'}, {'entity': 'chitotriosidasi'}, {'entity': 'beta-glucosidasi'}, {'entity': 'glicemia'}, {'entity': 'profilo lipidico'}, {'entity': 'escludono'}]\n",
      "in parse_json model_response =  [{'entity': 'dosaggio'}, {'entity': 'metaboliche'}, {'entity': 'chitotriosidasi'}, {'entity': 'beta-glucosidasi'}, {'entity': 'glicemia'}, {'entity': 'profilo lipidico'}, {'entity': 'escludono'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"dosaggio\"}, {\"entity\": \"metaboliche\"}, {\"entity\": \"chitotriosidasi\"}, {\"entity\": \"beta-glucosidasi\"}, {\"entity\": \"glicemia\"}, {\"entity\": \"profilo lipidico\"}, {\"entity\": \"escludono\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"dosaggio\"}, {\"entity\": \"metaboliche\"}, {\"entity\": \"chitotriosidasi\"}, {\"entity\": \"beta-glucosidasi\"}, {\"entity\": \"glicemia\"}, {\"entity\": \"profilo lipidico\"}, {\"entity\": \"escludono\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"dosaggio\"}, {\"entity\": \"metaboliche\"}, {\"entity\": \"chitotriosidasi\"}, {\"entity\": \"beta-glucosidasi\"}, {\"entity\": \"glicemia\"}, {\"entity\": \"profilo lipidico\"}, {\"entity\": \"escludono\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"enzimi\"}, {\"entity\": \"chitotriosidasi\"}, {\"entity\": \"beta-glucosidasi\"}, {\"entity\": \"glicemia\"}, {\"entity\": \"profilo\"}, {\"entity\": \"acidi\"}, {\"entity\": \"escludono\"}, {\"entity\": \"cause\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"enzimi\"}, {\"entity\": \"chitotriosidasi\"}, {\"entity\": \"beta-glucosidasi\"}, {\"entity\": \"glicemia\"}, {\"entity\": \"profilo\"}, {\"entity\": \"acidi\"}, {\"entity\": \"escludono\"}, {\"entity\": \"cause\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"enzimi\"}, {\"entity\": \"chitotriosidasi\"}, {\"entity\": \"beta-glucosidasi\"}, {\"entity\": \"glicemia\"}, {\"entity\": \"profilo\"}, {\"entity\": \"acidi\"}, {\"entity\": \"escludono\"}, {\"entity\": \"cause\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"enzimi\"}, {\"entity\": \"chitotriosidasi\"}, {\"entity\": \"beta-glucosidasi\"}, {\"entity\": \"glicemia\"}, {\"entity\": \"profilo\"}, {\"entity\": \"acidi\"}, {\"entity\": \"escludono\"}, {\"entity\": \"cause\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'conferma'}, {'entity': 'l’aspirato'}, {'entity': 'cellule di accumulo'}, {'entity': 'mostra'}]\n",
      "in parse_json model_response =  [{'entity': 'conferma'}, {'entity': 'l’aspirato'}, {'entity': 'cellule di accumulo'}, {'entity': 'mostra'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"conferma\"}, {\"entity\": \"l’aspirato\"}, {\"entity\": \"cellule di accumulo\"}, {\"entity\": \"mostra\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"conferma\"}, {\"entity\": \"l’aspirato\"}, {\"entity\": \"cellule di accumulo\"}, {\"entity\": \"mostra\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"conferma\"}, {\"entity\": \"l’aspirato\"}, {\"entity\": \"cellule di accumulo\"}, {\"entity\": \"mostra\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"aspirato\"}, {\"entity\": \"conferma\"}, {\"entity\": \"cellule\"}, {\"entity\": \"emopoiesi\"}, {\"entity\": \"normale\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"aspirato\"}, {\"entity\": \"conferma\"}, {\"entity\": \"cellule\"}, {\"entity\": \"emopoiesi\"}, {\"entity\": \"normale\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"aspirato\"}, {\"entity\": \"conferma\"}, {\"entity\": \"cellule\"}, {\"entity\": \"emopoiesi\"}, {\"entity\": \"normale\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"aspirato\"}, {\"entity\": \"conferma\"}, {\"entity\": \"cellule\"}, {\"entity\": \"emopoiesi\"}, {\"entity\": \"normale\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'transaminasi'}, {'entity': 'a1-antitripsina'}, {'entity': 'dosaggio'}, {'entity': 'analisi'}, {'entity': 'evidenzia'}, {'entity': 'infezioni'}, {'entity': 'normali'}, {'entity': 'Le'}]\n",
      "in parse_json model_response =  [{'entity': 'transaminasi'}, {'entity': 'a1-antitripsina'}, {'entity': 'dosaggio'}, {'entity': 'analisi'}, {'entity': 'evidenzia'}, {'entity': 'infezioni'}, {'entity': 'normali'}, {'entity': 'Le'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"transaminasi\"}, {\"entity\": \"a1-antitripsina\"}, {\"entity\": \"dosaggio\"}, {\"entity\": \"analisi\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"infezioni\"}, {\"entity\": \"normali\"}, {\"entity\": \"Le\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"transaminasi\"}, {\"entity\": \"a1-antitripsina\"}, {\"entity\": \"dosaggio\"}, {\"entity\": \"analisi\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"infezioni\"}, {\"entity\": \"normali\"}, {\"entity\": \"Le\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"transaminasi\"}, {\"entity\": \"a1-antitripsina\"}, {\"entity\": \"dosaggio\"}, {\"entity\": \"analisi\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"infezioni\"}, {\"entity\": \"normali\"}, {\"entity\": \"Le\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"transaminasi\"}, {\"entity\": \"antitripsina\"}, {\"entity\": \"proteina\"}, {\"entity\": \"fibrosi\"}, {\"entity\": \"indagini\"}, {\"entity\": \"evidenzano\"}, {\"entity\": \"infezioni\"}, {\"entity\": \"CMV\"}, {\"entity\": \"EBV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"HIV1\"}, {\"entity\": \"HBV\"}, {\"entity\": \"HCV\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"Rubella\"}, {\"entity\": \"normali\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"transaminasi\"}, {\"entity\": \"antitripsina\"}, {\"entity\": \"proteina\"}, {\"entity\": \"fibrosi\"}, {\"entity\": \"indagini\"}, {\"entity\": \"evidenzano\"}, {\"entity\": \"infezioni\"}, {\"entity\": \"CMV\"}, {\"entity\": \"EBV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"HIV1\"}, {\"entity\": \"HBV\"}, {\"entity\": \"HCV\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"Rubella\"}, {\"entity\": \"normali\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"transaminasi\"}, {\"entity\": \"antitripsina\"}, {\"entity\": \"proteina\"}, {\"entity\": \"fibrosi\"}, {\"entity\": \"indagini\"}, {\"entity\": \"evidenzano\"}, {\"entity\": \"infezioni\"}, {\"entity\": \"CMV\"}, {\"entity\": \"EBV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"HIV1\"}, {\"entity\": \"HBV\"}, {\"entity\": \"HCV\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"Rubella\"}, {\"entity\": \"normali\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"transaminasi\"}, {\"entity\": \"antitripsina\"}, {\"entity\": \"proteina\"}, {\"entity\": \"fibrosi\"}, {\"entity\": \"indagini\"}, {\"entity\": \"evidenzano\"}, {\"entity\": \"infezioni\"}, {\"entity\": \"CMV\"}, {\"entity\": \"EBV\"}, {\"entity\": \"HSV\"}, {\"entity\": \"HIV1\"}, {\"entity\": \"HBV\"}, {\"entity\": \"HCV\"}, {\"entity\": \"Parvovirus\"}, {\"entity\": \"Rubella\"}, {\"entity\": \"normali\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'ipersplenismo'}, {'entity': 'splenectomizzata'}]\n",
      "in parse_json model_response =  [{'entity': 'ipersplenismo'}, {'entity': 'splenectomizzata'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ipersplenismo\"}, {\"entity\": \"splenectomizzata\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ipersplenismo\"}, {\"entity\": \"splenectomizzata\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ipersplenismo\"}, {\"entity\": \"splenectomizzata\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"persistenza\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"splenectomizzata\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"Vittoria\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"persistenza\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"splenectomizzata\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"Vittoria\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"persistenza\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"splenectomizzata\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"Vittoria\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"persistenza\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"splenectomizzata\"}, {\"entity\": \"ipersplenismo\"}, {\"entity\": \"Vittoria\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Gli elementi monocitari sono presenti in differenti stadi maturativi'}, {'entity': 'atipie'}]\n",
      "in parse_json model_response =  [{'entity': 'Gli elementi monocitari sono presenti in differenti stadi maturativi'}, {'entity': 'atipie'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Gli elementi monocitari sono presenti in differenti stadi maturativi\"}, {\"entity\": \"atipie\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Gli elementi monocitari sono presenti in differenti stadi maturativi\"}, {\"entity\": \"atipie\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Gli elementi monocitari sono presenti in differenti stadi maturativi\"}, {\"entity\": \"atipie\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"elementi\"}, {\"entity\": \"stadi\"}, {\"entity\": \"atipie\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"elementi\"}, {\"entity\": \"stadi\"}, {\"entity\": \"atipie\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"elementi\"}, {\"entity\": \"stadi\"}, {\"entity\": \"atipie\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"elementi\"}, {\"entity\": \"stadi\"}, {\"entity\": \"atipie\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'leucemia'}, {'entity': 'JMML'}, {'entity': 'confermando'}, {'entity': 'valutazione'}]\n",
      "in parse_json model_response =  [{'entity': 'leucemia'}, {'entity': 'JMML'}, {'entity': 'confermando'}, {'entity': 'valutazione'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"leucemia\"}, {\"entity\": \"JMML\"}, {\"entity\": \"confermando\"}, {\"entity\": \"valutazione\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"leucemia\"}, {\"entity\": \"JMML\"}, {\"entity\": \"confermando\"}, {\"entity\": \"valutazione\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"leucemia\"}, {\"entity\": \"JMML\"}, {\"entity\": \"confermando\"}, {\"entity\": \"valutazione\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"JMML\"}, {\"entity\": \"leucemia\"}, {\"entity\": \"richiesta\"}, {\"entity\": \"fosforilazione\"}, {\"entity\": \"confermando\"}, {\"entity\": \"sospetto\"}, {\"entity\": \"JMML\"}, {\"entity\": \"leucemia giovanile mielomonocitica\"}, {\"entity\": \"patologica\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"JMML\"}, {\"entity\": \"leucemia\"}, {\"entity\": \"richiesta\"}, {\"entity\": \"fosforilazione\"}, {\"entity\": \"confermando\"}, {\"entity\": \"sospetto\"}, {\"entity\": \"JMML\"}, {\"entity\": \"leucemia giovanile mielomonocitica\"}, {\"entity\": \"patologica\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"JMML\"}, {\"entity\": \"leucemia\"}, {\"entity\": \"richiesta\"}, {\"entity\": \"fosforilazione\"}, {\"entity\": \"confermando\"}, {\"entity\": \"sospetto\"}, {\"entity\": \"JMML\"}, {\"entity\": \"leucemia giovanile mielomonocitica\"}, {\"entity\": \"patologica\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"JMML\"}, {\"entity\": \"leucemia\"}, {\"entity\": \"richiesta\"}, {\"entity\": \"fosforilazione\"}, {\"entity\": \"confermando\"}, {\"entity\": \"sospetto\"}, {\"entity\": \"JMML\"}, {\"entity\": \"leucemia giovanile mielomonocitica\"}, {\"entity\": \"patologica\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'alterazioni'}, {'entity': 'nei geni'}, {'entity': 'PTPN11'}, {'entity': 'RAS'}, {'entity': 'JAK2'}]\n",
      "in parse_json model_response =  [{'entity': 'alterazioni'}, {'entity': 'nei geni'}, {'entity': 'PTPN11'}, {'entity': 'RAS'}, {'entity': 'JAK2'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"alterazioni\"}, {\"entity\": \"nei geni\"}, {\"entity\": \"PTPN11\"}, {\"entity\": \"RAS\"}, {\"entity\": \"JAK2\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"alterazioni\"}, {\"entity\": \"nei geni\"}, {\"entity\": \"PTPN11\"}, {\"entity\": \"RAS\"}, {\"entity\": \"JAK2\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"alterazioni\"}, {\"entity\": \"nei geni\"}, {\"entity\": \"PTPN11\"}, {\"entity\": \"RAS\"}, {\"entity\": \"JAK2\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"riscontrano\"}, {\"entity\": \"alterazioni\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riscontrano\"}, {\"entity\": \"alterazioni\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riscontrano\"}, {\"entity\": \"alterazioni\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"riscontrano\"}, {\"entity\": \"alterazioni\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'mostre tessuto emopoietico con displasia maturativa'}, {'entity': 'emosiderosi'}]\n",
      "in parse_json model_response =  [{'entity': 'mostre tessuto emopoietico con displasia maturativa'}, {'entity': 'emosiderosi'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"mostre tessuto emopoietico con displasia maturativa\"}, {\"entity\": \"emosiderosi\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"mostre tessuto emopoietico con displasia maturativa\"}, {\"entity\": \"emosiderosi\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"mostre tessuto emopoietico con displasia maturativa\"}, {\"entity\": \"emosiderosi\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"tessuto\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"displasia\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"della milza\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"tessuto\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"displasia\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"della milza\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"tessuto\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"displasia\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"della milza\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"tessuto\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"displasia\"}, {\"entity\": \"fagocitosi\"}, {\"entity\": \"emosiderosi\"}, {\"entity\": \"della milza\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'evidenzia'}, {'entity': 'blasti'}]\n",
      "in parse_json model_response =  [{'entity': 'evidenzia'}, {'entity': 'blasti'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"evidenzia\"}, {\"entity\": \"blasti\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"evidenzia\"}, {\"entity\": \"blasti\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"evidenzia\"}, {\"entity\": \"blasti\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"valutazione\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"blasti\"}, {\"entity\": \"tessuto splenico\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"valutazione\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"blasti\"}, {\"entity\": \"tessuto splenico\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"valutazione\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"blasti\"}, {\"entity\": \"tessuto splenico\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"valutazione\"}, {\"entity\": \"evidenzia\"}, {\"entity\": \"blasti\"}, {\"entity\": \"tessuto splenico\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Vittoria'}]\n",
      "in parse_json model_response =  [{'entity': 'Vittoria'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Vittoria\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Vittoria\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Vittoria\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"inizia\"}, {\"entity\": \"isotretinoina\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"cellule staminali ematopoietiche\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"donatore non famigliare\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"inizia\"}, {\"entity\": \"isotretinoina\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"cellule staminali ematopoietiche\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"donatore non famigliare\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"inizia\"}, {\"entity\": \"isotretinoina\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"cellule staminali ematopoietiche\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"donatore non famigliare\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"inizia\"}, {\"entity\": \"isotretinoina\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"cellule staminali ematopoietiche\"}, {\"entity\": \"Vittoria\"}, {\"entity\": \"donatore non famigliare\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'osservazione'}, {'entity': 'giunto'}, {'entity': 'anemia'}, {'entity': 'neutropenia'}, {'entity': 'Hb'}, {'entity': 'N'}]\n",
      "in parse_json model_response =  [{'entity': 'osservazione'}, {'entity': 'giunto'}, {'entity': 'anemia'}, {'entity': 'neutropenia'}, {'entity': 'Hb'}, {'entity': 'N'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"osservazione\"}, {\"entity\": \"giunto\"}, {\"entity\": \"anemia\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"Hb\"}, {\"entity\": \"N\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"osservazione\"}, {\"entity\": \"giunto\"}, {\"entity\": \"anemia\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"Hb\"}, {\"entity\": \"N\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"osservazione\"}, {\"entity\": \"giunto\"}, {\"entity\": \"anemia\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"Hb\"}, {\"entity\": \"N\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"giunto\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"anemia\"}, {\"entity\": \"Hb\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"C.G.\"}, {\"entity\": \"4.5 gr/d\"}, {\"entity\": \"420/uL\"}, {\"entity\": \"nel novembre 2009\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"giunto\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"anemia\"}, {\"entity\": \"Hb\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"C.G.\"}, {\"entity\": \"4.5 gr/d\"}, {\"entity\": \"420/uL\"}, {\"entity\": \"nel novembre 2009\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"giunto\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"anemia\"}, {\"entity\": \"Hb\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"C.G.\"}, {\"entity\": \"4.5 gr/d\"}, {\"entity\": \"420/uL\"}, {\"entity\": \"nel novembre 2009\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"giunto\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"anemia\"}, {\"entity\": \"Hb\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"C.G.\"}, {\"entity\": \"4.5 gr/d\"}, {\"entity\": \"420/uL\"}, {\"entity\": \"nel novembre 2009\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'anamnesi'}, {'entity': 'fratellino'}, {'entity': 'piastrinopenia'}, {'entity': 'insorta'}, {'entity': 'Plt'}]\n",
      "in parse_json model_response =  [{'entity': 'anamnesi'}, {'entity': 'fratellino'}, {'entity': 'piastrinopenia'}, {'entity': 'insorta'}, {'entity': 'Plt'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anamnesi\"}, {\"entity\": \"fratellino\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"insorta\"}, {\"entity\": \"Plt\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anamnesi\"}, {\"entity\": \"fratellino\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"insorta\"}, {\"entity\": \"Plt\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"anamnesi\"}, {\"entity\": \"fratellino\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"insorta\"}, {\"entity\": \"Plt\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"anamnesi\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"insorta\"}, {\"entity\": \"salute\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"un fratellino di 18 mesi\"}, {\"entity\": \"C.L.\"}, {\"entity\": \"una sorellina di 5 mesi\"}, {\"entity\": \"90000 u/L\"}, {\"entity\": \"nel luglio 2009\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anamnesi\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"insorta\"}, {\"entity\": \"salute\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"un fratellino di 18 mesi\"}, {\"entity\": \"C.L.\"}, {\"entity\": \"una sorellina di 5 mesi\"}, {\"entity\": \"90000 u/L\"}, {\"entity\": \"nel luglio 2009\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anamnesi\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"insorta\"}, {\"entity\": \"salute\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"un fratellino di 18 mesi\"}, {\"entity\": \"C.L.\"}, {\"entity\": \"una sorellina di 5 mesi\"}, {\"entity\": \"90000 u/L\"}, {\"entity\": \"nel luglio 2009\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"anamnesi\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"insorta\"}, {\"entity\": \"salute\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"un fratellino di 18 mesi\"}, {\"entity\": \"C.L.\"}, {\"entity\": \"una sorellina di 5 mesi\"}, {\"entity\": \"90000 u/L\"}, {\"entity\": \"nel luglio 2009\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'macrocitosi'}, {'entity': 'incremento'}, {'entity': 'eritropoietina'}, {'entity': 'vitamina'}, {'entity': '10.2%'}, {'entity': '512 mU/mL'}, {'entity': '1149 pg/mL'}]\n",
      "in parse_json model_response =  [{'entity': 'macrocitosi'}, {'entity': 'incremento'}, {'entity': 'eritropoietina'}, {'entity': 'vitamina'}, {'entity': '10.2%'}, {'entity': '512 mU/mL'}, {'entity': '1149 pg/mL'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"macrocitosi\"}, {\"entity\": \"incremento\"}, {\"entity\": \"eritropoietina\"}, {\"entity\": \"vitamina\"}, {\"entity\": \"10.2%\"}, {\"entity\": \"512 mU/mL\"}, {\"entity\": \"1149 pg/mL\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"macrocitosi\"}, {\"entity\": \"incremento\"}, {\"entity\": \"eritropoietina\"}, {\"entity\": \"vitamina\"}, {\"entity\": \"10.2%\"}, {\"entity\": \"512 mU/mL\"}, {\"entity\": \"1149 pg/mL\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"macrocitosi\"}, {\"entity\": \"incremento\"}, {\"entity\": \"eritropoietina\"}, {\"entity\": \"vitamina\"}, {\"entity\": \"10.2%\"}, {\"entity\": \"512 mU/mL\"}, {\"entity\": \"1149 pg/mL\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esami\"}, {\"entity\": \"mostravano\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"MCV\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"HbF\"}, {\"entity\": \"eritropoietina\"}, {\"entity\": \"B12\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"96 fL\"}, {\"entity\": \"10.2%\"}, {\"entity\": \"512 mU/mL\"}, {\"entity\": \"1149 pg/mL\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esami\"}, {\"entity\": \"mostravano\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"MCV\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"HbF\"}, {\"entity\": \"eritropoietina\"}, {\"entity\": \"B12\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"96 fL\"}, {\"entity\": \"10.2%\"}, {\"entity\": \"512 mU/mL\"}, {\"entity\": \"1149 pg/mL\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esami\"}, {\"entity\": \"mostravano\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"MCV\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"HbF\"}, {\"entity\": \"eritropoietina\"}, {\"entity\": \"B12\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"96 fL\"}, {\"entity\": \"10.2%\"}, {\"entity\": \"512 mU/mL\"}, {\"entity\": \"1149 pg/mL\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esami\"}, {\"entity\": \"mostravano\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"MCV\"}, {\"entity\": \"emoglobina\"}, {\"entity\": \"HbF\"}, {\"entity\": \"eritropoietina\"}, {\"entity\": \"B12\"}, {\"entity\": \"macrocitosi\"}, {\"entity\": \"96 fL\"}, {\"entity\": \"10.2%\"}, {\"entity\": \"512 mU/mL\"}, {\"entity\": \"1149 pg/mL\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'esame'}, {'entity': 'evidenziava'}, {'entity': 'studio'}, {'entity': 'metafasi'}, {'entity': 'monosomia'}, {'entity': 'del cromosoma 7'}, {'entity': 'della metafisi'}]\n",
      "in parse_json model_response =  [{'entity': 'esame'}, {'entity': 'evidenziava'}, {'entity': 'studio'}, {'entity': 'metafasi'}, {'entity': 'monosomia'}, {'entity': 'del cromosoma 7'}, {'entity': 'della metafisi'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"studio\"}, {\"entity\": \"metafasi\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"del cromosoma 7\"}, {\"entity\": \"della metafisi\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"studio\"}, {\"entity\": \"metafasi\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"del cromosoma 7\"}, {\"entity\": \"della metafisi\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"studio\"}, {\"entity\": \"metafasi\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"del cromosoma 7\"}, {\"entity\": \"della metafisi\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"displasia\"}, {\"entity\": \"studio\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"displasia\"}, {\"entity\": \"monosomia del cromosoma 7\"}, {\"entity\": \"del sangue periferico\"}, {\"entity\": \"SP\"}, {\"entity\": \"midollo osseo\"}, {\"entity\": \"MO\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"displasia\"}, {\"entity\": \"studio\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"displasia\"}, {\"entity\": \"monosomia del cromosoma 7\"}, {\"entity\": \"del sangue periferico\"}, {\"entity\": \"SP\"}, {\"entity\": \"midollo osseo\"}, {\"entity\": \"MO\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"displasia\"}, {\"entity\": \"studio\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"displasia\"}, {\"entity\": \"monosomia del cromosoma 7\"}, {\"entity\": \"del sangue periferico\"}, {\"entity\": \"SP\"}, {\"entity\": \"midollo osseo\"}, {\"entity\": \"MO\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"displasia\"}, {\"entity\": \"studio\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"displasia\"}, {\"entity\": \"monosomia del cromosoma 7\"}, {\"entity\": \"del sangue periferico\"}, {\"entity\": \"SP\"}, {\"entity\": \"midollo osseo\"}, {\"entity\": \"MO\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'SMD'}, {'entity': 'ipotesi'}, {'entity': 'indicazione'}, {'entity': 'avviata'}, {'entity': 'tipizzazione'}, {'entity': 'studio'}, {'entity': 'Nel’ipotesi di una sindrome mielodisplastica'}, {'entity': 'della fratria'}]\n",
      "in parse_json model_response =  [{'entity': 'SMD'}, {'entity': 'ipotesi'}, {'entity': 'indicazione'}, {'entity': 'avviata'}, {'entity': 'tipizzazione'}, {'entity': 'studio'}, {'entity': 'Nel’ipotesi di una sindrome mielodisplastica'}, {'entity': 'della fratria'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"SMD\"}, {\"entity\": \"ipotesi\"}, {\"entity\": \"indicazione\"}, {\"entity\": \"avviata\"}, {\"entity\": \"tipizzazione\"}, {\"entity\": \"studio\"}, {\"entity\": \"Nel’ipotesi di una sindrome mielodisplastica\"}, {\"entity\": \"della fratria\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"SMD\"}, {\"entity\": \"ipotesi\"}, {\"entity\": \"indicazione\"}, {\"entity\": \"avviata\"}, {\"entity\": \"tipizzazione\"}, {\"entity\": \"studio\"}, {\"entity\": \"Nel’ipotesi di una sindrome mielodisplastica\"}, {\"entity\": \"della fratria\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"SMD\"}, {\"entity\": \"ipotesi\"}, {\"entity\": \"indicazione\"}, {\"entity\": \"avviata\"}, {\"entity\": \"tipizzazione\"}, {\"entity\": \"studio\"}, {\"entity\": \"Nel’ipotesi di una sindrome mielodisplastica\"}, {\"entity\": \"della fratria\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"sindrome\"}, {\"entity\": \"SMD\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"avviata\"}, {\"entity\": \"tipizzazione\"}, {\"entity\": \"studio\"}, {\"entity\": \"sindrome mielodisplastica (SMD) de novo\"}, {\"entity\": \"SMD\"}, {\"entity\": \"midollo osseo\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"sindrome\"}, {\"entity\": \"SMD\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"avviata\"}, {\"entity\": \"tipizzazione\"}, {\"entity\": \"studio\"}, {\"entity\": \"sindrome mielodisplastica (SMD) de novo\"}, {\"entity\": \"SMD\"}, {\"entity\": \"midollo osseo\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"sindrome\"}, {\"entity\": \"SMD\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"avviata\"}, {\"entity\": \"tipizzazione\"}, {\"entity\": \"studio\"}, {\"entity\": \"sindrome mielodisplastica (SMD) de novo\"}, {\"entity\": \"SMD\"}, {\"entity\": \"midollo osseo\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"sindrome\"}, {\"entity\": \"SMD\"}, {\"entity\": \"trapianto\"}, {\"entity\": \"avviata\"}, {\"entity\": \"tipizzazione\"}, {\"entity\": \"studio\"}, {\"entity\": \"sindrome mielodisplastica (SMD) de novo\"}, {\"entity\": \"SMD\"}, {\"entity\": \"midollo osseo\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  []\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esami\"}, {\"entity\": \"sul fratello minore\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esami\"}, {\"entity\": \"sul fratello minore\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esami\"}, {\"entity\": \"sul fratello minore\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esami\"}, {\"entity\": \"sul fratello minore\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'mostrato'}, {'entity': 'neutropenia'}, {'entity': 'piastrinopenia'}, {'entity': 'HbF'}, {'entity': 'Neutropenia'}, {'entity': 'piastrinopenia'}, {'entity': '69000'}, {'entity': '1100 u/L'}, {'entity': '7.5%'}, {'entity': 'L.'}]\n",
      "in parse_json model_response =  [{'entity': 'mostrato'}, {'entity': 'neutropenia'}, {'entity': 'piastrinopenia'}, {'entity': 'HbF'}, {'entity': 'Neutropenia'}, {'entity': 'piastrinopenia'}, {'entity': '69000'}, {'entity': '1100 u/L'}, {'entity': '7.5%'}, {'entity': 'L.'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"mostrato\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"HbF\"}, {\"entity\": \"Neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"69000\"}, {\"entity\": \"1100 u/L\"}, {\"entity\": \"7.5%\"}, {\"entity\": \"L.\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"mostrato\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"HbF\"}, {\"entity\": \"Neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"69000\"}, {\"entity\": \"1100 u/L\"}, {\"entity\": \"7.5%\"}, {\"entity\": \"L.\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"mostrato\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"HbF\"}, {\"entity\": \"Neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"69000\"}, {\"entity\": \"1100 u/L\"}, {\"entity\": \"7.5%\"}, {\"entity\": \"L.\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"mostrato\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"HbF\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"1100 u/L\"}, {\"entity\": \"69000\"}, {\"entity\": \"7.5%\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"mostrato\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"HbF\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"1100 u/L\"}, {\"entity\": \"69000\"}, {\"entity\": \"7.5%\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"mostrato\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"HbF\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"1100 u/L\"}, {\"entity\": \"69000\"}, {\"entity\": \"7.5%\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"mostrato\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"N\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"Plt\"}, {\"entity\": \"HbF\"}, {\"entity\": \"neutropenia\"}, {\"entity\": \"piastrinopenia\"}, {\"entity\": \"1100 u/L\"}, {\"entity\": \"69000\"}, {\"entity\": \"7.5%\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'esame'}, {'entity': 'es Conefermata'}, {'entity': 'biopsia'}, {'entity': 'cariotipo'}, {'entity': 'del(7)(q22) 46, XY  I controlli'}]\n",
      "in parse_json model_response =  [{'entity': 'esame'}, {'entity': 'es Conefermata'}, {'entity': 'biopsia'}, {'entity': 'cariotipo'}, {'entity': 'del(7)(q22) 46, XY  I controlli'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"es Conefermata\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"cariotipo\"}, {\"entity\": \"del(7)(q22) 46, XY  I controlli\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"es Conefermata\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"cariotipo\"}, {\"entity\": \"del(7)(q22) 46, XY  I controlli\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"es Conefermata\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"cariotipo\"}, {\"entity\": \"del(7)(q22) 46, XY  I controlli\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziato\"}, {\"entity\": \"displasia\"}, {\"entity\": \"confermata\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"studio\"}, {\"entity\": \"delezione\"}, {\"entity\": \"ontrolli \"}, {\"entity\": \"displasia\"}, {\"entity\": \"SP\"}, {\"entity\": \"MO\"}, {\"entity\": \"enitori \"}, {\"entity\": \"orella minore \"}, {\"entity\": \"egativi.\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziato\"}, {\"entity\": \"displasia\"}, {\"entity\": \"confermata\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"studio\"}, {\"entity\": \"delezione\"}, {\"entity\": \"ontrolli \"}, {\"entity\": \"displasia\"}, {\"entity\": \"SP\"}, {\"entity\": \"MO\"}, {\"entity\": \"enitori \"}, {\"entity\": \"orella minore \"}, {\"entity\": \"egativi.\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziato\"}, {\"entity\": \"displasia\"}, {\"entity\": \"confermata\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"studio\"}, {\"entity\": \"delezione\"}, {\"entity\": \"ontrolli \"}, {\"entity\": \"displasia\"}, {\"entity\": \"SP\"}, {\"entity\": \"MO\"}, {\"entity\": \"enitori \"}, {\"entity\": \"orella minore \"}, {\"entity\": \"egativi.\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"evidenziato\"}, {\"entity\": \"displasia\"}, {\"entity\": \"confermata\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"studio\"}, {\"entity\": \"delezione\"}, {\"entity\": \"ontrolli \"}, {\"entity\": \"displasia\"}, {\"entity\": \"SP\"}, {\"entity\": \"MO\"}, {\"entity\": \"enitori \"}, {\"entity\": \"orella minore \"}, {\"entity\": \"egativi.\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'SMD'}, {'entity': 'excludere'}, {'entity': 'sinomia'}, {'entity': 'sindrome da insufficienzia midollare congenita'}, {'entity': 'DEB test'}, {'entity': 'ricerca'}, {'entity': 'dellaSMD'}]\n",
      "in parse_json model_response =  [{'entity': 'SMD'}, {'entity': 'excludere'}, {'entity': 'sinomia'}, {'entity': 'sindrome da insufficienzia midollare congenita'}, {'entity': 'DEB test'}, {'entity': 'ricerca'}, {'entity': 'dellaSMD'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"SMD\"}, {\"entity\": \"excludere\"}, {\"entity\": \"sinomia\"}, {\"entity\": \"sindrome da insufficienzia midollare congenita\"}, {\"entity\": \"DEB test\"}, {\"entity\": \"ricerca\"}, {\"entity\": \"dellaSMD\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"SMD\"}, {\"entity\": \"excludere\"}, {\"entity\": \"sinomia\"}, {\"entity\": \"sindrome da insufficienzia midollare congenita\"}, {\"entity\": \"DEB test\"}, {\"entity\": \"ricerca\"}, {\"entity\": \"dellaSMD\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"SMD\"}, {\"entity\": \"excludere\"}, {\"entity\": \"sinomia\"}, {\"entity\": \"sindrome da insufficienzia midollare congenita\"}, {\"entity\": \"DEB test\"}, {\"entity\": \"ricerca\"}, {\"entity\": \"dellaSMD\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"scludere \"}, {\"entity\": \"MD \"}, {\"entity\": \"EB \"}, {\"entity\": \"icerca \"}, {\"entity\": \"MD \"}, {\"entity\": \"indrome da insufficienza midollare congenita \"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"scludere \"}, {\"entity\": \"MD \"}, {\"entity\": \"EB \"}, {\"entity\": \"icerca \"}, {\"entity\": \"MD \"}, {\"entity\": \"indrome da insufficienza midollare congenita \"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"scludere \"}, {\"entity\": \"MD \"}, {\"entity\": \"EB \"}, {\"entity\": \"icerca \"}, {\"entity\": \"MD \"}, {\"entity\": \"indrome da insufficienza midollare congenita \"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"scludere \"}, {\"entity\": \"MD \"}, {\"entity\": \"EB \"}, {\"entity\": \"icerca \"}, {\"entity\": \"MD \"}, {\"entity\": \"indrome da insufficienza midollare congenita \"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'avviato'}, {'entity': 'el giugno 2010'}]\n",
      "in parse_json model_response =  [{'entity': 'avviato'}, {'entity': 'el giugno 2010'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"avviato\"}, {\"entity\": \"el giugno 2010\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"avviato\"}, {\"entity\": \"el giugno 2010\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"avviato\"}, {\"entity\": \"el giugno 2010\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"vviato \"}, {\"entity\": \"MO \"}, {\"entity\": \"ondizionamento \"}, {\"entity\": \".G. \"}, {\"entity\": \"el giugno 2010 \"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"vviato \"}, {\"entity\": \"MO \"}, {\"entity\": \"ondizionamento \"}, {\"entity\": \".G. \"}, {\"entity\": \"el giugno 2010 \"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"vviato \"}, {\"entity\": \"MO \"}, {\"entity\": \"ondizionamento \"}, {\"entity\": \".G. \"}, {\"entity\": \"el giugno 2010 \"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"vviato \"}, {\"entity\": \"MO \"}, {\"entity\": \"ondizionamento \"}, {\"entity\": \".G. \"}, {\"entity\": \"el giugno 2010 \"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'decorso'}, {'entity': 'GVHD'}, {'entity': 'epatopatia'}, {'entity': 'giorno + 43'}, {'entity': 'decesso'}]\n",
      "in parse_json model_response =  [{'entity': 'decorso'}, {'entity': 'GVHD'}, {'entity': 'epatopatia'}, {'entity': 'giorno + 43'}, {'entity': 'decesso'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"decorso\"}, {\"entity\": \"GVHD\"}, {\"entity\": \"epatopatia\"}, {\"entity\": \"giorno + 43\"}, {\"entity\": \"decesso\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"decorso\"}, {\"entity\": \"GVHD\"}, {\"entity\": \"epatopatia\"}, {\"entity\": \"giorno + 43\"}, {\"entity\": \"decesso\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"decorso\"}, {\"entity\": \"GVHD\"}, {\"entity\": \"epatopatia\"}, {\"entity\": \"giorno + 43\"}, {\"entity\": \"decesso\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"ecorso \"}, {\"entity\": \"omplicato \"}, {\"entity\": \"VHD \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"ecesso,\"}, {\"entity\": \"VHD acuta cutanea ed intestinale,\"}, {\"entity\": \"VHD acuta cutanea \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"iorno + 43.\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ecorso \"}, {\"entity\": \"omplicato \"}, {\"entity\": \"VHD \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"ecesso,\"}, {\"entity\": \"VHD acuta cutanea ed intestinale,\"}, {\"entity\": \"VHD acuta cutanea \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"iorno + 43.\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ecorso \"}, {\"entity\": \"omplicato \"}, {\"entity\": \"VHD \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"ecesso,\"}, {\"entity\": \"VHD acuta cutanea ed intestinale,\"}, {\"entity\": \"VHD acuta cutanea \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"iorno + 43.\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"ecorso \"}, {\"entity\": \"omplicato \"}, {\"entity\": \"VHD \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"ecesso,\"}, {\"entity\": \"VHD acuta cutanea ed intestinale,\"}, {\"entity\": \"VHD acuta cutanea \"}, {\"entity\": \"patopatia \"}, {\"entity\": \"iorno + 43.\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'monosomia familiare'}, {'entity': 'monosomia'}, {'entity': 'delezione'}, {'entity': 'del 7'}, {'entity': 'due o più membri'}]\n",
      "in parse_json model_response =  [{'entity': 'monosomia familiare'}, {'entity': 'monosomia'}, {'entity': 'delezione'}, {'entity': 'del 7'}, {'entity': 'due o più membri'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"monosomia familiare\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"delezione\"}, {\"entity\": \"del 7\"}, {\"entity\": \"due o più membri\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"monosomia familiare\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"delezione\"}, {\"entity\": \"del 7\"}, {\"entity\": \"due o più membri\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"monosomia familiare\"}, {\"entity\": \"monosomia\"}, {\"entity\": \"delezione\"}, {\"entity\": \"del 7\"}, {\"entity\": \"due o più membri\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"onosomia \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"elezione \"}, {\"entity\": \"ue o più membri della stessa famiglia.\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"onosomia \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"elezione \"}, {\"entity\": \"ue o più membri della stessa famiglia.\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"onosomia \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"elezione \"}, {\"entity\": \"ue o più membri della stessa famiglia.\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"onosomia \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"elezione \"}, {\"entity\": \"ue o più membri della stessa famiglia.\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'ereditata'}, {'entity': 'penetranza'}, {'entity': 'erdiabilità'}]\n",
      "in parse_json model_response =  [{'entity': 'ereditata'}, {'entity': 'penetranza'}, {'entity': 'erdiabilità'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ereditata\"}, {\"entity\": \"penetranza\"}, {\"entity\": \"erdiabilità\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ereditata\"}, {\"entity\": \"penetranza\"}, {\"entity\": \"erdiabilità\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ereditata\"}, {\"entity\": \"penetranza\"}, {\"entity\": \"erdiabilità\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"redisposizione \"}, {\"entity\": \"reditata \"}, {\"entity\": \"robabilità \"}, {\"entity\": \"mmalare.\"}, {\"entity\": \"a fratria del probando \"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"redisposizione \"}, {\"entity\": \"reditata \"}, {\"entity\": \"robabilità \"}, {\"entity\": \"mmalare.\"}, {\"entity\": \"a fratria del probando \"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"redisposizione \"}, {\"entity\": \"reditata \"}, {\"entity\": \"robabilità \"}, {\"entity\": \"mmalare.\"}, {\"entity\": \"a fratria del probando \"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"redisposizione \"}, {\"entity\": \"reditata \"}, {\"entity\": \"robabilità \"}, {\"entity\": \"mmalare.\"}, {\"entity\": \"a fratria del probando \"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'emopatia'}, {'entity': 'descritte'}]\n",
      "in parse_json model_response =  [{'entity': 'emopatia'}, {'entity': 'descritte'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"emopatia\"}, {\"entity\": \"descritte\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"emopatia\"}, {\"entity\": \"descritte\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"emopatia\"}, {\"entity\": \"descritte\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"escritte \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"mopatia.\"}, {\"entity\": \"4 famiglie \"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"escritte \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"mopatia.\"}, {\"entity\": \"4 famiglie \"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"escritte \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"mopatia.\"}, {\"entity\": \"4 famiglie \"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"escritte \"}, {\"entity\": \"onosomia \"}, {\"entity\": \"mopatia.\"}, {\"entity\": \"4 famiglie \"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'd’elezione'}]\n",
      "in parse_json model_response =  [{'entity': 'd’elezione'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"d’elezione\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"d’elezione\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"d’elezione\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"erapia \"}, {\"entity\": \"MO.\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"erapia \"}, {\"entity\": \"MO.\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"erapia \"}, {\"entity\": \"MO.\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"erapia \"}, {\"entity\": \"MO.\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'rischio'}, {'entity': 'SMD'}, {'entity': 'LMA'}, {'entity': 'applicare'}, {'entity': 'protocolli'}, {'entity': 'de novo'}]\n",
      "in parse_json model_response =  [{'entity': 'rischio'}, {'entity': 'SMD'}, {'entity': 'LMA'}, {'entity': 'applicare'}, {'entity': 'protocolli'}, {'entity': 'de novo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"rischio\"}, {\"entity\": \"SMD\"}, {\"entity\": \"LMA\"}, {\"entity\": \"applicare\"}, {\"entity\": \"protocolli\"}, {\"entity\": \"de novo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"rischio\"}, {\"entity\": \"SMD\"}, {\"entity\": \"LMA\"}, {\"entity\": \"applicare\"}, {\"entity\": \"protocolli\"}, {\"entity\": \"de novo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"rischio\"}, {\"entity\": \"SMD\"}, {\"entity\": \"LMA\"}, {\"entity\": \"applicare\"}, {\"entity\": \"protocolli\"}, {\"entity\": \"de novo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"oto \"}, {\"entity\": \"ischio \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"orretto \"}, {\"entity\": \"indrome \"}, {\"entity\": \"rotocolli \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"ei pazienti \"}, {\"entity\": \"ei pazienti con forme de novo.\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"oto \"}, {\"entity\": \"ischio \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"orretto \"}, {\"entity\": \"indrome \"}, {\"entity\": \"rotocolli \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"ei pazienti \"}, {\"entity\": \"ei pazienti con forme de novo.\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"oto \"}, {\"entity\": \"ischio \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"orretto \"}, {\"entity\": \"indrome \"}, {\"entity\": \"rotocolli \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"ei pazienti \"}, {\"entity\": \"ei pazienti con forme de novo.\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"oto \"}, {\"entity\": \"ischio \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"orretto \"}, {\"entity\": \"indrome \"}, {\"entity\": \"rotocolli \"}, {\"entity\": \"MD \"}, {\"entity\": \"MA \"}, {\"entity\": \"ei pazienti \"}, {\"entity\": \"ei pazienti con forme de novo.\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'mostra'}, {'entity': 'quadro'}, {'entity': 'é'}, {'entity': 'TMO'}, {'entity': 'l piccolo C.L.'}]\n",
      "in parse_json model_response =  [{'entity': 'mostra'}, {'entity': 'quadro'}, {'entity': 'é'}, {'entity': 'TMO'}, {'entity': 'l piccolo C.L.'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"mostra\"}, {\"entity\": \"quadro\"}, {\"entity\": \"é\"}, {\"entity\": \"TMO\"}, {\"entity\": \"l piccolo C.L.\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"mostra\"}, {\"entity\": \"quadro\"}, {\"entity\": \"é\"}, {\"entity\": \"TMO\"}, {\"entity\": \"l piccolo C.L.\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"mostra\"}, {\"entity\": \"quadro\"}, {\"entity\": \"é\"}, {\"entity\": \"TMO\"}, {\"entity\": \"l piccolo C.L.\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"uadro \"}, {\"entity\": \"MO.\"}, {\"entity\": \"l piccolo C.L. \"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"uadro \"}, {\"entity\": \"MO.\"}, {\"entity\": \"l piccolo C.L. \"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"uadro \"}, {\"entity\": \"MO.\"}, {\"entity\": \"l piccolo C.L. \"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"uadro \"}, {\"entity\": \"MO.\"}, {\"entity\": \"l piccolo C.L. \"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'AAMC'}, {'entity': 'giunta'}, {'entity': 'esordita'}, {'entity': 'SNC'}, {'entity': 'paziente venezuelana'}, {'entity': '9 mesi'}, {'entity': 'LAM M1-M2'}, {'entity': '18 anni'}]\n",
      "in parse_json model_response =  [{'entity': 'AAMC'}, {'entity': 'giunta'}, {'entity': 'esordita'}, {'entity': 'SNC'}, {'entity': 'paziente venezuelana'}, {'entity': '9 mesi'}, {'entity': 'LAM M1-M2'}, {'entity': '18 anni'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"AAMC\"}, {\"entity\": \"giunta\"}, {\"entity\": \"esordita\"}, {\"entity\": \"SNC\"}, {\"entity\": \"paziente venezuelana\"}, {\"entity\": \"9 mesi\"}, {\"entity\": \"LAM M1-M2\"}, {\"entity\": \"18 anni\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"AAMC\"}, {\"entity\": \"giunta\"}, {\"entity\": \"esordita\"}, {\"entity\": \"SNC\"}, {\"entity\": \"paziente venezuelana\"}, {\"entity\": \"9 mesi\"}, {\"entity\": \"LAM M1-M2\"}, {\"entity\": \"18 anni\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"AAMC\"}, {\"entity\": \"giunta\"}, {\"entity\": \"esordita\"}, {\"entity\": \"SNC\"}, {\"entity\": \"paziente venezuelana\"}, {\"entity\": \"9 mesi\"}, {\"entity\": \"LAM M1-M2\"}, {\"entity\": \"18 anni\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"giunta\"}, {\"entity\": \"esordita\"}, {\"entity\": \"LAM\"}, {\"entity\": \"AAMC\"}, {\"entity\": \"paziente venezuelana\"}, {\"entity\": \"9 mesi prima\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"giunta\"}, {\"entity\": \"esordita\"}, {\"entity\": \"LAM\"}, {\"entity\": \"AAMC\"}, {\"entity\": \"paziente venezuelana\"}, {\"entity\": \"9 mesi prima\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"giunta\"}, {\"entity\": \"esordita\"}, {\"entity\": \"LAM\"}, {\"entity\": \"AAMC\"}, {\"entity\": \"paziente venezuelana\"}, {\"entity\": \"9 mesi prima\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"giunta\"}, {\"entity\": \"esordita\"}, {\"entity\": \"LAM\"}, {\"entity\": \"AAMC\"}, {\"entity\": \"paziente venezuelana\"}, {\"entity\": \"9 mesi prima\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Borm'}, {'entity': 'induzione'}, {'entity': 're induzione'}, {'entity': 'ottenimento'}, {'entity': 'RC'}]\n",
      "in parse_json model_response =  [{'entity': 'Borm'}, {'entity': 'induzione'}, {'entity': 're induzione'}, {'entity': 'ottenimento'}, {'entity': 'RC'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Borm\"}, {\"entity\": \"induzione\"}, {\"entity\": \"re induzione\"}, {\"entity\": \"ottenimento\"}, {\"entity\": \"RC\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Borm\"}, {\"entity\": \"induzione\"}, {\"entity\": \"re induzione\"}, {\"entity\": \"ottenimento\"}, {\"entity\": \"RC\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Borm\"}, {\"entity\": \"induzione\"}, {\"entity\": \"re induzione\"}, {\"entity\": \"ottenimento\"}, {\"entity\": \"RC\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"induzione\"}, {\"entity\": \"induzione\"}, {\"entity\": \"ottenimento\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"induzione\"}, {\"entity\": \"induzione\"}, {\"entity\": \"ottenimento\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"induzione\"}, {\"entity\": \"induzione\"}, {\"entity\": \"ottenimento\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"induzione\"}, {\"entity\": \"induzione\"}, {\"entity\": \"ottenimento\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'cicli'}, {'entity': 'porta'}, {'entity': 'la paziente'}]\n",
      "in parse_json model_response =  [{'entity': 'cicli'}, {'entity': 'porta'}, {'entity': 'la paziente'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"cicli\"}, {\"entity\": \"porta\"}, {\"entity\": \"la paziente\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"cicli\"}, {\"entity\": \"porta\"}, {\"entity\": \"la paziente\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"cicli\"}, {\"entity\": \"porta\"}, {\"entity\": \"la paziente\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"cicli\"}, {\"entity\": \"CLOVE\"}, {\"entity\": \"porta\"}, {\"entity\": \"la paziente\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"cicli\"}, {\"entity\": \"CLOVE\"}, {\"entity\": \"porta\"}, {\"entity\": \"la paziente\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"cicli\"}, {\"entity\": \"CLOVE\"}, {\"entity\": \"porta\"}, {\"entity\": \"la paziente\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"cicli\"}, {\"entity\": \"CLOVE\"}, {\"entity\": \"porta\"}, {\"entity\": \"la paziente\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Regime'}, {'entity': 'Busulfano'}]\n",
      "in parse_json model_response =  [{'entity': 'Regime'}, {'entity': 'Busulfano'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Regime\"}, {\"entity\": \"Busulfano\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Regime\"}, {\"entity\": \"Busulfano\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Regime\"}, {\"entity\": \"Busulfano\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"Regime\"}, {\"entity\": \"Busulfano\"}, {\"entity\": \"Thiotepa-Fludarabina\"}, {\"entity\": \"ATG\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Regime\"}, {\"entity\": \"Busulfano\"}, {\"entity\": \"Thiotepa-Fludarabina\"}, {\"entity\": \"ATG\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Regime\"}, {\"entity\": \"Busulfano\"}, {\"entity\": \"Thiotepa-Fludarabina\"}, {\"entity\": \"ATG\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"Regime\"}, {\"entity\": \"Busulfano\"}, {\"entity\": \"Thiotepa-Fludarabina\"}, {\"entity\": \"ATG\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'riceve'}, {'entity': 'La paziente'}, {'entity': '7.6x10^6'}]\n",
      "in parse_json model_response =  [{'entity': 'riceve'}, {'entity': 'La paziente'}, {'entity': '7.6x10^6'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"riceve\"}, {\"entity\": \"La paziente\"}, {\"entity\": \"7.6x10^6\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"riceve\"}, {\"entity\": \"La paziente\"}, {\"entity\": \"7.6x10^6\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"riceve\"}, {\"entity\": \"La paziente\"}, {\"entity\": \"7.6x10^6\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"CD34\"}, {\"entity\": \"La paziente\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"CD34\"}, {\"entity\": \"La paziente\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"CD34\"}, {\"entity\": \"La paziente\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"CD34\"}, {\"entity\": \"La paziente\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{\"entity\":\"\"}]\n",
      "in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\":\"\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\":\"\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"EDX\"}, {\"entity\": \"TCR\"}, {\"entity\": \"7.8x10^6/kg\"}, {\"entity\": \"ai giorni +3 e +4\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"EDX\"}, {\"entity\": \"TCR\"}, {\"entity\": \"7.8x10^6/kg\"}, {\"entity\": \"ai giorni +3 e +4\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"EDX\"}, {\"entity\": \"TCR\"}, {\"entity\": \"7.8x10^6/kg\"}, {\"entity\": \"ai giorni +3 e +4\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"EDX\"}, {\"entity\": \"TCR\"}, {\"entity\": \"7.8x10^6/kg\"}, {\"entity\": \"ai giorni +3 e +4\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'febbre'}, {'entity': 'episodio'}]\n",
      "in parse_json model_response =  [{'entity': 'febbre'}, {'entity': 'episodio'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"febbre\"}, {\"entity\": \"episodio\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"febbre\"}, {\"entity\": \"episodio\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"febbre\"}, {\"entity\": \"episodio\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"febbre\"}, {\"entity\": \"insufficienza\"}, {\"entity\": \"insufficienza respiratoria acuta\"}, {\"entity\": \"giornata +6\"}, {\"entity\": \"giornata +13\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"febbre\"}, {\"entity\": \"insufficienza\"}, {\"entity\": \"insufficienza respiratoria acuta\"}, {\"entity\": \"giornata +6\"}, {\"entity\": \"giornata +13\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"febbre\"}, {\"entity\": \"insufficienza\"}, {\"entity\": \"insufficienza respiratoria acuta\"}, {\"entity\": \"giornata +6\"}, {\"entity\": \"giornata +13\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"febbre\"}, {\"entity\": \"insufficienza\"}, {\"entity\": \"insufficienza respiratoria acuta\"}, {\"entity\": \"giornata +6\"}, {\"entity\": \"giornata +13\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'fenomeni'}, {'entity': 'consolidazione'}, {'entity': 'estesa'}, {'entity': 'infezione'}, {'entity': 'fungina'}]\n",
      "in parse_json model_response =  [{'entity': 'fenomeni'}, {'entity': 'consolidazione'}, {'entity': 'estesa'}, {'entity': 'infezione'}, {'entity': 'fungina'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"fenomeni\"}, {\"entity\": \"consolidazione\"}, {\"entity\": \"estesa\"}, {\"entity\": \"infezione\"}, {\"entity\": \"fungina\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"fenomeni\"}, {\"entity\": \"consolidazione\"}, {\"entity\": \"estesa\"}, {\"entity\": \"infezione\"}, {\"entity\": \"fungina\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"fenomeni\"}, {\"entity\": \"consolidazione\"}, {\"entity\": \"estesa\"}, {\"entity\": \"infezione\"}, {\"entity\": \"fungina\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"TC\"}, {\"entity\": \"fenomeni\"}, {\"entity\": \"infezione\"}, {\"entity\": \"al lobo inferiore sinistro e superiore\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"TC\"}, {\"entity\": \"fenomeni\"}, {\"entity\": \"infezione\"}, {\"entity\": \"al lobo inferiore sinistro e superiore\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"TC\"}, {\"entity\": \"fenomeni\"}, {\"entity\": \"infezione\"}, {\"entity\": \"al lobo inferiore sinistro e superiore\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"TC\"}, {\"entity\": \"fenomeni\"}, {\"entity\": \"infezione\"}, {\"entity\": \"al lobo inferiore sinistro e superiore\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{\"entity\":\"\"}]\n",
      "in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\":\"\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\":\"\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"Terapia\"}, {\"entity\": \"ossigenoterapia\"}, {\"entity\": \"terapia\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Terapia\"}, {\"entity\": \"ossigenoterapia\"}, {\"entity\": \"terapia\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Terapia\"}, {\"entity\": \"ossigenoterapia\"}, {\"entity\": \"terapia\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"Terapia\"}, {\"entity\": \"ossigenoterapia\"}, {\"entity\": \"terapia\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'sfebbramento'}]\n",
      "in parse_json model_response =  [{'entity': 'sfebbramento'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"sfebbramento\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"sfebbramento\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"sfebbramento\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"sfebbramento\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"giornata +20\"}, {\"entity\": \"nei giorni successivi\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"sfebbramento\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"giornata +20\"}, {\"entity\": \"nei giorni successivi\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"sfebbramento\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"giornata +20\"}, {\"entity\": \"nei giorni successivi\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"sfebbramento\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"giornata +20\"}, {\"entity\": \"nei giorni successivi\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Dimissione'}, {'entity': 'giornata +56'}]\n",
      "in parse_json model_response =  [{'entity': 'Dimissione'}, {'entity': 'giornata +56'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Dimissione\"}, {\"entity\": \"giornata +56\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Dimissione\"}, {\"entity\": \"giornata +56\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Dimissione\"}, {\"entity\": \"giornata +56\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"Dimissione\"}, {\"entity\": \"giornata +56\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Dimissione\"}, {\"entity\": \"giornata +56\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Dimissione\"}, {\"entity\": \"giornata +56\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"Dimissione\"}, {\"entity\": \"giornata +56\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{\"entity\":\"\"}]\n",
      "in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\":\"\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\":\"\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"Emocolture\"}, {\"entity\": \"galattomannano\"}, {\"entity\": \"monitoraggio\"}, {\"entity\": \"Adenovirus\"}, {\"entity\": \"CMV\"}, {\"entity\": \"ricovero\"}, {\"entity\": \"CMVDNA\"}, {\"entity\": \"negativi o debolmente positivi\"}, {\"entity\": \"920 copie/mmc\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Emocolture\"}, {\"entity\": \"galattomannano\"}, {\"entity\": \"monitoraggio\"}, {\"entity\": \"Adenovirus\"}, {\"entity\": \"CMV\"}, {\"entity\": \"ricovero\"}, {\"entity\": \"CMVDNA\"}, {\"entity\": \"negativi o debolmente positivi\"}, {\"entity\": \"920 copie/mmc\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Emocolture\"}, {\"entity\": \"galattomannano\"}, {\"entity\": \"monitoraggio\"}, {\"entity\": \"Adenovirus\"}, {\"entity\": \"CMV\"}, {\"entity\": \"ricovero\"}, {\"entity\": \"CMVDNA\"}, {\"entity\": \"negativi o debolmente positivi\"}, {\"entity\": \"920 copie/mmc\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"Emocolture\"}, {\"entity\": \"galattomannano\"}, {\"entity\": \"monitoraggio\"}, {\"entity\": \"Adenovirus\"}, {\"entity\": \"CMV\"}, {\"entity\": \"ricovero\"}, {\"entity\": \"CMVDNA\"}, {\"entity\": \"negativi o debolmente positivi\"}, {\"entity\": \"920 copie/mmc\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'febbricola'}, {'entity': 'mucosite'}, {'entity': 'tosse catarrale'}, {'entity': 'miglioramento del quadro radiologico'}, {'entity': 'A domicilio'}]\n",
      "in parse_json model_response =  [{'entity': 'febbricola'}, {'entity': 'mucosite'}, {'entity': 'tosse catarrale'}, {'entity': 'miglioramento del quadro radiologico'}, {'entity': 'A domicilio'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse catarrale\"}, {\"entity\": \"miglioramento del quadro radiologico\"}, {\"entity\": \"A domicilio\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse catarrale\"}, {\"entity\": \"miglioramento del quadro radiologico\"}, {\"entity\": \"A domicilio\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse catarrale\"}, {\"entity\": \"miglioramento del quadro radiologico\"}, {\"entity\": \"A domicilio\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"persistenza\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}, {\"entity\": \"evidenza\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"persistenza\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}, {\"entity\": \"evidenza\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"persistenza\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}, {\"entity\": \"evidenza\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"persistenza\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}, {\"entity\": \"evidenza\"}, {\"entity\": \"miglioramento\"}, {\"entity\": \"febbricola\"}, {\"entity\": \"mucosite\"}, {\"entity\": \"tosse\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'terapia'}, {'entity': 'ritroddizione'}, {'entity': 'viremia'}, {'entity': 'Ciclopiroxolatolo'}]\n",
      "in parse_json model_response =  [{'entity': 'terapia'}, {'entity': 'ritroddizione'}, {'entity': 'viremia'}, {'entity': 'Ciclopiroxolatolo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"ritroddizione\"}, {\"entity\": \"viremia\"}, {\"entity\": \"Ciclopiroxolatolo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"ritroddizione\"}, {\"entity\": \"viremia\"}, {\"entity\": \"Ciclopiroxolatolo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"terapia\"}, {\"entity\": \"ritroddizione\"}, {\"entity\": \"viremia\"}, {\"entity\": \"Ciclopiroxolatolo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"Rituximab\"}, {\"entity\": \"EBV\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"130000 copie/mL\"}, {\"entity\": \"294 copie/100000\"}, {\"entity\": \"60000 copie/mL\"}, {\"entity\": \"80 copie/100000\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Rituximab\"}, {\"entity\": \"EBV\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"130000 copie/mL\"}, {\"entity\": \"294 copie/100000\"}, {\"entity\": \"60000 copie/mL\"}, {\"entity\": \"80 copie/100000\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Rituximab\"}, {\"entity\": \"EBV\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"130000 copie/mL\"}, {\"entity\": \"294 copie/100000\"}, {\"entity\": \"60000 copie/mL\"}, {\"entity\": \"80 copie/100000\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"Rituximab\"}, {\"entity\": \"EBV\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"leucociti\"}, {\"entity\": \"130000 copie/mL\"}, {\"entity\": \"294 copie/100000\"}, {\"entity\": \"60000 copie/mL\"}, {\"entity\": \"80 copie/100000\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'indagini'}, {'entity': 'mostrano'}, {'entity': 'pegioramento'}, {'entity': 'mostrano'}, {'entity': 'NIV'}]\n",
      "in parse_json model_response =  [{'entity': 'indagini'}, {'entity': 'mostrano'}, {'entity': 'pegioramento'}, {'entity': 'mostrano'}, {'entity': 'NIV'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"indagini\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"pegioramento\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"NIV\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"indagini\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"pegioramento\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"NIV\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"indagini\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"pegioramento\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"NIV\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"indagini\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"peggioramento\"}, {\"entity\": \"necessità\"}, {\"entity\": \"NIV\"}, {\"entity\": \"saturazione\"}, {\"entity\": \"al lobo inferiore e medio di sinistra e superiore di destra\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"indagini\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"peggioramento\"}, {\"entity\": \"necessità\"}, {\"entity\": \"NIV\"}, {\"entity\": \"saturazione\"}, {\"entity\": \"al lobo inferiore e medio di sinistra e superiore di destra\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"indagini\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"peggioramento\"}, {\"entity\": \"necessità\"}, {\"entity\": \"NIV\"}, {\"entity\": \"saturazione\"}, {\"entity\": \"al lobo inferiore e medio di sinistra e superiore di destra\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"indagini\"}, {\"entity\": \"mostrano\"}, {\"entity\": \"peggioramento\"}, {\"entity\": \"necessità\"}, {\"entity\": \"NIV\"}, {\"entity\": \"saturazione\"}, {\"entity\": \"al lobo inferiore e medio di sinistra e superiore di destra\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'progressiva'}, {'entity': 'compromissione'}, {'entity': 'trasferita'}, {'entity': 'broncoscopia'}, {'entity': 'biopsia'}]\n",
      "in parse_json model_response =  [{'entity': 'progressiva'}, {'entity': 'compromissione'}, {'entity': 'trasferita'}, {'entity': 'broncoscopia'}, {'entity': 'biopsia'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"progressiva\"}, {\"entity\": \"compromissione\"}, {\"entity\": \"trasferita\"}, {\"entity\": \"broncoscopia\"}, {\"entity\": \"biopsia\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"progressiva\"}, {\"entity\": \"compromissione\"}, {\"entity\": \"trasferita\"}, {\"entity\": \"broncoscopia\"}, {\"entity\": \"biopsia\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"progressiva\"}, {\"entity\": \"compromissione\"}, {\"entity\": \"trasferita\"}, {\"entity\": \"broncoscopia\"}, {\"entity\": \"biopsia\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"progressiva\"}, {\"entity\": \"trasferita\"}, {\"entity\": \"broncoscopia\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"la paziente\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"progressiva\"}, {\"entity\": \"trasferita\"}, {\"entity\": \"broncoscopia\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"la paziente\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"progressiva\"}, {\"entity\": \"trasferita\"}, {\"entity\": \"broncoscopia\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"la paziente\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"progressiva\"}, {\"entity\": \"trasferita\"}, {\"entity\": \"broncoscopia\"}, {\"entity\": \"biopsia\"}, {\"entity\": \"la paziente\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'decede'}, {'entity': 'extensione'}, {'entity': 'arresto'}, {'entity': 'Im-155'}]\n",
      "in parse_json model_response =  [{'entity': 'decede'}, {'entity': 'extensione'}, {'entity': 'arresto'}, {'entity': 'Im-155'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"decede\"}, {\"entity\": \"extensione\"}, {\"entity\": \"arresto\"}, {\"entity\": \"Im-155\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"decede\"}, {\"entity\": \"extensione\"}, {\"entity\": \"arresto\"}, {\"entity\": \"Im-155\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"decede\"}, {\"entity\": \"extensione\"}, {\"entity\": \"arresto\"}, {\"entity\": \"Im-155\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"decede\"}, {\"entity\": \"estensione\"}, {\"entity\": \"arresto\"}, {\"entity\": \"arresto cardiocircolatorio\"}, {\"entity\": \"la paziente\"}, {\"entity\": \"giornata +115\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"decede\"}, {\"entity\": \"estensione\"}, {\"entity\": \"arresto\"}, {\"entity\": \"arresto cardiocircolatorio\"}, {\"entity\": \"la paziente\"}, {\"entity\": \"giornata +115\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"decede\"}, {\"entity\": \"estensione\"}, {\"entity\": \"arresto\"}, {\"entity\": \"arresto cardiocircolatorio\"}, {\"entity\": \"la paziente\"}, {\"entity\": \"giornata +115\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"decede\"}, {\"entity\": \"estensione\"}, {\"entity\": \"arresto\"}, {\"entity\": \"arresto cardiocircolatorio\"}, {\"entity\": \"la paziente\"}, {\"entity\": \"giornata +115\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'un esame'}]\n",
      "in parse_json model_response =  [{'entity': 'un esame'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"un esame\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"un esame\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"un esame\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"definisce\"}, {\"entity\": \"PTLD\"}, {\"entity\": \"PTLD polimorfo monotipico monoclonale\"}, {\"entity\": \"EBV\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"definisce\"}, {\"entity\": \"PTLD\"}, {\"entity\": \"PTLD polimorfo monotipico monoclonale\"}, {\"entity\": \"EBV\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esame\"}, {\"entity\": \"definisce\"}, {\"entity\": \"PTLD\"}, {\"entity\": \"PTLD polimorfo monotipico monoclonale\"}, {\"entity\": \"EBV\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"esame\"}, {\"entity\": \"definisce\"}, {\"entity\": \"PTLD\"}, {\"entity\": \"PTLD polimorfo monotipico monoclonale\"}, {\"entity\": \"EBV\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'dolori'}]\n",
      "in parse_json model_response =  [{'entity': 'dolori'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"dolori\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"dolori\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"dolori\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"dolori addominali crampiformi\"}, {\"entity\": \"scariche diarroiche\"}, {\"entity\": \"gastroenterite\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"dolori addominali crampiformi\"}, {\"entity\": \"scariche diarroiche\"}, {\"entity\": \"gastroenterite\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"dolori addominali crampiformi\"}, {\"entity\": \"scariche diarroiche\"}, {\"entity\": \"gastroenterite\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"dolori addominali crampiformi\"}, {\"entity\": \"scariche diarroiche\"}, {\"entity\": \"gastroenterite\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'ecografia'}, {'entity': 'sospetta'}, {'entity': 'evidenziava'}, {'entity': 'immagini'}, {'entity': 'evidenziava'}, {'entity': 'meteorismo'}, {'entity': 'un’ecografia'}, {'entity': 'questa'}, {'entity': 'richiesta'}]\n",
      "in parse_json model_response =  [{'entity': 'ecografia'}, {'entity': 'sospetta'}, {'entity': 'evidenziava'}, {'entity': 'immagini'}, {'entity': 'evidenziava'}, {'entity': 'meteorismo'}, {'entity': 'un’ecografia'}, {'entity': 'questa'}, {'entity': 'richiesta'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ecografia\"}, {\"entity\": \"sospetta\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"immagini\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"meteorismo\"}, {\"entity\": \"un’ecografia\"}, {\"entity\": \"questa\"}, {\"entity\": \"richiesta\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ecografia\"}, {\"entity\": \"sospetta\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"immagini\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"meteorismo\"}, {\"entity\": \"un’ecografia\"}, {\"entity\": \"questa\"}, {\"entity\": \"richiesta\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ecografia\"}, {\"entity\": \"sospetta\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"immagini\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"meteorismo\"}, {\"entity\": \"un’ecografia\"}, {\"entity\": \"questa\"}, {\"entity\": \"richiesta\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"invaginazione intestinale\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"invaginazione intestinale\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"invaginazione intestinale\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"invaginazione intestinale\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': ''}]\n",
      "in parse_json model_response =  [{'entity': ''}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'immagine'}, {'entity': 'evidenziava'}, {'entity': 'un’immagine a coccarda'}, {'entity': 'un’invaginazione ileo-ileale'}]\n",
      "in parse_json model_response =  [{'entity': 'immagine'}, {'entity': 'evidenziava'}, {'entity': 'un’immagine a coccarda'}, {'entity': 'un’invaginazione ileo-ileale'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"immagine\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"un’immagine a coccarda\"}, {\"entity\": \"un’invaginazione ileo-ileale\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"immagine\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"un’immagine a coccarda\"}, {\"entity\": \"un’invaginazione ileo-ileale\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"immagine\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"un’immagine a coccarda\"}, {\"entity\": \"un’invaginazione ileo-ileale\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"invaginazione ileo-ileale\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"invaginazione ileo-ileale\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"invaginazione ileo-ileale\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"invaginazione ileo-ileale\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{\"entity\":\"\"}]\n",
      "in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\":\"\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\":\"\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\":\"\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"ernia\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ernia\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ernia\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"ernia\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': ''}]\n",
      "in parse_json model_response =  [{'entity': ''}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Riprendeva'}, {'entity': \"l'intervento\"}, {'entity': 'concludeva'}, {'entity': 'resezione'}, {'entity': \"l'ileo\"}, {'entity': \"l'ansa intestinale\"}, {'entity': 'derotata'}, {'entity': 'del diverticolo di Meckel'}, {'entity': \"l'intervento\"}, {'entity': 'un termino-terminale'}]\n",
      "in parse_json model_response =  [{'entity': 'Riprendeva'}, {'entity': \"l'intervento\"}, {'entity': 'concludeva'}, {'entity': 'resezione'}, {'entity': \"l'ileo\"}, {'entity': \"l'ansa intestinale\"}, {'entity': 'derotata'}, {'entity': 'del diverticolo di Meckel'}, {'entity': \"l'intervento\"}, {'entity': 'un termino-terminale'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Riprendeva\"}, {\"entity\": \"l'intervento\"}, {\"entity\": \"concludeva\"}, {\"entity\": \"resezione\"}, {\"entity\": \"l'ileo\"}, {\"entity\": \"l'ansa intestinale\"}, {\"entity\": \"derotata\"}, {\"entity\": \"del diverticolo di Meckel\"}, {\"entity\": \"l'intervento\"}, {\"entity\": \"un termino-terminale\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Riprendeva\"}, {\"entity\": \"l'intervento\"}, {\"entity\": \"concludeva\"}, {\"entity\": \"resezione\"}, {\"entity\": \"l'ileo\"}, {\"entity\": \"l'ansa intestinale\"}, {\"entity\": \"derotata\"}, {\"entity\": \"del diverticolo di Meckel\"}, {\"entity\": \"l'intervento\"}, {\"entity\": \"un termino-terminale\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Riprendeva\"}, {\"entity\": \"l'intervento\"}, {\"entity\": \"concludeva\"}, {\"entity\": \"resezione\"}, {\"entity\": \"l'ileo\"}, {\"entity\": \"l'ansa intestinale\"}, {\"entity\": \"derotata\"}, {\"entity\": \"del diverticolo di Meckel\"}, {\"entity\": \"l'intervento\"}, {\"entity\": \"un termino-terminale\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Il cieco'}]\n",
      "in parse_json model_response =  [{'entity': 'Il cieco'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Il cieco\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Il cieco\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Il cieco\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'dimesso'}, {'entity': 'Il bambino'}]\n",
      "in parse_json model_response =  [{'entity': 'dimesso'}, {'entity': 'Il bambino'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"dimesso\"}, {\"entity\": \"Il bambino\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"dimesso\"}, {\"entity\": \"Il bambino\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"dimesso\"}, {\"entity\": \"Il bambino\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  []\n",
      "AFTER asses_model_output in parse_json model_response =  []\n",
      "AFTER TERZO  parse_json model_response =  []\n",
      "ORA STO PARSANDO:  [] \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Giungeva'}, {'entity': 'febbre'}, {'entity': 'brividi'}]\n",
      "in parse_json model_response =  [{'entity': 'Giungeva'}, {'entity': 'febbre'}, {'entity': 'brividi'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Giungeva\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Giungeva\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Giungeva\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"Giungeva\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Giungeva\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Giungeva\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"Giungeva\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}, {\"entity\": \"febbre\"}, {\"entity\": \"brividi\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'ricovero'}, {'entity': 'febbre'}, {'entity': 'emocolture'}, {'entity': 'ecocardiogramma'}, {'entity': 'veter  -  ch  -  negativo'}]\n",
      "in parse_json model_response =  [{'entity': 'ricovero'}, {'entity': 'febbre'}, {'entity': 'emocolture'}, {'entity': 'ecocardiogramma'}, {'entity': 'veter  -  ch  -  negativo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"febbre\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"veter  -  ch  -  negativo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"febbre\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"veter  -  ch  -  negativo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ricovero\"}, {\"entity\": \"febbre\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"veter  -  ch  -  negativo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"febbre\"}, {\"entity\": \"positive\"}, {\"entity\": \"negativo\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"febbre\"}, {\"entity\": \"positive\"}, {\"entity\": \"negativo\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"febbre\"}, {\"entity\": \"positive\"}, {\"entity\": \"negativo\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"ricovero\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"febbre\"}, {\"entity\": \"positive\"}, {\"entity\": \"negativo\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'PCR'}, {'entity': 'emocolture'}, {'entity': 'E.Faecalis'}, {'entity': '7.2'}]\n",
      "in parse_json model_response =  [{'entity': 'PCR'}, {'entity': 'emocolture'}, {'entity': 'E.Faecalis'}, {'entity': '7.2'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"PCR\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"7.2\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"PCR\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"7.2\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"PCR\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"7.2\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"PCR\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"7.2\"}, {\"entity\": \"positive\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"PCR\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"7.2\"}, {\"entity\": \"positive\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"PCR\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"7.2\"}, {\"entity\": \"positive\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"PCR\"}, {\"entity\": \"emocolture\"}, {\"entity\": \"E.Faecalis\"}, {\"entity\": \"7.2\"}, {\"entity\": \"positive\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Ecocardiogramma'}, {'entity': 'vgetazioni'}]\n",
      "in parse_json model_response =  [{'entity': 'Ecocardiogramma'}, {'entity': 'vgetazioni'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Ecocardiogramma\"}, {\"entity\": \"vgetazioni\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Ecocardiogramma\"}, {\"entity\": \"vgetazioni\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Ecocardiogramma\"}, {\"entity\": \"vgetazioni\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"Ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"negativo\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"negativo\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"negativo\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"Ecocardiogramma\"}, {\"entity\": \"vegetazioni\"}, {\"entity\": \"negativo\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'persistere'}, {'entity': 'TC-PET'}, {'entity': 'captazione'}, {'entity': 'parte ventricolare posteriore sx'}, {'entity': 'valvolare'}]\n",
      "in parse_json model_response =  [{'entity': 'persistere'}, {'entity': 'TC-PET'}, {'entity': 'captazione'}, {'entity': 'parte ventricolare posteriore sx'}, {'entity': 'valvolare'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"persistere\"}, {\"entity\": \"TC-PET\"}, {\"entity\": \"captazione\"}, {\"entity\": \"parte ventricolare posteriore sx\"}, {\"entity\": \"valvolare\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"persistere\"}, {\"entity\": \"TC-PET\"}, {\"entity\": \"captazione\"}, {\"entity\": \"parte ventricolare posteriore sx\"}, {\"entity\": \"valvolare\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"persistere\"}, {\"entity\": \"TC-PET\"}, {\"entity\": \"captazione\"}, {\"entity\": \"parte ventricolare posteriore sx\"}, {\"entity\": \"valvolare\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"persistere\"}, {\"entity\": \"sintomatologia\"}, {\"entity\": \"TC-PET\"}, {\"entity\": \"febbrile\"}, {\"entity\": \"della parete ventricolare posteriore sx\"}, {\"entity\": \"sul piano valvolare\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"persistere\"}, {\"entity\": \"sintomatologia\"}, {\"entity\": \"TC-PET\"}, {\"entity\": \"febbrile\"}, {\"entity\": \"della parete ventricolare posteriore sx\"}, {\"entity\": \"sul piano valvolare\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"persistere\"}, {\"entity\": \"sintomatologia\"}, {\"entity\": \"TC-PET\"}, {\"entity\": \"febbrile\"}, {\"entity\": \"della parete ventricolare posteriore sx\"}, {\"entity\": \"sul piano valvolare\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"persistere\"}, {\"entity\": \"sintomatologia\"}, {\"entity\": \"TC-PET\"}, {\"entity\": \"febbrile\"}, {\"entity\": \"della parete ventricolare posteriore sx\"}, {\"entity\": \"sul piano valvolare\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'embolizzazioni'}, {'entity': 'TC total-body'}]\n",
      "in parse_json model_response =  [{'entity': 'embolizzazioni'}, {'entity': 'TC total-body'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"embolizzazioni\"}, {\"entity\": \"TC total-body\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"embolizzazioni\"}, {\"entity\": \"TC total-body\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"embolizzazioni\"}, {\"entity\": \"TC total-body\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"TC\"}, {\"entity\": \"embolizzazioni\"}, {\"entity\": \"negativa\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"TC\"}, {\"entity\": \"embolizzazioni\"}, {\"entity\": \"negativa\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"TC\"}, {\"entity\": \"embolizzazioni\"}, {\"entity\": \"negativa\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"TC\"}, {\"entity\": \"embolizzazioni\"}, {\"entity\": \"negativa\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'indicava'}, {'entity': 'intervento'}]\n",
      "in parse_json model_response =  [{'entity': 'indicava'}, {'entity': 'intervento'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"indicava\"}, {\"entity\": \"intervento\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"indicava\"}, {\"entity\": \"intervento\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"indicava\"}, {\"entity\": \"intervento\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il cardiochirurgo\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il cardiochirurgo\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il cardiochirurgo\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"intervento\"}, {\"entity\": \"Il cardiochirurgo\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Eseguiva'}, {'entity': 'terapia'}, {'entity': 'beneficio'}]\n",
      "in parse_json model_response =  [{'entity': 'Eseguiva'}, {'entity': 'terapia'}, {'entity': 'beneficio'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Eseguiva\"}, {\"entity\": \"terapia\"}, {\"entity\": \"beneficio\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Eseguiva\"}, {\"entity\": \"terapia\"}, {\"entity\": \"beneficio\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Eseguiva\"}, {\"entity\": \"terapia\"}, {\"entity\": \"beneficio\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"beneficio\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"beneficio\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"beneficio\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"terapia\"}, {\"entity\": \"beneficio\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Dopo'}, {'entity': 'terapia'}, {'entity': 'dimesso'}, {'entity': 'buone'}, {'entity': 'indicazione'}]\n",
      "in parse_json model_response =  [{'entity': 'Dopo'}, {'entity': 'terapia'}, {'entity': 'dimesso'}, {'entity': 'buone'}, {'entity': 'indicazione'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Dopo\"}, {\"entity\": \"terapia\"}, {\"entity\": \"dimesso\"}, {\"entity\": \"buone\"}, {\"entity\": \"indicazione\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Dopo\"}, {\"entity\": \"terapia\"}, {\"entity\": \"dimesso\"}, {\"entity\": \"buone\"}, {\"entity\": \"indicazione\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Dopo\"}, {\"entity\": \"terapia\"}, {\"entity\": \"dimesso\"}, {\"entity\": \"buone\"}, {\"entity\": \"indicazione\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"dimesso\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"follow-up\"}, {\"entity\": \"6 settimane\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"dimesso\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"follow-up\"}, {\"entity\": \"6 settimane\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"terapia\"}, {\"entity\": \"dimesso\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"follow-up\"}, {\"entity\": \"6 settimane\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"terapia\"}, {\"entity\": \"dimesso\"}, {\"entity\": \"condizioni\"}, {\"entity\": \"follow-up\"}, {\"entity\": \"6 settimane\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'Il signor Ugo di anni 63 sposato'}]\n",
      "in parse_json model_response =  [{'entity': 'Il signor Ugo di anni 63 sposato'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"Il signor Ugo di anni 63 sposato\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"Il signor Ugo di anni 63 sposato\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"Il signor Ugo di anni 63 sposato\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"sposato\"}, {\"entity\": \"ricoverato\"}, {\"entity\": \"accertamenti\"}, {\"entity\": \"Il signor Ugo di anni 63\"}, {\"entity\": \"due figli\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"sposato\"}, {\"entity\": \"ricoverato\"}, {\"entity\": \"accertamenti\"}, {\"entity\": \"Il signor Ugo di anni 63\"}, {\"entity\": \"due figli\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"sposato\"}, {\"entity\": \"ricoverato\"}, {\"entity\": \"accertamenti\"}, {\"entity\": \"Il signor Ugo di anni 63\"}, {\"entity\": \"due figli\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"sposato\"}, {\"entity\": \"ricoverato\"}, {\"entity\": \"accertamenti\"}, {\"entity\": \"Il signor Ugo di anni 63\"}, {\"entity\": \"due figli\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'ricovero'}, {'entity': 'dolori addominali'}, {'entity': 'vomito'}]\n",
      "in parse_json model_response =  [{'entity': 'ricovero'}, {'entity': 'dolori addominali'}, {'entity': 'vomito'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"vomito\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ricovero\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"vomito\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ricovero\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"vomito\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"forti\"}, {\"entity\": \"vomito\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"vomito\"}, {\"entity\": \"il signor Ugo\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"forti\"}, {\"entity\": \"vomito\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"vomito\"}, {\"entity\": \"il signor Ugo\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"forti\"}, {\"entity\": \"vomito\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"vomito\"}, {\"entity\": \"il signor Ugo\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"forti\"}, {\"entity\": \"vomito\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"vomito\"}, {\"entity\": \"il signor Ugo\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'un K gastrico'}, {'entity': 'metastasi del fegato e del pancreas'}]\n",
      "in parse_json model_response =  [{'entity': 'un K gastrico'}, {'entity': 'metastasi del fegato e del pancreas'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"un K gastrico\"}, {\"entity\": \"metastasi del fegato e del pancreas\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"un K gastrico\"}, {\"entity\": \"metastasi del fegato e del pancreas\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"un K gastrico\"}, {\"entity\": \"metastasi del fegato e del pancreas\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"accertamenti\"}, {\"entity\": \"diagnosticato\"}, {\"entity\": \"K\"}, {\"entity\": \"K gastrico\"}, {\"entity\": \"metastasi del fegato e del pancreas\"}, {\"entity\": \"metastasi del fegato\"}, {\"entity\": \"del fegato\"}, {\"entity\": \"del pancreas\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"accertamenti\"}, {\"entity\": \"diagnosticato\"}, {\"entity\": \"K\"}, {\"entity\": \"K gastrico\"}, {\"entity\": \"metastasi del fegato e del pancreas\"}, {\"entity\": \"metastasi del fegato\"}, {\"entity\": \"del fegato\"}, {\"entity\": \"del pancreas\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"accertamenti\"}, {\"entity\": \"diagnosticato\"}, {\"entity\": \"K\"}, {\"entity\": \"K gastrico\"}, {\"entity\": \"metastasi del fegato e del pancreas\"}, {\"entity\": \"metastasi del fegato\"}, {\"entity\": \"del fegato\"}, {\"entity\": \"del pancreas\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"accertamenti\"}, {\"entity\": \"diagnosticato\"}, {\"entity\": \"K\"}, {\"entity\": \"K gastrico\"}, {\"entity\": \"metastasi del fegato e del pancreas\"}, {\"entity\": \"metastasi del fegato\"}, {\"entity\": \"del fegato\"}, {\"entity\": \"del pancreas\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'intervento'}, {'entity': 'Il signor Ugo'}]\n",
      "in parse_json model_response =  [{'entity': 'intervento'}, {'entity': 'Il signor Ugo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il signor Ugo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il signor Ugo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"intervento\"}, {\"entity\": \"Il signor Ugo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il signor Ugo\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il signor Ugo\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"intervento\"}, {\"entity\": \"Il signor Ugo\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"intervento\"}, {\"entity\": \"Il signor Ugo\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'ritorno'}, {'entity': 'dolori'}, {'entity': 'posizionato'}, {'entity': 'prescritta'}, {'entity': 'dolori addominali'}]\n",
      "in parse_json model_response =  [{'entity': 'ritorno'}, {'entity': 'dolori'}, {'entity': 'posizionato'}, {'entity': 'prescritta'}, {'entity': 'dolori addominali'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ritorno\"}, {\"entity\": \"dolori\"}, {\"entity\": \"posizionato\"}, {\"entity\": \"prescritta\"}, {\"entity\": \"dolori addominali\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ritorno\"}, {\"entity\": \"dolori\"}, {\"entity\": \"posizionato\"}, {\"entity\": \"prescritta\"}, {\"entity\": \"dolori addominali\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"ritorno\"}, {\"entity\": \"dolori\"}, {\"entity\": \"posizionato\"}, {\"entity\": \"prescritta\"}, {\"entity\": \"dolori addominali\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"ritorno\"}, {\"entity\": \"forti\"}, {\"entity\": \"posizionato\"}, {\"entity\": \"prescritta\"}, {\"entity\": \"nutrizione\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"Ugo\"}, {\"entity\": \"gli\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"ritorno\"}, {\"entity\": \"forti\"}, {\"entity\": \"posizionato\"}, {\"entity\": \"prescritta\"}, {\"entity\": \"nutrizione\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"Ugo\"}, {\"entity\": \"gli\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"ritorno\"}, {\"entity\": \"forti\"}, {\"entity\": \"posizionato\"}, {\"entity\": \"prescritta\"}, {\"entity\": \"nutrizione\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"Ugo\"}, {\"entity\": \"gli\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"ritorno\"}, {\"entity\": \"forti\"}, {\"entity\": \"posizionato\"}, {\"entity\": \"prescritta\"}, {\"entity\": \"nutrizione\"}, {\"entity\": \"dolori addominali\"}, {\"entity\": \"Ugo\"}, {\"entity\": \"gli\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'alimentarsi'}, {'entity': 'togliere'}, {'entity': 'Il giorno successivo'}]\n",
      "in parse_json model_response =  [{'entity': 'alimentarsi'}, {'entity': 'togliere'}, {'entity': 'Il giorno successivo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"alimentarsi\"}, {\"entity\": \"togliere\"}, {\"entity\": \"Il giorno successivo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"alimentarsi\"}, {\"entity\": \"togliere\"}, {\"entity\": \"Il giorno successivo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"alimentarsi\"}, {\"entity\": \"togliere\"}, {\"entity\": \"Il giorno successivo\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"chiede\"}, {\"entity\": \"alimentarsi\"}, {\"entity\": \"togliere\"}, {\"entity\": \"Il signore\"}, {\"entity\": \"Il giorno successivo\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"chiede\"}, {\"entity\": \"alimentarsi\"}, {\"entity\": \"togliere\"}, {\"entity\": \"Il signore\"}, {\"entity\": \"Il giorno successivo\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"chiede\"}, {\"entity\": \"alimentarsi\"}, {\"entity\": \"togliere\"}, {\"entity\": \"Il signore\"}, {\"entity\": \"Il giorno successivo\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"chiede\"}, {\"entity\": \"alimentarsi\"}, {\"entity\": \"togliere\"}, {\"entity\": \"Il signore\"}, {\"entity\": \"Il giorno successivo\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'giungeva'}, {'entity': 'osservazione'}, {'entity': 'bassa statura'}, {'entity': 'anemia'}, {'entity': 'astenia'}, {'entity': 'bambina di 11 anni, prepubere'}]\n",
      "in parse_json model_response =  [{'entity': 'giungeva'}, {'entity': 'osservazione'}, {'entity': 'bassa statura'}, {'entity': 'anemia'}, {'entity': 'astenia'}, {'entity': 'bambina di 11 anni, prepubere'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"giungeva\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"bassa statura\"}, {\"entity\": \"anemia\"}, {\"entity\": \"astenia\"}, {\"entity\": \"bambina di 11 anni, prepubere\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"giungeva\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"bassa statura\"}, {\"entity\": \"anemia\"}, {\"entity\": \"astenia\"}, {\"entity\": \"bambina di 11 anni, prepubere\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"giungeva\"}, {\"entity\": \"osservazione\"}, {\"entity\": \"bassa statura\"}, {\"entity\": \"anemia\"}, {\"entity\": \"astenia\"}, {\"entity\": \"bambina di 11 anni, prepubere\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"bassa statura\"}, {\"entity\": \"anemia\"}, {\"entity\": \"astenia\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"bassa statura\"}, {\"entity\": \"anemia\"}, {\"entity\": \"astenia\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"bassa statura\"}, {\"entity\": \"anemia\"}, {\"entity\": \"astenia\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"bassa statura\"}, {\"entity\": \"anemia\"}, {\"entity\": \"astenia\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'emergeva'}, {'entity': 'ricovero'}, {'entity': 'altra struttura'}, {'entity': 'evidenziava'}, {'entity': 'assunta'}, {'entity': 'fece'}, {'entity': 'un deficit selettivo della linea eritroide'}, {'entity': 'un grave anemia'}, {'entity': 'un Hb'}, {'entity': 'un 6,8 gr/dl'}]\n",
      "in parse_json model_response =  [{'entity': 'emergeva'}, {'entity': 'ricovero'}, {'entity': 'altra struttura'}, {'entity': 'evidenziava'}, {'entity': 'assunta'}, {'entity': 'fece'}, {'entity': 'un deficit selettivo della linea eritroide'}, {'entity': 'un grave anemia'}, {'entity': 'un Hb'}, {'entity': 'un 6,8 gr/dl'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"emergeva\"}, {\"entity\": \"ricovero\"}, {\"entity\": \"altra struttura\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"assunta\"}, {\"entity\": \"fece\"}, {\"entity\": \"un deficit selettivo della linea eritroide\"}, {\"entity\": \"un grave anemia\"}, {\"entity\": \"un Hb\"}, {\"entity\": \"un 6,8 gr/dl\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"emergeva\"}, {\"entity\": \"ricovero\"}, {\"entity\": \"altra struttura\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"assunta\"}, {\"entity\": \"fece\"}, {\"entity\": \"un deficit selettivo della linea eritroide\"}, {\"entity\": \"un grave anemia\"}, {\"entity\": \"un Hb\"}, {\"entity\": \"un 6,8 gr/dl\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"emergeva\"}, {\"entity\": \"ricovero\"}, {\"entity\": \"altra struttura\"}, {\"entity\": \"evidenziava\"}, {\"entity\": \"assunta\"}, {\"entity\": \"fece\"}, {\"entity\": \"un deficit selettivo della linea eritroide\"}, {\"entity\": \"un grave anemia\"}, {\"entity\": \"un Hb\"}, {\"entity\": \"un 6,8 gr/dl\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"anemia\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anemia\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anemia\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"anemia\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'valutazione'}]\n",
      "in parse_json model_response =  [{'entity': 'valutazione'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"valutazione\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"valutazione\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"valutazione\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"deficit staturale\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"deficit staturale\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"deficit staturale\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"deficit staturale\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'quadro'}]\n",
      "in parse_json model_response =  [{'entity': 'quadro'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"quadro\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"quadro\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"quadro\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"sindrome di Turner\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"sindrome di Turner\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"sindrome di Turner\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"sindrome di Turner\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'evidenziava'}, {'entity': 'segni'}, {'entity': 'avviate'}, {'entity': 'mostravano'}, {'entity': 'Hb'}, {'entity': 'G.R.'}, {'entity': 'MCV'}, {'entity': 'Ht'}, {'entity': 'emolisa'}, {'entity': 'infezione'}, {'entity': 'anemia'}, {'entity': 'cello-laboratoristici'}, {'entity': 'clinico'}]\n",
      "in parse_json model_response =  [{'entity': 'evidenziava'}, {'entity': 'segni'}, {'entity': 'avviate'}, {'entity': 'mostravano'}, {'entity': 'Hb'}, {'entity': 'G.R.'}, {'entity': 'MCV'}, {'entity': 'Ht'}, {'entity': 'emolisa'}, {'entity': 'infezione'}, {'entity': 'anemia'}, {'entity': 'cello-laboratoristici'}, {'entity': 'clinico'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"evidenziava\"}, {\"entity\": \"segni\"}, {\"entity\": \"avviate\"}, {\"entity\": \"mostravano\"}, {\"entity\": \"Hb\"}, {\"entity\": \"G.R.\"}, {\"entity\": \"MCV\"}, {\"entity\": \"Ht\"}, {\"entity\": \"emolisa\"}, {\"entity\": \"infezione\"}, {\"entity\": \"anemia\"}, {\"entity\": \"cello-laboratoristici\"}, {\"entity\": \"clinico\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"evidenziava\"}, {\"entity\": \"segni\"}, {\"entity\": \"avviate\"}, {\"entity\": \"mostravano\"}, {\"entity\": \"Hb\"}, {\"entity\": \"G.R.\"}, {\"entity\": \"MCV\"}, {\"entity\": \"Ht\"}, {\"entity\": \"emolisa\"}, {\"entity\": \"infezione\"}, {\"entity\": \"anemia\"}, {\"entity\": \"cello-laboratoristici\"}, {\"entity\": \"clinico\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"evidenziava\"}, {\"entity\": \"segni\"}, {\"entity\": \"avviate\"}, {\"entity\": \"mostravano\"}, {\"entity\": \"Hb\"}, {\"entity\": \"G.R.\"}, {\"entity\": \"MCV\"}, {\"entity\": \"Ht\"}, {\"entity\": \"emolisa\"}, {\"entity\": \"infezione\"}, {\"entity\": \"anemia\"}, {\"entity\": \"cello-laboratoristici\"}, {\"entity\": \"clinico\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"anemia\"}, {\"entity\": \"anemia normocromica macrocitica\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anemia\"}, {\"entity\": \"anemia normocromica macrocitica\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anemia\"}, {\"entity\": \"anemia normocromica macrocitica\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"anemia\"}, {\"entity\": \"anemia normocromica macrocitica\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'anemia'}, {'entity': 'carenza'}, {'entity': 'anemia'}, {'entity': 'anemia'}, {'entity': 'anemia di Fanconi'}]\n",
      "in parse_json model_response =  [{'entity': 'anemia'}, {'entity': 'carenza'}, {'entity': 'anemia'}, {'entity': 'anemia'}, {'entity': 'anemia di Fanconi'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anemia\"}, {\"entity\": \"carenza\"}, {\"entity\": \"anemia\"}, {\"entity\": \"anemia\"}, {\"entity\": \"anemia di Fanconi\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anemia\"}, {\"entity\": \"carenza\"}, {\"entity\": \"anemia\"}, {\"entity\": \"anemia\"}, {\"entity\": \"anemia di Fanconi\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"anemia\"}, {\"entity\": \"carenza\"}, {\"entity\": \"anemia\"}, {\"entity\": \"anemia\"}, {\"entity\": \"anemia di Fanconi\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"anemia macrocitica\"}, {\"entity\": \"carenza di vitamina B12 e ac. folico\"}, {\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"anemia di Blackfan-Diamond\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anemia macrocitica\"}, {\"entity\": \"carenza di vitamina B12 e ac. folico\"}, {\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"anemia di Blackfan-Diamond\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anemia macrocitica\"}, {\"entity\": \"carenza di vitamina B12 e ac. folico\"}, {\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"anemia di Blackfan-Diamond\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"anemia macrocitica\"}, {\"entity\": \"carenza di vitamina B12 e ac. folico\"}, {\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"anemia di Blackfan-Diamond\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'eritroblastopenia'}, {'entity': 'scartata'}, {'entity': 'esordio'}, {'entity': 'transitorio'}, {'entity': 'anomalie'}]\n",
      "in parse_json model_response =  [{'entity': 'eritroblastopenia'}, {'entity': 'scartata'}, {'entity': 'esordio'}, {'entity': 'transitorio'}, {'entity': 'anomalie'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"eritroblastopenia\"}, {\"entity\": \"scartata\"}, {\"entity\": \"esordio\"}, {\"entity\": \"transitorio\"}, {\"entity\": \"anomalie\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"eritroblastopenia\"}, {\"entity\": \"scartata\"}, {\"entity\": \"esordio\"}, {\"entity\": \"transitorio\"}, {\"entity\": \"anomalie\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"eritroblastopenia\"}, {\"entity\": \"scartata\"}, {\"entity\": \"esordio\"}, {\"entity\": \"transitorio\"}, {\"entity\": \"anomalie\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"eritroblastopenia transitoria dell’infanzia\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"eritroblastopenia transitoria dell’infanzia\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"eritroblastopenia transitoria dell’infanzia\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"eritroblastopenia transitoria dell’infanzia\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'carenza'}, {'entity': 'segni'}, {'entity': 'glossite'}, {'entity': 'perdita'}, {'entity': 'nausea'}, {'entity': 'stipsi'}, {'entity': 'afotosi'}, {'entity': 'sintomi'}, {'entity': 'iperbilirubinemia'}, {'entity': 'diarreia'}]\n",
      "in parse_json model_response =  [{'entity': 'carenza'}, {'entity': 'segni'}, {'entity': 'glossite'}, {'entity': 'perdita'}, {'entity': 'nausea'}, {'entity': 'stipsi'}, {'entity': 'afotosi'}, {'entity': 'sintomi'}, {'entity': 'iperbilirubinemia'}, {'entity': 'diarreia'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"carenza\"}, {\"entity\": \"segni\"}, {\"entity\": \"glossite\"}, {\"entity\": \"perdita\"}, {\"entity\": \"nausea\"}, {\"entity\": \"stipsi\"}, {\"entity\": \"afotosi\"}, {\"entity\": \"sintomi\"}, {\"entity\": \"iperbilirubinemia\"}, {\"entity\": \"diarreia\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"carenza\"}, {\"entity\": \"segni\"}, {\"entity\": \"glossite\"}, {\"entity\": \"perdita\"}, {\"entity\": \"nausea\"}, {\"entity\": \"stipsi\"}, {\"entity\": \"afotosi\"}, {\"entity\": \"sintomi\"}, {\"entity\": \"iperbilirubinemia\"}, {\"entity\": \"diarreia\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"carenza\"}, {\"entity\": \"segni\"}, {\"entity\": \"glossite\"}, {\"entity\": \"perdita\"}, {\"entity\": \"nausea\"}, {\"entity\": \"stipsi\"}, {\"entity\": \"afotosi\"}, {\"entity\": \"sintomi\"}, {\"entity\": \"iperbilirubinemia\"}, {\"entity\": \"diarreia\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"carenza di vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'esclusa'}, {'entity': 'vitamina B12'}, {'entity': 'ac. B12'}]\n",
      "in parse_json model_response =  [{'entity': 'esclusa'}, {'entity': 'vitamina B12'}, {'entity': 'ac. B12'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"esclusa\"}, {\"entity\": \"vitamina B12\"}, {\"entity\": \"ac. B12\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"esclusa\"}, {\"entity\": \"vitamina B12\"}, {\"entity\": \"ac. B12\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"esclusa\"}, {\"entity\": \"vitamina B12\"}, {\"entity\": \"ac. B12\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"carenza di acido folico e/o vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"carenza di acido folico e/o vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"carenza di acido folico e/o vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"carenza di acido folico e/o vitamina B12\"}, {\"entity\": \"carenza di acido folico\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'escludere'}, {'entity': 'anemia'}, {'entity': 'aplasia'}, {'entity': 'un-anemia di Fanconi'}, {'entity': 'negativo'}, {'entity': 'Al fine'}]\n",
      "in parse_json model_response =  [{'entity': 'escludere'}, {'entity': 'anemia'}, {'entity': 'aplasia'}, {'entity': 'un-anemia di Fanconi'}, {'entity': 'negativo'}, {'entity': 'Al fine'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"escludere\"}, {\"entity\": \"anemia\"}, {\"entity\": \"aplasia\"}, {\"entity\": \"un-anemia di Fanconi\"}, {\"entity\": \"negativo\"}, {\"entity\": \"Al fine\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"escludere\"}, {\"entity\": \"anemia\"}, {\"entity\": \"aplasia\"}, {\"entity\": \"un-anemia di Fanconi\"}, {\"entity\": \"negativo\"}, {\"entity\": \"Al fine\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"escludere\"}, {\"entity\": \"anemia\"}, {\"entity\": \"aplasia\"}, {\"entity\": \"un-anemia di Fanconi\"}, {\"entity\": \"negativo\"}, {\"entity\": \"Al fine\"}] \n",
      "\n",
      "\n",
      "\n",
      "in parse_json model_response =  [{\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"aplasia pura della serie eritroide\"}] \n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"aplasia pura della serie eritroide\"}] \n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"aplasia pura della serie eritroide\"}] \n",
      "ORA STO PARSANDO:  [{\"entity\": \"anemia di Fanconi\"}, {\"entity\": \"aplasia pura della serie eritroide\"}]  \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL model_output:  [{'entity': 'fesone'}, {'entity': 'presenza'}, {'entity': 'esordio'}, {'entity': 'fenotipo'}, {'entity': 'indagini'}, {'entity': 'anemia'}, {'entity': 'reticolocitopenia'}, {'entity': 'midollo'}]\n",
      "in parse_json model_response =  [{'entity': 'fesone'}, {'entity': 'presenza'}, {'entity': 'esordio'}, {'entity': 'fenotipo'}, {'entity': 'indagini'}, {'entity': 'anemia'}, {'entity': 'reticolocitopenia'}, {'entity': 'midollo'}]\n",
      "AFTER asses_model_output in parse_json model_response =  [{\"entity\": \"fesone\"}, {\"entity\": \"presenza\"}, {\"entity\": \"esordio\"}, {\"entity\": \"fenotipo\"}, {\"entity\": \"indagini\"}, {\"entity\": \"anemia\"}, {\"entity\": \"reticolocitopenia\"}, {\"entity\": \"midollo\"}]\n",
      "AFTER TERZO  parse_json model_response =  [{\"entity\": \"fesone\"}, {\"entity\": \"presenza\"}, {\"entity\": \"esordio\"}, {\"entity\": \"fenotipo\"}, {\"entity\": \"indagini\"}, {\"entity\": \"anemia\"}, {\"entity\": \"reticolocitopenia\"}, {\"entity\": \"midollo\"}]\n",
      "ORA STO PARSANDO:  [{\"entity\": \"fesone\"}, {\"entity\": \"presenza\"}, {\"entity\": \"esordio\"}, {\"entity\": \"fenotipo\"}, {\"entity\": \"indagini\"}, {\"entity\": \"anemia\"}, {\"entity\": \"reticolocitopenia\"}, {\"entity\": \"midollo\"}] \n",
      "\n",
      "\n",
      "\n",
      " di Blackfan-Diamond\"}] onse =  [{\"entity\": \"anemia\n",
      " di Blackfan-Diamond\"}]  in parse_json model_response =  [{\"entity\": \"anemia\n",
      " di Blackfan-Diamond\"}] model_response =  [{\"entity\": \"anemia\n",
      " di Blackfan-Diamond\"}]  ity\": \"anemia\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Invalid control character at: line 1 column 20 (char 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m cleaned_data \u001b[38;5;241m=\u001b[39m output_cleaner\u001b[38;5;241m.\u001b[39mapply_cleaning(eval_data, wrong_keys_to_entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#.select(range(12,13))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator(data\u001b[38;5;241m=\u001b[39mcleaned_data, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, output_cleaner\u001b[38;5;241m=\u001b[39moutput_cleaner)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_evaluation_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop_words\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuperset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleveshtein\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 469\u001b[0m, in \u001b[0;36mEvaluator.generate_evaluation_table\u001b[0;34m(self, similar_is_equal_threshold, words_level, similarity_types)\u001b[0m\n\u001b[1;32m    467\u001b[0m metrics_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m--> 469\u001b[0m     metrics_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_TP_FP_FN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mground_truth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    471\u001b[0m metrics_dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metrics_list, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    472\u001b[0m summary \u001b[38;5;241m=\u001b[39m metrics_dataframe\u001b[38;5;241m.\u001b[39msum()\n",
      "Cell \u001b[0;32mIn[8], line 414\u001b[0m, in \u001b[0;36mEvaluator._extract_TP_FP_FN\u001b[0;34m(self, model_response, ground_truth, similar_is_equal, similar_is_equal_threshold, similarity_types, words_level)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcleaner\u001b[38;5;241m.\u001b[39mverbose: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGINAL model_output: \u001b[39m\u001b[38;5;124m'\u001b[39m, model_response)\n\u001b[1;32m    413\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json(model_response)\n\u001b[0;32m--> 414\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m model_response \u001b[38;5;241m=\u001b[39m model_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    416\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m ground_truth[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[8], line 107\u001b[0m, in \u001b[0;36mEvaluator._parse_json\u001b[0;34m(self, model_response, drop_duplicates)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORA STO PARSANDO: \u001b[39m\u001b[38;5;124m'\u001b[39m, model_response, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    106\u001b[0m model_response \u001b[38;5;241m=\u001b[39m model_response\n\u001b[0;32m--> 107\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# print('OUTPUT: ', type(output))\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop_duplicates:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Invalid control character at: line 1 column 20 (char 19)"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "#from utils.evaluator import Evaluator\n",
    "#from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "file = 'data/zefiro/4bit_FT/maxNewTokensFactor8_nShotsInference4_zefiro-7b-base-ita__adapters_it.layer1_4_torch.bfloat16_32_64_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner(verbose=True)\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False) #.select(range(12,13))\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                    words_level=True, similarity_types=['case', 'stop_words', 'subset', 'superset', 'leveshtein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluation_table['evaluation'].to_csv('data/EVAL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from utils.evaluator import Evaluator\n",
    "# from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_threshold_list = [100]\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/zefiro/4bit_FT/*.csv') \n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "output_cleaner = OutputCleaner(verbose=True)\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "        # print(f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\")\n",
    "        evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "        evaluator.generate_evaluation_table(similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                            words_level=True, \n",
    "                                            similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "        #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "        evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "        # print('DONE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
