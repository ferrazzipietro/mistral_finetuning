{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from tqdm import tqdm \n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from log import enlayer1_3epochs_4bits__ft_params as models_params\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "class OutputCleaner():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "  \n",
    "    def _remove_space_from_dict_keys(self, model_ouput_list: list) -> list:\n",
    "        \"\"\"\n",
    "        Remove the spaces from the keys of a dictionary. E.g., [{\"entity \": \"value\"}] -> [{\"entity\": \"value\"}]\n",
    "\n",
    "        Args:\n",
    "        model_ouput_list (dict): the list of dictionaries to be cleaned\n",
    "\n",
    "        return:\n",
    "        list: the cleaned list of dicts\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for dict in model_ouput_list:\n",
    "            out.append({k.replace(' ', ''): v for k, v in dict.items()})\n",
    "        return out\n",
    "    \n",
    "    def _drop_duplicates(self, model_response: list) -> str:\n",
    "        \"\"\"\n",
    "        Drop the duplicates from a list. This is useful when the model output contains the same entity multiple times.\n",
    "\n",
    "        Args:\n",
    "        model_response (str): the model response with no duplicates\n",
    "        \"\"\"\n",
    "        try :\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        except Exception as error:\n",
    "            model_response = self._remove_space_from_dict_keys(model_response)\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        \n",
    "    def _assess_model_output(self, model_response: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the model output is in the right format. If not, return False.\n",
    "        \n",
    "        Args:\n",
    "        model_output (str): the postprocessed model output after beeing passed to _postprocess_model_output()\n",
    "\n",
    "        return:\n",
    "        bool: True if the format is correct, False otherwise\n",
    "        \"\"\"\n",
    "        good_format = True\n",
    "        try :\n",
    "            res = json.loads(model_response)\n",
    "            # print( res)\n",
    "        except:\n",
    "            good_format = False\n",
    "        return good_format\n",
    "    \n",
    "    def _clean_model_output(self, example: dict) -> str:\n",
    "        \"\"\"\n",
    "        Postprocess the model output to return a json like formatted string that can be used to compute the F1 score.\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the model output as it is returned by the model. The processing of the output is done in the function\n",
    "\n",
    "        return:\n",
    "        str: the model response, i.e. the model output without the instruction\n",
    "\n",
    "        \"\"\"\n",
    "        def has_unclosed_square_brackets(s):\n",
    "            count = 0\n",
    "            for char in s:\n",
    "                if char == '[':\n",
    "                    count += 1\n",
    "                elif char == ']':\n",
    "                    count -= 1\n",
    "                    if count < 0:\n",
    "                        return True\n",
    "            return count > 0\n",
    "        \n",
    "        def has_unopen_square_brackets(s):\n",
    "            count = 0\n",
    "            for char in s:\n",
    "                if char == '[':\n",
    "                    count -= 1\n",
    "                elif char == ']':\n",
    "                    count += 1\n",
    "                    if count > 0:\n",
    "                        return True\n",
    "            return count > 0\n",
    "        \n",
    "        def is_list_of_lists(string):\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, list) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_strings(string):\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, str) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        model_output = example['model_responses']\n",
    "\n",
    "        if model_output is None:\n",
    "            return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "        if is_list_of_lists(model_output):\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = str(tmp[0])\n",
    "            return {'model_output':tmp}\n",
    "\n",
    "        if is_list_of_strings(model_output):\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":el} for el in tmp]\n",
    "            tmp = str(tmp)\n",
    "            # print('TMP: ', tmp)\n",
    "            # raise Exception\n",
    "            return {'model_output': tmp}\n",
    "\n",
    "        \n",
    "        if self._assess_model_output(model_output):\n",
    "            return {'model_output':model_output}\n",
    "        \n",
    "        if has_unopen_square_brackets(model_output):\n",
    "            last_bracket_index = model_output.rfind('],') # keep the closed list\n",
    "            model_output = '[' + model_output[:last_bracket_index+1] \n",
    "            return {'model_output':model_output} \n",
    "        \n",
    "        tmp = re.findall(r'\\[\\{(.+?)\\}\\]', model_output)\n",
    "        if len(tmp) != 0:\n",
    "            tmp = '[{' + tmp[0] + '}]'\n",
    "            if self._assess_model_output(tmp):\n",
    "                return {'model_output':tmp}\n",
    "            \n",
    "        if has_unclosed_square_brackets(model_output):\n",
    "            last_bracket_index = model_output.rfind('},') # find the last complete entity\n",
    "            model_output = model_output[:last_bracket_index+1] + ']' \n",
    "            return {'model_output':model_output} \n",
    "\n",
    "\n",
    "        if model_output.strip()[0] == '{':\n",
    "            tmp = '[' + model_output + ']'\n",
    "            if self._assess_model_output(tmp):\n",
    "                return {'model_output':tmp}\n",
    "            else:\n",
    "                last_bracket_index = model_output.rfind('},') # find the last complete entity\n",
    "                model_output = '[' + model_output[:last_bracket_index+1] + ']'\n",
    "                return {'model_output':model_output}\n",
    "            \n",
    "        if model_output.strip().startswith('[['):\n",
    "            tmp = model_output[1:]\n",
    "            if self._assess_model_output(tmp):\n",
    "                return {'model_output':tmp}\n",
    "        print('THIS IS A BROKEN ROW: ', model_output)\n",
    "\n",
    "        return {'model_output':model_output}\n",
    "\n",
    "    \n",
    "    def apply_cleaning(self, data) -> None:\n",
    "        \"\"\"\n",
    "        Apply the cleaning to the model output and return the cleaned response in a new cloumn called 'model_output\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the model output as it is returned by the model. The processing of the output is done in the function\n",
    "\n",
    "        return:\n",
    "        str: the model response, i.e. the model output without the instruction\n",
    "        \"\"\"\n",
    "        return data.map(lambda x: self._clean_model_output(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 80\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation':      TP  FP  FN\n",
       " 0     3   2   7\n",
       " 1     0   0   4\n",
       " 2     3   4   1\n",
       " 3     0   0   5\n",
       " 4     0   0   2\n",
       " ..   ..  ..  ..\n",
       " 676   0   0   4\n",
       " 677   3   0   1\n",
       " 678   0   0   3\n",
       " 679   0   0   5\n",
       " 680   2   5   2\n",
       " \n",
       " [681 rows x 3 columns],\n",
       " 'precision': 0.6470588235294118,\n",
       " 'recall': 0.2982646420824295,\n",
       " 'f1': 0.4083147735708983}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.002.csv\n",
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1074.82 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1071.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1168.76 examples/s]\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS A BROKEN ROW:  \"INST \"\"\" \"entity>>>>>>. contained Ex injsonentity\"},tract format \"entity\" a\"\" \"tract \"tractentity>>>0 <<entity.\":tractentity the \"entity \"\"\": \" Ex {\" \" \"tractentity \" \" only>>>\"},:\n",
      "THIS IS A BROKEN ROW:  \"}, Exthe \"\"},\"}, \" \" \"entitytract  in Ex in format \" \"tract\" in containedINST\"}, \"INST \"\":tracttract \" \" \"entity \" contained. contained.1.\": \"tract in \"tract \"json\",. containedtracttracttract.\n",
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1165.68 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1251.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1253.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS A BROKEN ROW:  Question: Extract the entities contained in the text.\n",
      " Return the result in a json format.\n",
      " Text: <<She received an epidural anesthesia, with\n",
      "THIS IS A BROKEN ROW:  - findings\n",
      "- cancer\n",
      "- liver\n",
      "- parotid malignancy\n",
      "THIS IS A BROKEN ROW:  - {\"entity\": \"hypertensive\"},\n",
      "- {\"entity\": \"hospitalized\"},\n",
      "- {\"entity\": \"mass\"},\n",
      "- {\"entity\": \"appeared\"},\n",
      "- {\"entity\": \"cervical mass\"},\n",
      "- {\"entity\": \"A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1277.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1217.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS A BROKEN ROW:  \"diagnosed\": {\"entity\": \"diabetes mellitus\"},\n",
      "  \"referred\": {\"entity\": \"hypokalemia\"},\n",
      "  \"hypertension\", \"dyslipidemia\", \"hypertension\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1301.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1165.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 757.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS A BROKEN ROW:  [\"study\"], [\"tests\"], [\"indicated\"]\n",
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1245.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1102.51 examples/s]\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1209.20 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1184.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:193: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1027.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1312.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1259.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1090.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS A BROKEN ROW:  [\"managed\"] \n",
      "\n",
      "Note:The text contains entities not contained in the text. The entities returned are the ones contained in the text.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/test_data_processed/*.csv')\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if file.strip().endswith('0.002'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "        elif not similar_is_equal:\n",
    "            evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluators\n",
    "evaluation_results[ evaluation_results['f1_score'] == evaluation_results['f1_score'].max()]\n",
    "evaluation_results[ evaluation_results['f1_score'] == evaluation_results['f1_score'].max()]['file'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluators' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adapt, vals \u001b[38;5;129;01min\u001b[39;00m \u001b[43mevaluators\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madapt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madapt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluators' is not defined"
     ]
    }
   ],
   "source": [
    "for adapt, vals in evaluators.items():\n",
    "    print(f'adapt: {adapt}\\n {vals[\"f1\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cleaner = OutputCleaner()\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data)\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False)\n",
    "evaluator.generate_evaluation_table(similar_is_equal=True, similar_is_equal_threshold=80)\n",
    "tmp = evaluator.evaluation_table\n",
    "tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
