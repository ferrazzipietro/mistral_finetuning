{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                                        words_level=True, \n",
    "                                                        similarity_types=['case', 'stop_words', 'subset', 'superset'])#,'leveshtein'])\n",
    "                    # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>0.635337</td>\n",
       "      <td>0.614908</td>\n",
       "      <td>0.657171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>65</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.005028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "482  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "480  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "478  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "485  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "484  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "..                                                 ...               ...   \n",
       "598  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "599  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "600  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "601  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "595  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "482                          70  0.635337   0.614908  0.657171  \n",
       "480                          80  0.635337   0.614908  0.657171  \n",
       "478                          90  0.635337   0.614908  0.657171  \n",
       "485                         100  0.635337   0.614908  0.657171  \n",
       "484                          60  0.635337   0.614908  0.657171  \n",
       "..                          ...       ...        ...       ...  \n",
       "598                          75  0.008748   0.033635  0.005028  \n",
       "599                          70  0.008748   0.033635  0.005028  \n",
       "600                          65  0.008748   0.033635  0.005028  \n",
       "601                          60  0.008748   0.033635  0.005028  \n",
       "595                          90  0.008748   0.033635  0.005028  \n",
       "\n",
       "[621 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 60].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation_results.to_csv('data/mistral/evaluation_results/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test_data_processed/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv',\n",
       " 'data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 100].sort_values(by='f1_score', ascending=False)['file'].to_list()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation':      TP  FP  FN\n",
       " 0     5   1   5\n",
       " 1     4   0   0\n",
       " 2     3   0   1\n",
       " 3     4   0   1\n",
       " 4     2   3   0\n",
       " ..   ..  ..  ..\n",
       " 676   4   0   0\n",
       " 677   4   1   0\n",
       " 678   3   2   0\n",
       " 679   3   1   2\n",
       " 680   3   3   1\n",
       " \n",
       " [681 rows x 3 columns],\n",
       " 'precision': 0.7872415001752541,\n",
       " 'recall': 0.6090021691973969,\n",
       " 'f1': 0.6867451460021403}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file ='data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                    words_level=False, similarity_types=['case', 'stop_words', 'subset', 'superset', 'leveshtein'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation':      TP  FP  FN\n",
       " 0     7   9   7\n",
       " 1     4   8   0\n",
       " 2     4   8   4\n",
       " 3     5   8   1\n",
       " 4     2  11   0\n",
       " ..   ..  ..  ..\n",
       " 676   2  10   2\n",
       " 677   3   8   2\n",
       " 678   2   9   3\n",
       " 679   6   8   4\n",
       " 680   2   9   6\n",
       " \n",
       " [681 rows x 3 columns],\n",
       " 'precision': 0.3156546793298474,\n",
       " 'recall': 0.5075497597803706,\n",
       " 'f1': 0.3892361339561814}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file ='data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                    words_level=True, similarity_types=['case', 'stop_words', 'subset', 'superset'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE MODEL MISTRAL 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit_base/*.csv') \n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.333916</td>\n",
       "      <td>0.260224</td>\n",
       "      <td>0.465835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.321196</td>\n",
       "      <td>0.250189</td>\n",
       "      <td>0.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>0.243325</td>\n",
       "      <td>0.437364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.309780</td>\n",
       "      <td>0.241062</td>\n",
       "      <td>0.433297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.308811</td>\n",
       "      <td>0.240308</td>\n",
       "      <td>0.431941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.128506</td>\n",
       "      <td>0.281651</td>\n",
       "      <td>0.083243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.127428</td>\n",
       "      <td>0.085827</td>\n",
       "      <td>0.247289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.127009</td>\n",
       "      <td>0.085545</td>\n",
       "      <td>0.246475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.126729</td>\n",
       "      <td>0.085357</td>\n",
       "      <td>0.245933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>0.070487</td>\n",
       "      <td>0.203091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "133  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "132  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "131  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "130  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "138  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "..                                                 ...               ...   \n",
       "19   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "31   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "30   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "38   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "39   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "133                          80  0.333916   0.260224  0.465835  \n",
       "132                          85  0.321196   0.250189  0.448482  \n",
       "131                          90  0.312688   0.243325  0.437364  \n",
       "130                          95  0.309780   0.241062  0.433297  \n",
       "138                         100  0.308811   0.240308  0.431941  \n",
       "..                          ...       ...        ...       ...  \n",
       "19                          100  0.128506   0.281651  0.083243  \n",
       "31                           90  0.127428   0.085827  0.247289  \n",
       "30                           95  0.127009   0.085545  0.246475  \n",
       "38                          100  0.126729   0.085357  0.245933  \n",
       "39                          100  0.104653   0.070487  0.203091  \n",
       "\n",
       "[84 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 80].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE MODEL MISTRAL 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/4bit_base/maxNewTokensFactor8_nShotsInference1_BaseModel.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/4bit_base/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if not file.strip().endswith('BaseModel.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.466546</td>\n",
       "      <td>0.445486</td>\n",
       "      <td>0.489696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.463026</td>\n",
       "      <td>0.446798</td>\n",
       "      <td>0.480477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.461848</td>\n",
       "      <td>0.456885</td>\n",
       "      <td>0.466920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.451200</td>\n",
       "      <td>0.434859</td>\n",
       "      <td>0.468818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.446995</td>\n",
       "      <td>0.426217</td>\n",
       "      <td>0.469902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.445845</td>\n",
       "      <td>0.440880</td>\n",
       "      <td>0.450922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.442473</td>\n",
       "      <td>0.426345</td>\n",
       "      <td>0.459870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.441708</td>\n",
       "      <td>0.445856</td>\n",
       "      <td>0.437636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.440010</td>\n",
       "      <td>0.423869</td>\n",
       "      <td>0.457430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.438910</td>\n",
       "      <td>0.422758</td>\n",
       "      <td>0.456345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.437484</td>\n",
       "      <td>0.416953</td>\n",
       "      <td>0.460141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.437148</td>\n",
       "      <td>0.432167</td>\n",
       "      <td>0.442245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.435309</td>\n",
       "      <td>0.414784</td>\n",
       "      <td>0.457972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.434021</td>\n",
       "      <td>0.413556</td>\n",
       "      <td>0.456616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.433548</td>\n",
       "      <td>0.428496</td>\n",
       "      <td>0.438720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.432744</td>\n",
       "      <td>0.427701</td>\n",
       "      <td>0.437907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.424508</td>\n",
       "      <td>0.428256</td>\n",
       "      <td>0.420824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.414114</td>\n",
       "      <td>0.417770</td>\n",
       "      <td>0.410521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.410832</td>\n",
       "      <td>0.414459</td>\n",
       "      <td>0.407267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.409408</td>\n",
       "      <td>0.412966</td>\n",
       "      <td>0.405911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.391293</td>\n",
       "      <td>0.376757</td>\n",
       "      <td>0.406996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.375886</td>\n",
       "      <td>0.358037</td>\n",
       "      <td>0.395607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.372990</td>\n",
       "      <td>0.368644</td>\n",
       "      <td>0.377440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.341763</td>\n",
       "      <td>0.344637</td>\n",
       "      <td>0.338937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/mistral/4bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.002711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  similar_is_equal  \\\n",
       "13  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "23  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "33  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "22  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "12  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "32  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "21  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "43  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "20  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "28  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "11  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "31  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "10  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "18  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "30  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "38  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "42  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "41  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "40  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "48  data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "29  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "19  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "39  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "49  data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "1   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "8   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "3   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "2   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "0   data/mistral/4bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "9   data/mistral/4bit_base/maxNewTokensFactor8_nSh...             False   \n",
       "\n",
       "    similar_is_equal_threshold  f1_score  precision    recall  \n",
       "13                          80  0.466546   0.445486  0.489696  \n",
       "23                          80  0.463026   0.446798  0.480477  \n",
       "33                          80  0.461848   0.456885  0.466920  \n",
       "22                          85  0.451200   0.434859  0.468818  \n",
       "12                          85  0.446995   0.426217  0.469902  \n",
       "32                          85  0.445845   0.440880  0.450922  \n",
       "21                          90  0.442473   0.426345  0.459870  \n",
       "43                          80  0.441708   0.445856  0.437636  \n",
       "20                          95  0.440010   0.423869  0.457430  \n",
       "28                         100  0.438910   0.422758  0.456345  \n",
       "11                          90  0.437484   0.416953  0.460141  \n",
       "31                          90  0.437148   0.432167  0.442245  \n",
       "10                          95  0.435309   0.414784  0.457972  \n",
       "18                         100  0.434021   0.413556  0.456616  \n",
       "30                          95  0.433548   0.428496  0.438720  \n",
       "38                         100  0.432744   0.427701  0.437907  \n",
       "42                          85  0.424508   0.428256  0.420824  \n",
       "41                          90  0.414114   0.417770  0.410521  \n",
       "40                          95  0.410832   0.414459  0.407267  \n",
       "48                         100  0.409408   0.412966  0.405911  \n",
       "29                         100  0.391293   0.376757  0.406996  \n",
       "19                         100  0.375886   0.358037  0.395607  \n",
       "39                         100  0.372990   0.368644  0.377440  \n",
       "49                         100  0.341763   0.344637  0.338937  \n",
       "1                           90  0.005207   0.065359  0.002711  \n",
       "8                          100  0.005207   0.065359  0.002711  \n",
       "3                           80  0.005207   0.065359  0.002711  \n",
       "2                           85  0.005207   0.065359  0.002711  \n",
       "0                           95  0.005207   0.065359  0.002711  \n",
       "9                          100  0.005206   0.064935  0.002711  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 80].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/mistral_4bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL BASE 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference1_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference4_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor4_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor2_nShotsInference1_BaseModel.csv\n",
      "FILE:  data/mistral/8bit_base/maxNewTokensFactor8_nShotsInference1_BaseModel.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit_base/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    if not file.strip().endswith('BaseModel.csv'):\n",
    "        continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.333916</td>\n",
       "      <td>0.260224</td>\n",
       "      <td>0.465835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.321196</td>\n",
       "      <td>0.250189</td>\n",
       "      <td>0.448482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>0.243325</td>\n",
       "      <td>0.437364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.309780</td>\n",
       "      <td>0.241062</td>\n",
       "      <td>0.433297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor8_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.308811</td>\n",
       "      <td>0.240308</td>\n",
       "      <td>0.431941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.128506</td>\n",
       "      <td>0.281651</td>\n",
       "      <td>0.083243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.127428</td>\n",
       "      <td>0.085827</td>\n",
       "      <td>0.247289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.127009</td>\n",
       "      <td>0.085545</td>\n",
       "      <td>0.246475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.126729</td>\n",
       "      <td>0.085357</td>\n",
       "      <td>0.245933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/mistral/8bit_base/maxNewTokensFactor2_nSh...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>0.070487</td>\n",
       "      <td>0.203091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "133  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "132  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "131  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "130  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "138  data/mistral/8bit_base/maxNewTokensFactor8_nSh...              True   \n",
       "..                                                 ...               ...   \n",
       "19   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "31   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "30   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "38   data/mistral/8bit_base/maxNewTokensFactor2_nSh...              True   \n",
       "39   data/mistral/8bit_base/maxNewTokensFactor2_nSh...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "133                          80  0.333916   0.260224  0.465835  \n",
       "132                          85  0.321196   0.250189  0.448482  \n",
       "131                          90  0.312688   0.243325  0.437364  \n",
       "130                          95  0.309780   0.241062  0.433297  \n",
       "138                         100  0.308811   0.240308  0.431941  \n",
       "..                          ...       ...        ...       ...  \n",
       "19                          100  0.128506   0.281651  0.083243  \n",
       "31                           90  0.127428   0.085827  0.247289  \n",
       "30                           95  0.127009   0.085545  0.246475  \n",
       "38                          100  0.126729   0.085357  0.245933  \n",
       "39                          100  0.104653   0.070487  0.203091  \n",
       "\n",
       "[84 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold'] >= 80].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/mistral_8bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/mistral/8bit/*.csv') #'data/mistral/test_data_processed/*.csv'\n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    # if file.strip().endswith('0.002.csv'):\n",
    "    #     continue\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/mistral_8bit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.648048</td>\n",
       "      <td>0.633049</td>\n",
       "      <td>0.663774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.641816</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.686280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.638147</td>\n",
       "      <td>0.598386</td>\n",
       "      <td>0.683568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.638144</td>\n",
       "      <td>0.631369</td>\n",
       "      <td>0.645065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.631801</td>\n",
       "      <td>0.615860</td>\n",
       "      <td>0.648590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.019928</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>data/mistral/8bit/maxNewTokensFactor8_nShotsIn...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.002440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "535  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "54   data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "555  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "164  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "534  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "..                                                 ...               ...   \n",
       "669  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "663  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "662  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "661  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...              True   \n",
       "670  data/mistral/8bit/maxNewTokensFactor8_nShotsIn...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "535                          75  0.648048   0.633049  0.663774  \n",
       "54                           75  0.641816   0.602763  0.686280  \n",
       "555                          75  0.638147   0.598386  0.683568  \n",
       "164                          75  0.638144   0.631369  0.645065  \n",
       "534                          80  0.631801   0.615860  0.648590  \n",
       "..                          ...       ...        ...       ...  \n",
       "669                         100  0.005189   0.019928  0.002983  \n",
       "663                          85  0.005189   0.019928  0.002983  \n",
       "662                          90  0.005189   0.019928  0.002983  \n",
       "661                          95  0.005189   0.019928  0.002983  \n",
       "670                         100  0.004245   0.016304  0.002440  \n",
       "\n",
       "[484 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA 13 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0008.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference4_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "FILE:  data/llama/13B_4bit/maxNewTokensFactor8_nShotsInference2_Llama-2-13b-chat-hf_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0008.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/13B_4bit/*.csv') \n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=100,\n",
    "                                                words_level=True,\n",
    "                                                similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "            evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "\n",
    "        elif not similar_is_equal:\n",
    "            evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100,\n",
    "                                                words_level=True,\n",
    "                                                similarity_types=['case', 'stop_words', 'subset', 'superset'])\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            # print('DONE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.481901</td>\n",
       "      <td>0.368749</td>\n",
       "      <td>0.695238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.478199</td>\n",
       "      <td>0.368759</td>\n",
       "      <td>0.680013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.472521</td>\n",
       "      <td>0.366797</td>\n",
       "      <td>0.663874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.450015</td>\n",
       "      <td>0.330673</td>\n",
       "      <td>0.704145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.448366</td>\n",
       "      <td>0.333982</td>\n",
       "      <td>0.681909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.215044</td>\n",
       "      <td>0.142909</td>\n",
       "      <td>0.434225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.207913</td>\n",
       "      <td>0.138867</td>\n",
       "      <td>0.413521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.207215</td>\n",
       "      <td>0.138471</td>\n",
       "      <td>0.411506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.206795</td>\n",
       "      <td>0.137973</td>\n",
       "      <td>0.412605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>data/llama/13B_4bit/maxNewTokensFactor8_nShots...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.199068</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>0.395200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "82   data/llama/13B_4bit/maxNewTokensFactor8_nShots...              True   \n",
       "26   data/llama/13B_4bit/maxNewTokensFactor8_nShots...              True   \n",
       "40   data/llama/13B_4bit/maxNewTokensFactor8_nShots...              True   \n",
       "114  data/llama/13B_4bit/maxNewTokensFactor8_nShots...              True   \n",
       "42   data/llama/13B_4bit/maxNewTokensFactor8_nShots...              True   \n",
       "..                                                 ...               ...   \n",
       "63   data/llama/13B_4bit/maxNewTokensFactor8_nShots...             False   \n",
       "5    data/llama/13B_4bit/maxNewTokensFactor8_nShots...             False   \n",
       "131  data/llama/13B_4bit/maxNewTokensFactor8_nShots...             False   \n",
       "105  data/llama/13B_4bit/maxNewTokensFactor8_nShots...             False   \n",
       "141  data/llama/13B_4bit/maxNewTokensFactor8_nShots...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "82                          100  0.481901   0.368749  0.695238  \n",
       "26                          100  0.478199   0.368759  0.680013  \n",
       "40                          100  0.472521   0.366797  0.663874  \n",
       "114                         100  0.450015   0.330673  0.704145  \n",
       "42                          100  0.448366   0.333982  0.681909  \n",
       "..                          ...       ...        ...       ...  \n",
       "63                          100  0.215044   0.142909  0.434225  \n",
       "5                           100  0.207913   0.138867  0.413521  \n",
       "131                         100  0.207215   0.138471  0.411506  \n",
       "105                         100  0.206795   0.137973  0.412605  \n",
       "141                         100  0.199068   0.133041  0.395200  \n",
       "\n",
       "[144 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/llama13B_4bit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/8bit/*.csv') \n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hormonal study and dynamic biochemical tests performed indicated ECS.',\n",
       " 'entities': \"[{'id': '1704', 'offsets': array([ 9, 14]), 'role': '', 'semantic_type_id': '', 'text': 'study', 'type': 'EVENT'}\\n {'id': '1719', 'offsets': array([39, 44]), 'role': '', 'semantic_type_id': '', 'text': 'tests', 'type': 'EVENT'}\\n {'id': '1734', 'offsets': array([55, 64]), 'role': '', 'semantic_type_id': '', 'text': 'indicated', 'type': 'EVENT'}\\n {'id': '1749', 'offsets': array([65, 68]), 'role': '', 'semantic_type_id': '', 'text': 'ECS', 'type': 'EVENT'}]\",\n",
       " 'original_text': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia. Hormonal study and dynamic biochemical tests performed indicated ECS. Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases. Somatostatin receptor scintigraphy has shown an increased uptake in the parotid gland and mild expression in liver metastasis. The patient underwent right parotidectomy, and histopathologic examination confirmed ACC. Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide. Despite chemotherapy onset, a rapid disease progression and clinical course deterioration was observed.\\r\\n',\n",
       " 'original_id': 'EN101783',\n",
       " 'prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST][{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"indicated\"}, {\"entity\": \"ECS\"}] </s>',\n",
       " 'inference_prompt': '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST]',\n",
       " 'ground_truth': '[{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"indicated\"}, {\"entity\": \"ECS\"}]',\n",
       " 'model_responses': '[{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST] [{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"ECS\"}, {\"entity\": \"indicated\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<A 1-year-old boy presented with a 2-day history of fever and vomiting.>>> [/INST][{\"entity\": \"presented\"}, {\"entity',\n",
       " 'model_output': \"[{'entity': 'present'}, {'entity': 'history'}, {'entity': 'enlargement'}, {'entity': 'entity_name'}, {'entity': 'presented'}, {'entity': 'refusal'}, {'entity': 'bear'}, {'entity': 'peaks'}, {'entity': 'entity_name'}, {'entity': 'study'}, {'entity': 'tests'}, {'entity': 'ECS'}, {'entity': 'indicated'}, {'entity': 'entity_name'}, {'entity': 'presented'}]\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.405388</td>\n",
       "      <td>0.277098</td>\n",
       "      <td>0.754881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.404637</td>\n",
       "      <td>0.276725</td>\n",
       "      <td>0.752440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.398314</td>\n",
       "      <td>0.272060</td>\n",
       "      <td>0.743221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.396249</td>\n",
       "      <td>0.271486</td>\n",
       "      <td>0.733189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.396191</td>\n",
       "      <td>0.270660</td>\n",
       "      <td>0.738883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.250214</td>\n",
       "      <td>0.182912</td>\n",
       "      <td>0.395879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.248097</td>\n",
       "      <td>0.181227</td>\n",
       "      <td>0.393167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>0.180477</td>\n",
       "      <td>0.391540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.180080</td>\n",
       "      <td>0.390727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>data/llama/8bit/maxNewTokensFactor8_nShotsInfe...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.240294</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.380965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "354  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "104  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "353  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "374  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "103  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "..                                                 ...               ...   \n",
       "272  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "271  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "270  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "278  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...              True   \n",
       "279  data/llama/8bit/maxNewTokensFactor8_nShotsInfe...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "354                          75  0.405388   0.277098  0.754881  \n",
       "104                          75  0.404637   0.276725  0.752440  \n",
       "353                          80  0.398314   0.272060  0.743221  \n",
       "374                          75  0.396249   0.271486  0.733189  \n",
       "103                          80  0.396191   0.270660  0.738883  \n",
       "..                          ...       ...        ...       ...  \n",
       "272                          85  0.250214   0.182912  0.395879  \n",
       "271                          90  0.248097   0.181227  0.393167  \n",
       "270                          95  0.247070   0.180477  0.391540  \n",
       "278                         100  0.246536   0.180080  0.390727  \n",
       "279                         100  0.240294   0.175493  0.380965  \n",
       "\n",
       "[280 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/llama7b_8bit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAM7 BASE 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/7B_4bit_base/*.csv') \n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.271827</td>\n",
       "      <td>0.230436</td>\n",
       "      <td>0.331345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.261285</td>\n",
       "      <td>0.221447</td>\n",
       "      <td>0.318601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.254501</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>0.310466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.248140</td>\n",
       "      <td>0.210160</td>\n",
       "      <td>0.302874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.247668</td>\n",
       "      <td>0.209744</td>\n",
       "      <td>0.302332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/llama/7B_4bit_base/maxNewTokensFactor2_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file  similar_is_equal  \\\n",
       "144  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "143  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "142  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "141  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "140  data/llama/7B_4bit_base/maxNewTokensFactor8_nS...              True   \n",
       "..                                                 ...               ...   \n",
       "12   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "13   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "18   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "10   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...              True   \n",
       "19   data/llama/7B_4bit_base/maxNewTokensFactor2_nS...             False   \n",
       "\n",
       "     similar_is_equal_threshold  f1_score  precision    recall  \n",
       "144                          75  0.271827   0.230436  0.331345  \n",
       "143                          80  0.261285   0.221447  0.318601  \n",
       "142                          85  0.254501   0.215631  0.310466  \n",
       "141                          90  0.248140   0.210160  0.302874  \n",
       "140                          95  0.247668   0.209744  0.302332  \n",
       "..                          ...       ...        ...       ...  \n",
       "12                           85  0.003781   0.466667  0.001898  \n",
       "13                           80  0.003781   0.466667  0.001898  \n",
       "18                          100  0.003781   0.466667  0.001898  \n",
       "10                           95  0.003781   0.466667  0.001898  \n",
       "19                          100  0.003241   0.400000  0.001627  \n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/llama7b_4bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA7 BASE 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [file, similar_is_equal, similar_is_equal_threshold, f1_score, precision, recall]\n",
      "Index: []\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference0_BaseModel.csv\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference2_BaseModel.csv\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference3_BaseModel.csv\n",
      "FILE:  data/llama/7B_8bit_base/maxNewTokensFactor8_nShotsInference1_BaseModel.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "#adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "evaluators = {}\n",
    "csv_files = glob.glob('data/llama/7B_8bit_base/*.csv') \n",
    "#csv_files = ['data/test_data_processed/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv']\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "print(evaluation_results)\n",
    "for file in csv_files:\n",
    "    print(\"FILE: \" , file)\n",
    "    eval_data = Dataset.from_csv(file) \n",
    "    output_cleaner = OutputCleaner()\n",
    "    cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "    for similar_is_equal in similar_is_equal_list:\n",
    "        if similar_is_equal:\n",
    "            for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "                # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                                \n",
    "                try:\n",
    "                    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                    evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal_threshold, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "                    #evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}_Threshold{similar_is_equal_threshold}\"] = evaluator\n",
    "                    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                    # print('DONE')\n",
    "                except:\n",
    "                    break\n",
    "        elif not similar_is_equal:\n",
    "            # evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "            # evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "            # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "            # evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n",
    "            try:\n",
    "                evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "                evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=100)\n",
    "                # evaluators[f\"{file}_SimilarIsEqual{similar_is_equal}\"] = evaluator\n",
    "                evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': similar_is_equal, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                # print('DONE')\n",
    "            except:\n",
    "                #print('SKIPPING THIS')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>similar_is_equal</th>\n",
       "      <th>similar_is_equal_threshold</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.244096</td>\n",
       "      <td>0.350325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.285771</td>\n",
       "      <td>0.532939</td>\n",
       "      <td>0.195228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.276906</td>\n",
       "      <td>0.234850</td>\n",
       "      <td>0.337310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.271771</td>\n",
       "      <td>0.506282</td>\n",
       "      <td>0.185738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.271473</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>0.330803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.265436</td>\n",
       "      <td>0.225052</td>\n",
       "      <td>0.323482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.264457</td>\n",
       "      <td>0.224170</td>\n",
       "      <td>0.322397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.263790</td>\n",
       "      <td>0.223605</td>\n",
       "      <td>0.321584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.479351</td>\n",
       "      <td>0.176247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.252131</td>\n",
       "      <td>0.468681</td>\n",
       "      <td>0.172451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.251338</td>\n",
       "      <td>0.467207</td>\n",
       "      <td>0.171909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.250545</td>\n",
       "      <td>0.465733</td>\n",
       "      <td>0.171367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.239001</td>\n",
       "      <td>0.176236</td>\n",
       "      <td>0.371204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.237282</td>\n",
       "      <td>0.171588</td>\n",
       "      <td>0.384490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.234052</td>\n",
       "      <td>0.172565</td>\n",
       "      <td>0.363612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.232185</td>\n",
       "      <td>0.171146</td>\n",
       "      <td>0.360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.231104</td>\n",
       "      <td>0.170215</td>\n",
       "      <td>0.359816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.231064</td>\n",
       "      <td>0.170172</td>\n",
       "      <td>0.359816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.230890</td>\n",
       "      <td>0.170044</td>\n",
       "      <td>0.359544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0.229322</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.371746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228203</td>\n",
       "      <td>0.193439</td>\n",
       "      <td>0.278200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>0.224191</td>\n",
       "      <td>0.162054</td>\n",
       "      <td>0.363612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>0.222037</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>0.360629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>0.221666</td>\n",
       "      <td>0.160116</td>\n",
       "      <td>0.360087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>0.221499</td>\n",
       "      <td>0.159995</td>\n",
       "      <td>0.359816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.217134</td>\n",
       "      <td>0.159913</td>\n",
       "      <td>0.338124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.202180</td>\n",
       "      <td>0.375829</td>\n",
       "      <td>0.138286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/llama/7B_8bit_base/maxNewTokensFactor8_nS...</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.198798</td>\n",
       "      <td>0.143598</td>\n",
       "      <td>0.322939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  similar_is_equal  \\\n",
       "34  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "4   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "33  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "3   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "32  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "31  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "30  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "38  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "2   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "1   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "0   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "8   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "14  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "24  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "13  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "12  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "11  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "10  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "18  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "23  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "39  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "22  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "21  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "20  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "28  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...              True   \n",
       "19  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "9   data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "29  data/llama/7B_8bit_base/maxNewTokensFactor8_nS...             False   \n",
       "\n",
       "    similar_is_equal_threshold  f1_score  precision    recall  \n",
       "34                          75  0.287719   0.244096  0.350325  \n",
       "4                           75  0.285771   0.532939  0.195228  \n",
       "33                          80  0.276906   0.234850  0.337310  \n",
       "3                           80  0.271771   0.506282  0.185738  \n",
       "32                          85  0.271473   0.230189  0.330803  \n",
       "31                          90  0.265436   0.225052  0.323482  \n",
       "30                          95  0.264457   0.224170  0.322397  \n",
       "38                         100  0.263790   0.223605  0.321584  \n",
       "2                           85  0.257732   0.479351  0.176247  \n",
       "1                           90  0.252131   0.468681  0.172451  \n",
       "0                           95  0.251338   0.467207  0.171909  \n",
       "8                          100  0.250545   0.465733  0.171367  \n",
       "14                          75  0.239001   0.176236  0.371204  \n",
       "24                          75  0.237282   0.171588  0.384490  \n",
       "13                          80  0.234052   0.172565  0.363612  \n",
       "12                          85  0.232185   0.171146  0.360900  \n",
       "11                          90  0.231104   0.170215  0.359816  \n",
       "10                          95  0.231064   0.170172  0.359816  \n",
       "18                         100  0.230890   0.170044  0.359544  \n",
       "23                          80  0.229322   0.165800  0.371746  \n",
       "39                         100  0.228203   0.193439  0.278200  \n",
       "22                          85  0.224191   0.162054  0.363612  \n",
       "21                          90  0.222037   0.160396  0.360629  \n",
       "20                          95  0.221666   0.160116  0.360087  \n",
       "28                         100  0.221499   0.159995  0.359816  \n",
       "19                         100  0.217134   0.159913  0.338124  \n",
       "9                          100  0.202180   0.375829  0.138286  \n",
       "29                         100  0.198798   0.143598  0.322939  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[evaluation_results['similar_is_equal_threshold']>=75].sort_values(by='f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation_results.to_csv('data/evaluation_results/llama7b_8bit_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL BASE simplest_prompt one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1050.15it/s]\n",
      "Generating train split: 681 examples [00:00, 20161.65 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 10661.97 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 6854.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evaluation':      TP  FP  FN\n",
      "0     0   0  10\n",
      "1     0   1   4\n",
      "2     0   0   4\n",
      "3     5   0   0\n",
      "4     1   0   1\n",
      "..   ..  ..  ..\n",
      "676   0   0   4\n",
      "677   3   0   1\n",
      "678   3   0   0\n",
      "679   3   1   2\n",
      "680   0   0   4\n",
      "\n",
      "[681 rows x 3 columns], 'precision': 0.7130730050933786, 'recall': 0.34164859002169196, 'f1': 0.46196150320806595}\n",
      "{'evaluation':      TP  FP  FN\n",
      "0     2   0   8\n",
      "1     3   0   1\n",
      "2     2   1   2\n",
      "3     3   0   2\n",
      "4     2   1   0\n",
      "..   ..  ..  ..\n",
      "676   2   1   2\n",
      "677   3   0   1\n",
      "678   2   1   1\n",
      "679   2   1   3\n",
      "680   3   0   1\n",
      "\n",
      "[681 rows x 3 columns], 'precision': 0.6405353728489483, 'recall': 0.2725054229934924, 'f1': 0.3823473463952825}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "similar_is_equal_list = postprocessing.similar_is_equal_list\n",
    "similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list\n",
    "\n",
    "file = 'data/test_data_processed/maxNewTokensFactor6_nShotsInference0_Mistral-7B-v0.1_simplest_prompt_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 80\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator_mistral_base = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_mistral_base.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "\n",
    "\n",
    "file = 'data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 80\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "evaluator_mistral_instruct = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "evaluator_mistral_instruct.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold)\n",
    "\n",
    "print(evaluator_mistral_instruct.evaluation_table)\n",
    "print(evaluator_mistral_base.evaluation_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "\n",
    "class OutputCleaner():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "  \n",
    "    def _remove_space_from_dict_keys(self, model_ouput_list: list) -> list:\n",
    "        \"\"\"\n",
    "        Remove the spaces from the keys of a dictionary. E.g., [{\"entity \": \"value\"}] -> [{\"entity\": \"value\"}]\n",
    "\n",
    "        Args:\n",
    "        model_ouput_list (dict): the list of dictionaries to be cleaned\n",
    "\n",
    "        return:\n",
    "        list: the cleaned list of dicts\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for dict in model_ouput_list:\n",
    "            out.append({k.replace(' ', ''): v for k, v in dict.items()})\n",
    "        return out\n",
    "    \n",
    "    def _drop_duplicates(self, model_response: list) -> str:\n",
    "        \"\"\"\n",
    "        Drop the duplicates from a list. This is useful when the model output contains the same entity multiple times.\n",
    "\n",
    "        Args:\n",
    "        model_response (str): the model response with no duplicates\n",
    "        \"\"\"\n",
    "        try :\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        except Exception as error:\n",
    "            model_response = self._remove_space_from_dict_keys(model_response)\n",
    "            return list({v['entity']:v for v in model_response}.values())\n",
    "        \n",
    "    def _assess_model_output(self, model_response: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the model output is in the right format. If not, return False.\n",
    "        \n",
    "        Args:\n",
    "        model_output (str): the postprocessed model output after beeing passed to _postprocess_model_output()\n",
    "\n",
    "        return:\n",
    "        bool: True if the format is correct, False otherwise\n",
    "        \"\"\"\n",
    "        good_format = True\n",
    "        try :\n",
    "            res = json.loads(model_response)\n",
    "            # print( res)\n",
    "        except:\n",
    "            good_format = False\n",
    "        return good_format\n",
    "\n",
    "            \n",
    "    def _remove_json_special_chars(self, string):\n",
    "        chars = ['\\xa0']\n",
    "        for char in chars:\n",
    "            string = string.replace(char, ' ')\n",
    "        return string\n",
    "    \n",
    "    def _clean_ground_truth(self, example: dict) -> dict:\n",
    "        ground_truth = example['ground_truth']\n",
    "        ground_truth = self._remove_json_special_chars(ground_truth)\n",
    "        if ground_truth == ']':\n",
    "            ground_truth = '[' + ground_truth\n",
    "        return({'ground_truth': ground_truth})\n",
    "\n",
    "    def _clean_model_output(self, example: dict,  wrong_keys_to_entity:bool, latest_version:bool=True) -> dict:\n",
    "        \"\"\"\n",
    "        Postprocess the model output to return a json like formatted string that can be used to compute the F1 score.\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the model output as it is returned by the model. The processing of the output is done in the function\n",
    "        wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'. If not, all keys that are not 'entity' are dropped\n",
    "\n",
    "        return:\n",
    "        dict: the model response\n",
    "\n",
    "        \"\"\"\n",
    "        def has_unclosed_square_brackets(s:str)  -> bool:\n",
    "            count = 0\n",
    "            for char in s:\n",
    "                if char == '[':\n",
    "                    count += 1\n",
    "                elif char == ']':\n",
    "                    count -= 1\n",
    "                    if count < 0:\n",
    "                        return True\n",
    "            return count > 0\n",
    "        \n",
    "        def has_unopen_square_brackets(s:str)  -> bool:\n",
    "            count = 0\n",
    "            for char in s:\n",
    "                if char == '[':\n",
    "                    count -= 1\n",
    "                elif char == ']':\n",
    "                    count += 1\n",
    "                    if count > 0:\n",
    "                        return True\n",
    "            return count > 0\n",
    "        \n",
    "        def is_empty_list(string:str)  -> bool:\n",
    "            if string=='[]':\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_lists(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, list) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_dicts(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, dict) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_lists_and_dict(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                found_dict = False\n",
    "                found_list = False\n",
    "                for element in tmp:\n",
    "                    if isinstance(element, list):\n",
    "                        found_list = True\n",
    "                    elif isinstance(element, dict):\n",
    "                        found_dict = True\n",
    "                    if found_list and found_dict:\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_list_of_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, list) and all(isinstance(item, str) for item in tmp):\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        def is_list_of_dicts_and_strings(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                #print('ASSESSED')\n",
    "                tmp = json.loads(string)\n",
    "                found_dict = False\n",
    "                found_string = False\n",
    "                for element in tmp:\n",
    "                    if isinstance(element, str):\n",
    "                        found_string = True\n",
    "                    elif isinstance(element, dict):\n",
    "                        found_dict = True\n",
    "                    if found_string and found_dict:\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        def is_string(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, str):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def is_numeric(string:str)  -> bool:\n",
    "            if self._assess_model_output(string):\n",
    "                tmp = json.loads(string)\n",
    "                if isinstance(tmp, (int, float)):\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def are_entities_extracted_as_dict_keys_instead_of_values(string:str, example:dict) -> bool:\n",
    "            if is_list_of_dicts(string):\n",
    "                tmp = json.loads(string)\n",
    "                keys = [key for item in tmp for key in item.keys()]\n",
    "                if 'entity' not in keys:\n",
    "                    if all(entity in example['sentence'] for entity in keys):\n",
    "                        return True\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        \n",
    "        def convert_wrong_keys_into_entity(string:str) -> List[str]:\n",
    "            if is_list_of_dicts(string):\n",
    "                tmp = json.loads(string)\n",
    "                tmp = [str({\"entity\":v}) for el in tmp for v in el.values()]\n",
    "                return tmp\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "\n",
    "        def only_dicts_with_key_entity(string:str, wrong_keys_to_entity:bool) -> Tuple[bool, str]:\n",
    "            \"\"\"\n",
    "            Extract only the dictionaries with the key 'entity' in the list of dictionaries in the string\n",
    "            \n",
    "            Args:\n",
    "            string (str): the string to be cleaned\n",
    "            wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'\n",
    "            \"\"\"\n",
    "            els_between_curly = re.findall(r'\\{(.+?)\\}', string)\n",
    "            clean = [el for el in els_between_curly if el.startswith('\"entity\"') or el.startswith(\"'entity'\")]\n",
    "            clean = ['{' + el + '}' for el in clean]\n",
    "            dirty = []\n",
    "            if wrong_keys_to_entity:\n",
    "                dirty = [el for el in els_between_curly if (not el.startswith('\"entity\"')) and (not el.startswith(\"'entity'\"))]\n",
    "                dirty = ['{' + el + '}' for el in dirty]\n",
    "                dirty = '[' + ', '.join(dirty) + ']'\n",
    "                cleaned_dirty = convert_wrong_keys_into_entity(dirty)\n",
    "                out = '[' + ', '.join(clean) + ', '.join(cleaned_dirty) +  ']'\n",
    "            else:\n",
    "                out = '[' + ', '.join(clean) + ']'\n",
    "            out = out.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\" \\'\", \" \\\"\")\n",
    "            operations_performed = False\n",
    "            if len(clean) != len(els_between_curly):\n",
    "                operations_performed = True\n",
    "            if is_empty_list(out):\n",
    "                return operations_performed, '[{\"entity\":\"\"}]'\n",
    "            return operations_performed, str(out)\n",
    "        \n",
    "\n",
    "        model_output = example['model_responses']        \n",
    "        print('TESTTT')\n",
    "        print('ORIGINAL MODEL OUTPUT: ', model_output)\n",
    "        \n",
    "        if model_output is None or is_empty_list(model_output):\n",
    "            return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "        model_output = self._remove_json_special_chars(model_output)\n",
    "                \n",
    "        if are_entities_extracted_as_dict_keys_instead_of_values(model_output, example):\n",
    "            print('ENTITIES EXTRACTED AS DICT KEYS INSTEAD OF VALUES')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":k} for el in tmp for k in el.keys() ]\n",
    "            tmp = str(tmp)\n",
    "            return {'model_output':tmp}\n",
    "\n",
    "        if is_numeric(model_output):\n",
    "            print('IS NUMERIC')\n",
    "            return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "        if is_list_of_lists_and_dict(model_output):\n",
    "            print('is_list_of_lists_and_dict')\n",
    "            tmp = json.loads(model_output)\n",
    "            for el in tmp:\n",
    "                if isinstance(el, list):\n",
    "                    tmp = str(el)\n",
    "                    # print('is_list_of_lists_and_dict')\n",
    "                    return {'model_output':tmp}\n",
    "                \n",
    "        if is_list_of_lists(model_output):\n",
    "            print('is_list_of_lists')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp2 = str(tmp[0]).replace(\"'\", \"\\\"\")\n",
    "            if is_list_of_dicts_and_strings(tmp2):\n",
    "                tmp = tmp[0]\n",
    "                out = [item for item in tmp if isinstance(item, dict)]\n",
    "                print('questo:', out)\n",
    "                \n",
    "                return {'model_output':str(out)} \n",
    "            tmp = str(tmp[0])\n",
    "            return {'model_output':tmp}\n",
    "\n",
    "        if is_list_of_strings(model_output):\n",
    "            print('is_list_of_strings')\n",
    "            tmp = json.loads(model_output)\n",
    "            tmp = [{\"entity\":el} for el in tmp]\n",
    "            tmp = str(tmp)\n",
    "            # print('is_list_of_strings')\n",
    "            return {'model_output': tmp}\n",
    "        \n",
    "        if is_string(model_output):\n",
    "            # model_output = model_output.replace(\"{\\'\", \"{\\\"\").replace(\"\\'}\", \"\\\"}\").replace(\"\\'ent\", \"\\\"ent\").replace(\"ty\\'\", \"ty\\\"\").replace(\" \\'\", \" \\\"\")\n",
    "            print('PULITO: ', model_output)\n",
    "            tmp = json.loads(model_output)\n",
    "            if all(el in tmp for el in ['{', 'entity', '}']):\n",
    "                return {'model_output':tmp}\n",
    "            tmp = [{\"entity\":tmp}]\n",
    "            tmp = str(tmp)\n",
    "            #print('is_string')\n",
    "            return {'model_output':tmp}\n",
    "\n",
    "        \n",
    "        if latest_version:\n",
    "            model_output = self._extract_text_between_curl_brackets(model_output)\n",
    "            #last attempt to clean \n",
    "            model_output = self._clean_text_between_curl_brackets(model_output)\n",
    "            cleaning_done, cleaned_model_output = only_dicts_with_key_entity(model_output, wrong_keys_to_entity=wrong_keys_to_entity)\n",
    "            if cleaning_done:\n",
    "                model_output = cleaned_model_output\n",
    "            \n",
    "            if is_list_of_dicts(model_output):\n",
    "                tmp = json.loads(model_output)\n",
    "                #tmp = [item for item in tmp if 'entity' in item.keys()]\n",
    "                return {'model_output':str(tmp)}\n",
    "            \n",
    "            else: \n",
    "                # print('NOT CLEANED: ', model_output, '\\n\\n')\n",
    "                return {'model_output':'[{\"entity\":\"\"}]'}\n",
    "        \n",
    "\n",
    "        if not latest_version:\n",
    "            if has_unopen_square_brackets(model_output):\n",
    "                last_bracket_index = model_output.rfind('],') # keep the closed list\n",
    "                model_output = '[' + model_output[:last_bracket_index+1] \n",
    "                return {'model_output':model_output} \n",
    "            \n",
    "            tmp = re.findall(r'\\[\\{(.+?)\\}\\]', model_output)\n",
    "            if len(tmp) != 0:\n",
    "                tmp = '[{' + tmp[0] + '}]'\n",
    "                if self._assess_model_output(tmp):\n",
    "                    return {'model_output':tmp}\n",
    "                \n",
    "            if has_unclosed_square_brackets(model_output):\n",
    "                last_bracket_index = model_output.rfind('},') # find the last complete entity\n",
    "                model_output = model_output[:last_bracket_index+1] + ']' \n",
    "                return {'model_output':model_output} \n",
    "\n",
    "\n",
    "            if model_output.strip()[0] == '{':\n",
    "                tmp = '[' + model_output + ']'\n",
    "                if self._assess_model_output(tmp):\n",
    "                    return {'model_output':tmp}\n",
    "                else:\n",
    "                    last_bracket_index = model_output.rfind('},') # find the last complete entity\n",
    "                    model_output = '[' + model_output[:last_bracket_index+1] + ']'\n",
    "                    return {'model_output':model_output}\n",
    "                \n",
    "            if model_output.strip().startswith('[['):\n",
    "                tmp = model_output[1:]\n",
    "                if self._assess_model_output(tmp):\n",
    "                    return {'model_output':tmp}\n",
    "\n",
    "            # print('THIS IS A BROKEN ROW: ', model_output)\n",
    "\n",
    "            return {'model_output':model_output}\n",
    "    \n",
    "    def _extract_text_between_curl_brackets(self, model_output: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the text between the curl brackets of the model output, as enitties are usually outputted in this format: {\"entity\": \"value\"}\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the example from the dataset\n",
    "\n",
    "        \"\"\"\n",
    "        text_between_curl_brackets = re.findall(r'\\{(.+?)\\}', model_output)\n",
    "        cleaned_output = ['{'+ el +'}' for el in text_between_curl_brackets]\n",
    "        cleaned_output = '[' + ', '.join(cleaned_output) + ']'\n",
    "        return cleaned_output\n",
    "    \n",
    "\n",
    "    def _clean_text_between_curl_brackets(self, text_between_curl_brackets: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean the text between the curl brackets of the model output, as entities are usually outputted in this format: {\"key\": \"value\"}\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the example from the dataset\n",
    "\n",
    "        \"\"\"\n",
    "        text_between_curl_brackets = re.sub(r'\",(.+?)}', r'\"}', text_between_curl_brackets)\n",
    "        return(text_between_curl_brackets)\n",
    "\n",
    "        # list_of_dicts = json.loads(text_between_curl_brackets)\n",
    "        # list_of_dicts_str = [str(item) for item in list_of_dicts]\n",
    "        # out = []\n",
    "        # print('list_of_dicts: ', list_of_dicts_str)\n",
    "        # if ' '.join(list_of_dicts_str).count(':') > len(list_of_dicts):\n",
    "        #     for item in list_of_dicts:\n",
    "        #         if len(item) > 1:\n",
    "        #             item = self._keep_only_one_keyVal_from_dict(item)\n",
    "        #         out.append(item)\n",
    "        #return str(out)\n",
    "\n",
    "    # def _keep_only_one_keyVal_from_dict(dict: dict) -> dict:\n",
    "    #     \"\"\"\n",
    "    #     Keep only one key-value pair from a dictionary. This is useful when the model outputs a dictionary with more than one key-value pair.\n",
    "\n",
    "    #     Args:\n",
    "    #     dict (dict): the dictionary to be cleaned\n",
    "\n",
    "    #     return:\n",
    "    #     dict: the cleaned dictionary\n",
    "    #     \"\"\"\n",
    "    #     k_first = \"entity\"\n",
    "    #     if k_first not in dict.keys():\n",
    "    #         k_first = list(dict.keys())[0]\n",
    "    #     return {k_first:dict[k_first]}\n",
    "\n",
    "    \n",
    "    def apply_cleaning(self, data, wrong_keys_to_entity) -> None:\n",
    "        \"\"\"\n",
    "        Apply the cleaning to the model output and return the cleaned response in a new cloumn called 'model_output\n",
    "\n",
    "        Args:\n",
    "        model_output (str): the model output as it is returned by the model. The processing of the output is done in the function\n",
    "        wrong_keys_to_entity (bool): if True, the function also extracts the dictionaries with keys different from 'entity', converting the keys into 'entity'. If not, all keys that are not 'entity' are dropped\n",
    "\n",
    "        return:\n",
    "        str: the model response, i.e. the model output without the instruction\n",
    "        \"\"\"\n",
    "        data = data.map(lambda x: self._clean_ground_truth(x), remove_columns=['ground_truth'])\n",
    "        data = data.map(lambda x: self._clean_model_output(x, wrong_keys_to_entity)) \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from config import postprocessing\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "file ='data/mistral/4bit/maxNewTokensFactor8_nShotsInference4_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv'\n",
    "eval_data = Dataset.from_csv(file) \n",
    "#display(eval_data.to_pandas().head(3))\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = True\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)#.select(range(138,139))\n",
    "\n",
    "# evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "# evaluator.generate_evaluation_table(similar_is_equal=similar_is_equal, similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "#                                     words_level=False, similarity_types=['case', 'stop_words', 'subset', 'superset', 'leveshtein'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference4_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file ='data/mistral/4bit/maxNewTokensFactor8_nShotsInference4_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv'\n",
    "evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "input_data_path = postprocessing.input_data_dir_path\n",
    "output_data_path = postprocessing.output_data_path\n",
    "words_level = postprocessing.words_level\n",
    "similarity_types=['case', 'stop_words', 'subset', 'superset', 'leveshtein']\n",
    "\n",
    "\n",
    "print(\"FILE: \" , file)\n",
    "eval_data = Dataset.from_csv(file) \n",
    "output_cleaner = OutputCleaner()\n",
    "cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=False)\n",
    "for similar_is_equal_threshold in [85, 100]:\n",
    "    evaluator = Evaluator(data=cleaned_data, offset=False, output_cleaner=output_cleaner)\n",
    "    evaluator.generate_evaluation_table(similar_is_equal=True, \n",
    "                                        similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                        words_level=words_level, \n",
    "                                        similarity_types=similarity_types)\n",
    "    evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': True, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_data_path:str, \n",
    "             output_file_path:str, \n",
    "             words_level:bool,\n",
    "             similar_is_equal_threshold_list,\n",
    "             similarity_types:list = ['case', 'stop_words', 'subset', 'superset'],\n",
    "             wrong_keys_to_entity=False,\n",
    "             offset=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test data\n",
    "    \n",
    "    Args:\n",
    "    input_data_path: The path to the test data directory\n",
    "    output_data_path: The path to the output file\n",
    "    \n",
    "    Returns:\n",
    "    evaluation_results: The evaluation results\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(input_data_path + '/*.csv') \n",
    "    evaluation_results = pd.DataFrame(columns=['file', 'similar_is_equal', 'similar_is_equal_threshold', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "    for file in csv_files:\n",
    "        print(\"FILE: \" , file)\n",
    "        eval_data = Dataset.from_csv(file) \n",
    "        output_cleaner = OutputCleaner()\n",
    "        cleaned_data = output_cleaner.apply_cleaning(eval_data, wrong_keys_to_entity=wrong_keys_to_entity)\n",
    "        for similar_is_equal_threshold in similar_is_equal_threshold_list:\n",
    "            evaluator = Evaluator(data=cleaned_data, offset=offset, output_cleaner=output_cleaner)\n",
    "            evaluator.generate_evaluation_table(similar_is_equal=True, \n",
    "                                                similar_is_equal_threshold=similar_is_equal_threshold,\n",
    "                                                words_level=words_level, \n",
    "                                                similarity_types=similarity_types)\n",
    "            evaluation_results.loc[len(evaluation_results)] = {'file': file, 'similar_is_equal': True, 'similar_is_equal_threshold': similar_is_equal_threshold, 'f1_score': evaluator.evaluation_table['f1'], 'precision': evaluator.evaluation_table['precision'], 'recall': evaluator.evaluation_table['recall']}\n",
    "                \n",
    "    evaluation_results.to_csv(output_file_path, index=False)\n",
    "    return evaluation_results\n",
    "\n",
    "if True:\n",
    "    input_data_path = 'data/mistral/4bit'\n",
    "    output_data_path = 'data/example.csv'\n",
    "    words_level = postprocessing.words_level\n",
    "    evaluate(input_data_path, output_data_path, words_level, \n",
    "             similar_is_equal_threshold_list = postprocessing.similar_is_equal_threshold_list,\n",
    "             similarity_types = ['case', 'stop_words', 'subset', 'superset'],\n",
    "             wrong_keys_to_entity = False,\n",
    "             offset = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference4_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:447: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:447: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference4_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_8_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.01_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n",
      "/home/pferrazzi/mistral_finetuning/utils/evaluator.py:445: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = summary['TP'] / (summary['TP'] + summary['FP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference4_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.01_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_32_32_0.05_8_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_4_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor4_nShotsInference2_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_64_32_0.05_2_0.0002.csv\n",
      "FILE:  data/mistral/4bit/maxNewTokensFactor8_nShotsInference4_Mistral-7B-Instruct-v0.2_adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002.csv\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 114 (char 113)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/mistral/4bit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/evaluation_results/mistral_4bit.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m         \u001b[49m\u001b[43msimilar_is_equal_threshold_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m         \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop_words\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuperset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m         \u001b[49m\u001b[43mwrong_keys_to_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m         \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mistral_finetuning/evaluation.py:37\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(input_data_path, output_file_path, words_level, similar_is_equal_threshold_list, similarity_types, wrong_keys_to_entity, offset)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m similar_is_equal_threshold \u001b[38;5;129;01min\u001b[39;00m similar_is_equal_threshold_list:\n\u001b[1;32m     36\u001b[0m         evaluator \u001b[38;5;241m=\u001b[39m Evaluator(data\u001b[38;5;241m=\u001b[39mcleaned_data, offset\u001b[38;5;241m=\u001b[39moffset, output_cleaner\u001b[38;5;241m=\u001b[39moutput_cleaner)\n\u001b[0;32m---> 37\u001b[0m         \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_evaluation_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilar_is_equal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwords_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilarity_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m         evaluation_results\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(evaluation_results)] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m: file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilar_is_equal\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilar_is_equal_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m: similar_is_equal_threshold, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m: evaluator\u001b[38;5;241m.\u001b[39mevaluation_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: evaluator\u001b[38;5;241m.\u001b[39mevaluation_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: evaluator\u001b[38;5;241m.\u001b[39mevaluation_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     43\u001b[0m evaluation_results\u001b[38;5;241m.\u001b[39mto_csv(output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:441\u001b[0m, in \u001b[0;36mEvaluator.generate_evaluation_table\u001b[0;34m(self, similar_is_equal, similar_is_equal_threshold, words_level, similarity_types)\u001b[0m\n\u001b[1;32m    439\u001b[0m metrics_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m--> 441\u001b[0m     metrics_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_TP_FP_FN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mground_truth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilar_is_equal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilar_is_equal_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_level\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    443\u001b[0m metrics_dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metrics_list, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    444\u001b[0m summary \u001b[38;5;241m=\u001b[39m metrics_dataframe\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:384\u001b[0m, in \u001b[0;36mEvaluator._extract_TP_FP_FN\u001b[0;34m(self, model_response, ground_truth, similar_is_equal, similar_is_equal_threshold, similarity_types, words_level)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03mCompute the F1 score, the precision and the recall between the model output and the ground truth\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# print('ORIGINAL model_response: ', model_response)\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json(ground_truth)\n\u001b[1;32m    386\u001b[0m model_response \u001b[38;5;241m=\u001b[39m model_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:67\u001b[0m, in \u001b[0;36mEvaluator._parse_json\u001b[0;34m(self, model_response, drop_duplicates)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_response: \u001b[38;5;28mstr\u001b[39m, drop_duplicates: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    Parse the model output to extract the entities and their offsets if present.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    drop_duplicates (bool): if True, drop the duplicates in the model response\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     good_format, model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assess_model_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_response \u001b[38;5;241m==\u001b[39m []:\n\u001b[1;32m     69\u001b[0m         model_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/evaluator.py:37\u001b[0m, in \u001b[0;36mEvaluator._assess_model_output\u001b[0;34m(self, model_response)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error\u001b[38;5;241m.\u001b[39mmsg\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpecting property name enclosed in double quotes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     36\u001b[0m     model_response \u001b[38;5;241m=\u001b[39m model_response\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mty\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mty\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# print('out ', out)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 114 (char 113)"
     ]
    }
   ],
   "source": [
    "from evaluation import evaluate\n",
    "\n",
    "\n",
    "res = evaluate('data/mistral/4bit',\n",
    "         'data/evaluation_results/mistral_4bit.csv',\n",
    "         words_level=True,\n",
    "         similar_is_equal_threshold_list=[80, 100],\n",
    "         similarity_types=['case', 'stop_words', 'subset', 'superset'],\n",
    "         wrong_keys_to_entity=False,\n",
    "         offset=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
