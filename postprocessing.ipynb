{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config.finetuning import config\n",
    "from config import postprocessing_params_mistral as postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from log import mistral_8bits as models_params\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = []#postprocessing.max_new_tokens_factor_list\n",
    "n_shots_inference_list = [2]#postprocessing.n_shots_inference_list\n",
    "layer = models_params.TRAIN_LAYER\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(model_checkpoint=models_params.BASE_MODEL_CHECKPOINT, \n",
    "                                tokenizer = models_params.BASE_MODEL_CHECKPOINT)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset,\n",
    "                                                 simplest_prompt=models_params.simplest_prompt)\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "load_in_8bit = not models_params.load_in_4bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit = models_params.load_in_4bit[0],\n",
    "            load_in_8bit = load_in_8bit,\n",
    "            bnb_4bit_use_double_quant = models_params.bnb_4bit_use_double_quant,\n",
    "            bnb_4bit_quant_type = models_params.bnb_4bit_quant_type[0],\n",
    "            bnb_4bit_compute_dtype = models_params.bnb_4bit_compute_dtype[0],\n",
    "            llm_int8_threshold = models_params.llm_int8_threshold[0],\n",
    "            llm_int8_has_fp16_weight = models_params.llm_int8_has_fp16_weight,\n",
    "            llm_int8_skip_modules = models_params.llm_int8_skip_modules\n",
    "            )\n",
    "\n",
    "\n",
    "adapters_list = generate_ft_adapters_list(\"mistral_8bits\", simplest_prompt=models_params.simplest_prompt)\n",
    "adapters_list = [adapters_list[0]]\n",
    "for max_new_tokens_factor in max_new_tokens_factor_list:\n",
    "    for n_shots_inference in n_shots_inference_list:\n",
    "        for adapters in tqdm(adapters_list, desc=\"adapters_list\"):\n",
    "            print(\"PROCESSING:\", adapters)\n",
    "            base_model = AutoModelForCausalLM.from_pretrained(\n",
    "                models_params.BASE_MODEL_CHECKPOINT, low_cpu_mem_usage=True,\n",
    "                quantization_config = bnb_config,\n",
    "                return_dict=True,  \n",
    "                #torch_dtype=torch.float16,\n",
    "                device_map= \"auto\")\n",
    "            merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "            tokenizer = AutoTokenizer.from_pretrained(models_params.BASE_MODEL_CHECKPOINT, add_eos_token=True)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            tokenizer.padding_side = \"left\"\n",
    "\n",
    "            # merged_model, tokenizer = load_mergedModel_tokenizer(adapters, base_model)\n",
    "            postprocessor = TestDataProcessor(test_data=val_data, \n",
    "                                              preprocessor=preprocessor, \n",
    "                                              n_shots_inference=n_shots_inference, \n",
    "                                              language=language, \n",
    "                                              tokenizer=tokenizer)\n",
    "            postprocessor.add_inference_prompt_column(simplest_prompt=models_params.simplest_prompt)\n",
    "            postprocessor.add_ground_truth_column()\n",
    "            try:\n",
    "                postprocessor.add_responses_column(model=merged_model, \n",
    "                                                tokenizer=tokenizer, \n",
    "                                                batch_size=36, \n",
    "                                                max_new_tokens_factor=max_new_tokens_factor)\n",
    "                postprocessor.test_data.to_csv(f\"{postprocessing.save_directory}maxNewTokensFactor{max_new_tokens_factor}_nShotsInference{n_shots_inference}_{adapters.split('/')[1]}.csv\", index=False)\n",
    "            except Exception as e:\n",
    "                print(\"ERROR IN PROCESSING: \", Exception, adapters)\n",
    "            del merged_model\n",
    "            del base_model\n",
    "            del tokenizer\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1520/1520 [00:00<00:00, 3633.82 examples/s]\n",
      "Map: 100%|██████████| 170/170 [00:00<00:00, 6718.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config.finetuning import config\n",
    "from utils.load_merged_model_tokenizer import load_mergedModel_tokenizer\n",
    "from config import postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from log import enlayer1_3epochs_4bits__ft_params as models_params\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = postprocessing.max_new_tokens_factor_list\n",
    "n_shots_inference_list = postprocessing.n_shots_inference_list\n",
    "layer = models_params.TRAIN_LAYER\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(config.BASE_MODEL_CHECKPOINT, config.BASE_MODEL_CHECKPOINT)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset, instruction_on_response_format='Return the result in a json format: [{\"entity\":\"entity_name\"}].')\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type=\"nf4\",\n",
    "#             bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=False,\n",
    "            load_in_8bit=True,\n",
    "            #bnb_4bit_use_double_quant=True,\n",
    "            #bnb_4bit_quant_type=\"nf4\",\n",
    "            #bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            llm_int8_threshold= 6.0,\n",
    "            llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "\n",
    "\n",
    "adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_4bits__ft_params\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config.finetuning_llama2 import config\n",
    "from utils.load_merged_model_tokenizer import load_mergedModel_tokenizer\n",
    "from config import postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from log import enlayer1_3epochs_8bits__ft_params_llama as models_params\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "LLAMA_TOKEN = dotenv_values(\".env.base\")['LLAMA_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = postprocessing.max_new_tokens_factor_list\n",
    "n_shots_inference_list = postprocessing.n_shots_inference_list\n",
    "layer = models_params.TRAIN_LAYER\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor()\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset)\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=False,\n",
    "            load_in_8bit=True,\n",
    "            #bnb_4bit_use_double_quant=True,\n",
    "            #bnb_4bit_quant_type=\"nf4\",\n",
    "            #bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            llm_int8_threshold= 6.0,\n",
    "            load_in_8bit_fp32_cpu_offload=True,\n",
    "            llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "\n",
    "\n",
    "adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_8bits__ft_params_llama\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapters = \"ferrazzipietro/Llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_4_0.0002\"\n",
    "merged_model, tokenizer = load_mergedModel_tokenizer(adapters, \"meta-llama/Llama-2-7b-chat-hf\", llama_key=LLAMA_TOKEN)\n",
    "\n",
    "postprocessor = TestDataProcessor(test_data=val_data.select(range(48)), preprocessor=preprocessor, n_shots_inference=2, language='en', tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column()\n",
    "postprocessor.add_ground_truth_column()\n",
    "postprocessor.add_responses_column(model=merged_model, tokenizer=tokenizer, batch_size=12, max_new_tokens_factor=5)\n",
    "postprocessor.test_data.to_csv(f\"data/test_data_processed/en_nShots{2}_maxNewTokensFactor{5}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.60ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "183295"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor.test_data['model_responses']\n",
    "postprocessor.test_data.to_csv(f\"data/test_data_processed/en_nShots{2}_maxNewTokensFactor{5}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for max_new_tokens_factor in max_new_tokens_factor_list:\n",
    "    for n_shots_inference in n_shots_inference_list:\n",
    "        for adapters in tqdm(adapters_list, desc=\"adapters_list\"):\n",
    "            print(\"PROCESSING:\", adapters)\n",
    "            base_model = AutoModelForCausalLM.from_pretrained(\n",
    "                models_params.BASE_MODEL_CHECKPOINT, low_cpu_mem_usage=True,\n",
    "                quantization_config = bnb_config,\n",
    "                return_dict=True,  load_in_4bit=True, \n",
    "                token = LLAMA_TOKEN,\n",
    "                #torch_dtype=torch.float16,\n",
    "                device_map= \"auto\")\n",
    "            merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "            tokenizer = AutoTokenizer.from_pretrained(models_params.BASE_MODEL_CHECKPOINT, add_eos_token=True, token=LLAMA_TOKEN)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            tokenizer.padding_side = \"left\"\n",
    "\n",
    "            # merged_model, tokenizer = load_mergedModel_tokenizer(adapters, base_model)\n",
    "            postprocessor = TestDataProcessor(test_data=val_data, \n",
    "                                              preprocessor=preprocessor, \n",
    "                                              n_shots_inference=n_shots_inference, \n",
    "                                              language=language, \n",
    "                                              tokenizer=tokenizer)\n",
    "            postprocessor.add_inference_prompt_column()\n",
    "            postprocessor.add_ground_truth_column()\n",
    "            # try:\n",
    "            postprocessor.add_responses_column(model=merged_model, \n",
    "                                            tokenizer=tokenizer, \n",
    "                                            batch_size=12, \n",
    "                                            max_new_tokens_factor=max_new_tokens_factor)\n",
    "            postprocessor.test_data.to_csv(f\"data/test_data_processed/maxNewTokensFactor{max_new_tokens_factor}_nShotsInference{n_shots_inference}_{adapters.split('/')[1]}.csv\", index=False)\n",
    "            # except Exception as e:\n",
    "            #     print(\"ERROR IN PROCESSING: \", Exception, adapters)\n",
    "\n",
    "            del merged_model\n",
    "            del base_model\n",
    "            del tokenizer\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE RUN MISTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it]\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 902.03 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 984.96 examples/s]\n",
      "generating responses:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.>>> [/INST]', '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST]', '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases.>>> [/INST]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses:  50%|█████     | 3/6 [00:27<00:27,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<The patient underwent right parotidectomy, and histopathologic examination confirmed ACC.>>> [/INST]', '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide.>>> [/INST]', '<s>[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \\n[INST] Extract the entities contained in the text. Extract only entities contained in the text.\\nReturn the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago.>>> [/INST]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses: 100%|██████████| 6/6 [00:53<00:00,  8.95s/it]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 912.27 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 819.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL OUTPUT:  [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.>>> [/INST] 1-month-onset diabetes mellitus, hypertension, dyslipidemia, 46-year-old man, diabetes mellitus, hypertension, dyslipidemia \n",
      "-18-27-23-18 \n",
      "-6\n",
      "-null\n",
      "ORIGINAL MODEL OUTPUT:  [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>> [/INST]{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"indicated\"}]\n",
      "ORIGINAL MODEL OUTPUT:  [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases.>>> [/INST] \t- \"findings\"\n",
      "\t- \"pointed\"\n",
      "\t- \"malignancy\"\n",
      "\t- \"metastases\"\n",
      "\t- \"parotid malignancy\"\n",
      "\t- \"liver metastases\"\n",
      "\t- \"a primary right parotid malignancy with liver metastases\"\n",
      "ORIGINAL MODEL OUTPUT:  [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<The patient underwent right parotidectomy, and histopathologic examination confirmed ACC.>>> [/INST] \t- \"parotidectomy\"\n",
      "\t- \"examination\"\n",
      "\t- \"ACC\"\n",
      "\t- \"The patient\" \n",
      "\t- \"disease\" \n",
      "\t-\"confirmed\"\t- \"ACC\" \n",
      "\t- \"patient\" \n",
      "\t- \"disease\"\n",
      "ORIGINAL MODEL OUTPUT:  [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide.>>> [/INST]\n",
      "ORIGINAL MODEL OUTPUT:  [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \n",
      "[INST] Extract the entities contained in the text. Extract only entities contained in the text.\n",
      "Return the result in a json format: [{\"entity\":\"entity_name\"}]. Text: <<A 50-years-old woman, hypertensive, hospitalized for a large cervical mass appeared 30 years ago.>>> [/INST] \t-\tA 50-years-old woman, \n",
      "\t-\thypertensive, \n",
      "\t-\thospitalized, \n",
      "\t-\tfor a large cervical mass, \n",
      "\t-\tappeared 30 years ago.\t \n",
      "\t \t \n",
      "-\ta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config.finetuning import config\n",
    "from utils.load_merged_model_tokenizer import load_mergedModel_tokenizer\n",
    "from config import postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from log import enlayer1_3epochs_4bits__ft_params as models_params\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = postprocessing.max_new_tokens_factor_list\n",
    "n_shots_inference_list = postprocessing.n_shots_inference_list\n",
    "layer = models_params.TRAIN_LAYER\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(config.BASE_MODEL_CHECKPOINT, config.BASE_MODEL_CHECKPOINT)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset, instruction_on_response_format='Return the result in a json format: [{\"entity\":\"entity_name\"}].')\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=False,\n",
    "            #load_in_8bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            # llm_int8_threshold= 6.0,\n",
    "            # llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\", low_cpu_mem_usage=True,\n",
    "    quantization_config = bnb_config,\n",
    "    return_dict=True,\n",
    "    device_map= 'auto')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "adapters = \"ferrazzipietro/Mistral-7B-Instruct-v0.2_adapters_en.layer1_8_torch.bfloat16_32_32_0.05_2_0.0002\"\n",
    "merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", add_eos_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "postprocessor = TestDataProcessor(test_data=val_data.select(range(6)), preprocessor=preprocessor, n_shots_inference=2, language='en', tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column()\n",
    "postprocessor.add_ground_truth_column()\n",
    "postprocessor.add_responses_column(model=merged_model, tokenizer=tokenizer, batch_size=3, max_new_tokens_factor=5)\n",
    "\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = False\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(postprocessor.test_data, wrong_keys_to_entity=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE RUN MISTAL NO QUANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config.finetuning import config\n",
    "from utils.load_merged_model_tokenizer import load_mergedModel_tokenizer\n",
    "from config import postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from log import enlayer1_3epochs_4bits__ft_params as models_params\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = postprocessing.max_new_tokens_factor_list\n",
    "n_shots_inference_list = postprocessing.n_shots_inference_list\n",
    "layer = models_params.TRAIN_LAYER\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(config.BASE_MODEL_CHECKPOINT, config.BASE_MODEL_CHECKPOINT)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset, instruction_on_response_format='Return the result in a json format: [{\"entity\":\"entity_name\"}].')\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=False,\n",
    "            #load_in_8bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            # llm_int8_threshold= 6.0,\n",
    "            # llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\", low_cpu_mem_usage=True,\n",
    "    quantization_config = bnb_config,\n",
    "    return_dict=True,\n",
    "    device_map= 'auto')\n",
    "\n",
    "\n",
    "adapters = 'ferrazzipietro/Mistral-7B-Instruct-v0.2__adapters_en.layer1_4_torch.bfloat16_16_32_0.05_2_0.0002'\n",
    "merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", add_eos_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "postprocessor = TestDataProcessor(test_data=val_data.select(range(6)), preprocessor=preprocessor, n_shots_inference=2, language='en', tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column()\n",
    "postprocessor.add_ground_truth_column()\n",
    "postprocessor.add_responses_column(model=merged_model, tokenizer=tokenizer, batch_size=3, max_new_tokens_factor=5)\n",
    "\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = False\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(postprocessor.test_data, wrong_keys_to_entity=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE RUN QWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Qwen2TokenizerFast' object has no attribute 'padding_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(BASE_MODEL_CHECKPOINT, add_eos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding_token: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_token\u001b[49m)\n\u001b[1;32m     51\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m postprocessor \u001b[38;5;241m=\u001b[39m TestDataProcessor(test_data\u001b[38;5;241m=\u001b[39mval_data\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m)), preprocessor\u001b[38;5;241m=\u001b[39mpreprocessor, n_shots_inference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Qwen2TokenizerFast' object has no attribute 'padding_token'"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "from peft import PeftModel\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = [6]\n",
    "n_shots_inference_list = [0]\n",
    "layer = 'en.layer1'\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "BASE_MODEL_CHECKPOINT = 'Qwen/Qwen1.5-7B-Chat'\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(BASE_MODEL_CHECKPOINT, BASE_MODEL_CHECKPOINT)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset, instruction_on_response_format='Return the result in a json format: [{\"entity\":\"entity_name\"}].')\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            #load_in_8bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            # llm_int8_threshold= 6.0,\n",
    "            # llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_CHECKPOINT, low_cpu_mem_usage=True,\n",
    "    quantization_config = bnb_config,\n",
    "    return_dict=True,\n",
    "    device_map= 'auto',\n",
    "    cache_dir='/data/disk1/share/pferrazzi/.cache')\n",
    "\n",
    "\n",
    "adapters = 'ferrazzipietro/qwen1.5-7b-chat__adapters_en.layer1_8_torch.bfloat16_16_32_0.01_2_0.0002'\n",
    "merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_CHECKPOINT, add_eos_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_token:  <|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6/6 [00:00<00:00, 970.79 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 1093.31 examples/s]\n",
      "generating responses: 100%|██████████| 6/6 [00:42<00:00,  7.15s/it]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 824.60 examples/s]\n",
      "Map: 100%|██████████| 6/6 [00:00<00:00, 948.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "print('padding_token: ', tokenizer.pad_token)\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "postprocessor = TestDataProcessor(test_data=val_data.select(range(6)), preprocessor=preprocessor, n_shots_inference=2, language='en', tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column(simplest_prompt=False)\n",
    "postprocessor.add_ground_truth_column()\n",
    "postprocessor.add_responses_column(model=merged_model, tokenizer=tokenizer, batch_size=3, max_new_tokens_factor=5)\n",
    "\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = False\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(postprocessor.test_data, wrong_keys_to_entity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.',\n",
       " 'entities': [{'id': '1614',\n",
       "   'offsets': [23, 35],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'hypertension',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1629',\n",
       "   'offsets': [40, 52],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'dyslipidemia',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1644',\n",
       "   'offsets': [53, 62],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'diagnosed',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1659',\n",
       "   'offsets': [110, 118],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'mellitus',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1674',\n",
       "   'offsets': [149, 157],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'referred',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1689',\n",
       "   'offsets': [186, 197],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'hypokalemia',\n",
       "   'type': 'EVENT'},\n",
       "  {'id': '1996',\n",
       "   'offsets': [91, 118],\n",
       "   'role': '',\n",
       "   'semantic_type_id': 'C0743128',\n",
       "   'text': 'new-onset diabetes mellitus',\n",
       "   'type': 'CLINENTITY'},\n",
       "  {'id': '2076',\n",
       "   'offsets': [0, 17],\n",
       "   'role': 'PATIENT',\n",
       "   'semantic_type_id': '',\n",
       "   'text': 'A 46-year-old man',\n",
       "   'type': 'ACTOR'},\n",
       "  {'id': '2090',\n",
       "   'offsets': [63, 71],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': '4-months',\n",
       "   'type': 'TIMEX3'},\n",
       "  {'id': '2099',\n",
       "   'offsets': [128, 135],\n",
       "   'role': '',\n",
       "   'semantic_type_id': '',\n",
       "   'text': '1-month',\n",
       "   'type': 'TIMEX3'}],\n",
       " 'original_text': 'A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia. Hormonal study and dynamic biochemical tests performed indicated ECS. Imaging and cytological findings pointed toward a likely primary right parotid malignancy with liver metastases. Somatostatin receptor scintigraphy has shown an increased uptake in the parotid gland and mild expression in liver metastasis. The patient underwent right parotidectomy, and histopathologic examination confirmed ACC. Meanwhile, hypercortisolism was managed with metyrapone, ketoconazole, and lanreotide. Despite chemotherapy onset, a rapid disease progression and clinical course deterioration was observed.\\r\\n',\n",
       " 'original_id': 'EN101783',\n",
       " 'prompt': '<|im_start|>user Return the result in a json format: [{\"entity\":\"entity_name\"}]. <<A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.>>> <|im_end|><|im_start|>assistant[{\"entity\": \"hypertension\"}, {\"entity\": \"dyslipidemia\"}, {\"entity\": \"diagnosed\"}, {\"entity\": \"mellitus\"}, {\"entity\": \"referred\"}, {\"entity\": \"hypokalemia\"}, {\"entity\": \"new-onset diabetes mellitus\"}, {\"entity\": \"A 46-year-old man\"}, {\"entity\": \"4-months\"}, {\"entity\": \"1-month\"}] <|im_end|>',\n",
       " 'inference_prompt': '<|im_start|>user Return the result in a json format: [{\"entity\":\"entity_name\"}]. <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> <|im_end|><|im_start|>assistant [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] <|im_end|>\\n<|im_start|>user Return the result in a json format: [{\"entity\":\"entity_name\"}]. <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> <|im_end|><|im_start|>assistant [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] <|im_end|>\\n<|im_start|>user Return the result in a json format: [{\"entity\":\"entity_name\"}]. <<A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.>>> <|im_end|><|im_start|>assistant',\n",
       " 'ground_truth': '[{\"entity\": \"hypertension\"}, {\"entity\": \"dyslipidemia\"}, {\"entity\": \"diagnosed\"}, {\"entity\": \"mellitus\"}, {\"entity\": \"referred\"}, {\"entity\": \"hypokalemia\"}, {\"entity\": \"new-onset diabetes mellitus\"}, {\"entity\": \"A 46-year-old man\"}, {\"entity\": \"4-months\"}, {\"entity\": \"1-month\"}] ',\n",
       " 'model_responses': '[{\"entity\": \"hypertension\"}, {\"entity\": \"dyslipidemia\"}, {\"entity\": \"diabetes\"}, {\"entity\": \"hypokalemia\"}, {\"entity\": \"A 46-year-old man\"}] <|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|>',\n",
       " 'model_output': \"[{'entity': 'hypertension'}, {'entity': 'dyslipidemia'}, {'entity': 'diabetes'}, {'entity': 'hypokalemia'}, {'entity': 'A 46-year-old man'}]\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMAM one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.92s/it]\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_token:  None\n",
      "padding_token:  </s>\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config.finetuning import config\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from utils.output_cleaner import OutputCleaner\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "LLAMA_TOKEN = dotenv_values(\".env.base\")['LLAMA_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = [6]\n",
    "n_shots_inference_list = [0]\n",
    "layer = 'en.layer1'\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(config.BASE_MODEL_CHECKPOINT, config.BASE_MODEL_CHECKPOINT)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset, instruction_on_response_format='Return the result in a json format: [{\"entity\":\"entity_name\"}].')\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=False,\n",
    "            #load_in_8bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            # llm_int8_threshold= 6.0,\n",
    "            # llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\", low_cpu_mem_usage=True,\n",
    "    quantization_config = bnb_config,\n",
    "    return_dict=True,\n",
    "    device_map= 'auto',\n",
    "    token = LLAMA_TOKEN,\n",
    "    cache_dir='/data/disk1/share/pferrazzi/.cache')\n",
    "\n",
    "\n",
    "adapters = 'ferrazzipietro/Llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_2_0.0002'\n",
    "merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", add_eos_token=True, \n",
    "    token = LLAMA_TOKEN,\n",
    "    cache_dir='/data/disk1/share/pferrazzi/.cache')\n",
    "print('padding_token: ', tokenizer.pad_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print('padding_token: ', tokenizer.pad_token)\n",
    "\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "postprocessor = TestDataProcessor(test_data=val_data.select(range(6)), preprocessor=preprocessor, n_shots_inference=2, language='en', tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column()\n",
    "postprocessor.add_ground_truth_column()\n",
    "postprocessor.add_responses_column(model=merged_model, tokenizer=tokenizer, batch_size=3, max_new_tokens_factor=5)\n",
    "\n",
    "output_cleaner = OutputCleaner()\n",
    "similar_is_equal = False\n",
    "similar_is_equal_threshold = 100\n",
    "cleaned_data = output_cleaner.apply_cleaning(postprocessor.test_data, wrong_keys_to_entity=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLAMA 7B 8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config import postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from log import enlayer1_3epochs_8bits__ft_params_llama as models_params\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "\n",
    "max_new_tokens_factor_list = postprocessing.max_new_tokens_factor_list\n",
    "n_shots_inference_list = postprocessing.n_shots_inference_list\n",
    "layer = models_params.TRAIN_LAYER\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(model_checkpoint=models_params.BASE_MODEL_CHECKPOINT, \n",
    "                                tokenizer = models_params.BASE_MODEL_CHECKPOINT)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset,models_params.instruction_on_response_format)\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=False,\n",
    "            load_in_8bit=True,\n",
    "            #bnb_4bit_use_double_quant=True,\n",
    "            #bnb_4bit_quant_type=\"nf4\",\n",
    "            #bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            llm_int8_threshold= 6.0,\n",
    "            llm_int8_has_fp16_weight = False,\n",
    "            llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "\n",
    "\n",
    "adapters_list = generate_ft_adapters_list(\"enlayer1_3epochs_8bits__ft_params_llama\")\n",
    "\n",
    "\n",
    "max_new_tokens_factor_list = [2]\n",
    "n_shots_inference_list = [0]\n",
    "val_data = val_data.select(range(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adapters_list:   0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING: ferrazzipietro/Llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_2_0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n",
      "Map: 100%|██████████| 12/12 [00:00<00:00, 1604.91 examples/s]\n",
      "Map: 100%|██████████| 12/12 [00:00<00:00, 1081.22 examples/s]\n",
      "generating responses: 100%|██████████| 12/12 [01:10<00:00,  5.89s/it]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 97.74ba/s]\n",
      "adapters_list:   3%|▎         | 1/36 [01:16<44:25, 76.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING: ferrazzipietro/Llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_2_0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]\n",
      "generating responses:   0%|          | 0/12 [00:19<?, ?it/s]\n",
      "adapters_list:   3%|▎         | 1/36 [01:39<58:18, 99.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m postprocessor\u001b[38;5;241m.\u001b[39madd_ground_truth_column()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mpostprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_responses_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmax_new_tokens_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m postprocessor\u001b[38;5;241m.\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/test_data_processed/maxNewTokensFactor\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_new_tokens_factor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nShotsInference\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_shots_inference\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00madapters\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#     print(\"ERROR IN PROCESSING: \", Exception, adapters)\u001b[39;00m\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/test_data_processor.py:176\u001b[0m, in \u001b[0;36mTestDataProcessor.add_responses_column\u001b[0;34m(self, model, tokenizer, batch_size, max_new_tokens_factor)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(indexes[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    175\u001b[0m     indici \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(idx, indexes[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m--> 176\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_model_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindici\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     responses_col\u001b[38;5;241m.\u001b[39mextend(tmp)\n\u001b[1;32m    178\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(batch_size)\n",
      "File \u001b[0;32m~/mistral_finetuning/utils/test_data_processor.py:152\u001b[0m, in \u001b[0;36mTestDataProcessor._generate_model_response\u001b[0;34m(self, examples, model, tokenizer, max_new_tokens_factor)\u001b[0m\n\u001b[1;32m    150\u001b[0m encodeds \u001b[38;5;241m=\u001b[39m tokenizer(prompts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    151\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m encodeds\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 152\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# max_new_tokens=max_new_tokens,\u001b[39;00m\n\u001b[1;32m    153\u001b[0m decoded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids)\n\u001b[1;32m    154\u001b[0m decoded \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_postprocess_model_output(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m decoded]\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/peft/peft_model.py:1060\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prepare_inputs_for_generation\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/transformers/generation/utils.py:1592\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1585\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1586\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1587\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1589\u001b[0m     )\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1610\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1611\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1616\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1617\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/transformers/generation/utils.py:2696\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2695\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2696\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2704\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:1168\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1165\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:1008\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    997\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    998\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    999\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         cache_position,\n\u001b[1;32m   1006\u001b[0m     )\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1008\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:749\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    748\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 749\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    752\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:236\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    234\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/bitsandbytes/nn/modules.py:450\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 450\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mhas_fp16_weights:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCxB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;66;03m# we converted 8-bit row major to turing/ampere format in the first inference pass\u001b[39;00m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;66;03m# we no longer need the row-major weight\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:562\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    561\u001b[0m     state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul8bitLt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:327\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    326\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 327\u001b[0m CA, CAt, SCA, SCAt, coo_tensorA \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_quant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m coo_tensorA \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mhas_fp16_weights:\n",
      "File \u001b[0;32m~/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/bitsandbytes/functional.py:2131\u001b[0m, in \u001b[0;36mdouble_quant\u001b[0;34m(A, col_stats, row_stats, out_col, out_row, threshold)\u001b[0m\n\u001b[1;32m   2129\u001b[0m is_on_gpu([A, col_stats, row_stats, out_col, out_row])\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m-> 2131\u001b[0m     nnz \u001b[38;5;241m=\u001b[39m \u001b[43mnnz_row_ptr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nnz \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2133\u001b[0m         coo_tensor \u001b[38;5;241m=\u001b[39m coo_zeros(\n\u001b[1;32m   2134\u001b[0m             A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], nnz_row_ptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(), device\n\u001b[1;32m   2135\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for max_new_tokens_factor in max_new_tokens_factor_list:\n",
    "    for n_shots_inference in n_shots_inference_list:\n",
    "        for adapters in tqdm(adapters_list, desc=\"adapters_list\"):\n",
    "            print(\"PROCESSING:\", adapters)\n",
    "            base_model = AutoModelForCausalLM.from_pretrained(\n",
    "                models_params.BASE_MODEL_CHECKPOINT, low_cpu_mem_usage=True,\n",
    "                quantization_config = bnb_config,\n",
    "                return_dict=True, \n",
    "                #torch_dtype=torch.float16,\n",
    "                device_map= \"auto\")\n",
    "            merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "            tokenizer = AutoTokenizer.from_pretrained(models_params.BASE_MODEL_CHECKPOINT, add_eos_token=False)\n",
    "            tokenizer.pad_token = tokenizer.unk_token\n",
    "            tokenizer.padding_side = \"left\"\n",
    "\n",
    "            # merged_model, tokenizer = load_mergedModel_tokenizer(adapters, base_model)\n",
    "            postprocessor = TestDataProcessor(test_data=val_data, \n",
    "                                              preprocessor=preprocessor, \n",
    "                                              n_shots_inference=n_shots_inference, \n",
    "                                              language=language, \n",
    "                                              tokenizer=tokenizer)\n",
    "            postprocessor.add_inference_prompt_column()\n",
    "            postprocessor.add_ground_truth_column()\n",
    "            #try:\n",
    "            postprocessor.add_responses_column(model=merged_model, \n",
    "                                            tokenizer=tokenizer, \n",
    "                                            batch_size=6, \n",
    "                                            max_new_tokens_factor=max_new_tokens_factor)\n",
    "            postprocessor.test_data.to_csv(f\"data/test_data_processed/maxNewTokensFactor{max_new_tokens_factor}_nShotsInference{n_shots_inference}_{adapters.split('/')[1]}.csv\", index=False)\n",
    "            # except Exception as e:\n",
    "            #     print(\"ERROR IN PROCESSING: \", Exception, adapters)\n",
    "            del merged_model\n",
    "            del base_model\n",
    "            del tokenizer\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapters = \"ferrazzipietro/Llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_4_0.0002\"\n",
    "\n",
    "postprocessor = TestDataProcessor(test_data=val_data.select(range(48)), preprocessor=preprocessor, n_shots_inference=2, language='en', tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column()\n",
    "postprocessor.add_ground_truth_column()\n",
    "postprocessor.add_responses_column(model=merged_model, tokenizer=tokenizer, batch_size=12, max_new_tokens_factor=5)\n",
    "postprocessor.test_data.to_csv(f\"data/test_data_processed/en_nShots{2}_maxNewTokensFactor{5}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL BASE simplets_prompt one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "Map: 100%|██████████| 1520/1520 [00:00<00:00, 5247.43 examples/s]\n",
      "Map: 100%|██████████| 170/170 [00:00<00:00, 6902.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config import postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "adapters = \"ferrazzipietro/Mistral-7B-v0.1_simplest_prompt_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_4_0.0002\"\n",
    "model_checkpoint = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "layer = 'en.layer1'\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(model_checkpoint=model_checkpoint, \n",
    "                                tokenizer = model_checkpoint)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset,\n",
    "                                                 simplest_prompt=True)\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            #load_in_4bit=True,\n",
    "            load_in_8bit=True,\n",
    "            # bnb_4bit_use_double_quant=True,\n",
    "            # bnb_4bit_quant_type=\"nf4\",\n",
    "            # bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            llm_int8_threshold= 6.0,\n",
    "            llm_int8_has_fp16_weight = False,\n",
    "            llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_checkpoint, low_cpu_mem_usage=True,\n",
    "    quantization_config = bnb_config,\n",
    "    return_dict=True, \n",
    "    #torch_dtype=torch.float16,\n",
    "    device_map= \"auto\")\n",
    "merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_eos_token=False)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "# merged_model, tokenizer = load_mergedModel_tokenizer(adapters, base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/681 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 681/681 [00:00<00:00, 7469.87 examples/s]\n",
      "Map: 100%|██████████| 681/681 [00:00<00:00, 10676.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "postprocessor = TestDataProcessor(test_data=val_data,\n",
    "                                  preprocessor=preprocessor, \n",
    "                                  n_shots_inference=2, \n",
    "                                  language=language, \n",
    "                                  tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column(simplest_prompt=True)\n",
    "postprocessor.add_ground_truth_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<<We present a case of a 32-year-old woman with a history of gradual enlargement of the anterior neck.>>> [/INST] [{\"entity\": \"present\"}, {\"entity\": \"history\"}, {\"entity\": \"enlargement\"}] \n",
      "[INST] <<<Patient information: a 9-month-old boy presented to the emergency room with a 3-day history of refusal to bear weight on the right lower extremity and febrile peaks of up to 38.5°C for 24 hours.>>> [/INST] [{\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}] \n",
      "[INST]A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.[/INST] \n",
      "\n",
      "<s>[INST]A 46-year-old man with hypertension and dyslipidemia diagnosed 4-months before, as well as new-onset diabetes mellitus unveiled 1-month earlier, was referred to emergency department for hypokalemia.[/INST][{\"entity\": \"hypertension\"}, {\"entity\": \"dyslipidemia\"}, {\"entity\": \"diagnosed\"}, {\"entity\": \"mellitus\"}, {\"entity\": \"referred\"}, {\"entity\": \"hypokalemia\"}, {\"entity\": \"new-onset diabetes mellitus\"}, {\"entity\": \"A 46-year-old man\"}, {\"entity\": \"4-months\"}, {\"entity\": \"1-month\"}] </s> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(postprocessor.test_data['inference_prompt'][0], '\\n')\n",
    "print(postprocessor.test_data['prompt'][0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses: 688it [11:38,  1.01s/it]                         \n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.34ba/s]\n"
     ]
    }
   ],
   "source": [
    "postprocessor.add_responses_column(model=merged_model, \n",
    "                                tokenizer=tokenizer, \n",
    "                                batch_size=8, \n",
    "                                max_new_tokens_factor=4)\n",
    "postprocessor.test_data.to_csv(f\"data/test_data_processed/maxNewTokensFactor{2}_nShotsInference{0}_{adapters.split('/')[1]}.csv\", index=False)\n",
    "# except Exception as e:\n",
    "#     print(\"ERROR IN PROCESSING: \", Exception, adapters)\n",
    "del merged_model\n",
    "del base_model\n",
    "del tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 Extract the entities contained in the text. Extract only entities\\n    contained in the text.\\n    2 Extract the entities contained in the text. Extract only entities contained in the text.</s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Hormonal study and dynamic biochemical tests performed indicated ECS.>>>\\n\\n 1 The text contains two entities: <<study>> and <<',\n",
       " '1 Extracted entities: right parotid malignancy with liver metastases 2 The entities contained in the text: primary right parotid malignancy with liver metastases Primary right parotid malignancy with liver metastases Malign',\n",
       " '3 Extract entities from ACC text.\\n```\\n\\n{\"entity\": \"parotidectomy\"}, {\"entity\": \"examination\"}, {\"entity\": \"confirmed\"}, {\"entity\": \"ACC\"}] 2\\n\\n6 {\"entity\": \"par',\n",
       " '1. Entities of the text in the DBpedia. 2. The entities only contained in the text. 3. Exactly those only contained in the text. 4. Metyrapone is not an entity.\\nEntities: ketoconaz',\n",
       " '1. A 50-years-old woman 2. hypertensive 3. hospitalized 4. a large cervical mass 5. appeared 30 years ago\\n\\n 1.. The system contains no errors. 2.',\n",
       " '2. Extract the entities contained in the text. Extract only entities contained in the text. 3. Text: <<In the family history, her mother, sisters and cousins underwent a surgery for MNG.>>>> ``` 25 2',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Text: <<Despite of the large volume of the mass, the patient never described signs of cervical compression whatsoever respiratory, digestive, l',\n",
       " '1. Text 2. Extract the entities contained in the text. 3. Extract only entities contained in the text. 4. She 5. dysfunction.\\n```text`{}`{}```\\n\\n| 1 | Text |',\n",
       " '1 Extract 2 Extract 3 contains 3 take 3 The mass took the front and the two sides of the neck.\\n\\n ## Text 2 1 Neck 1 The mass 2 The neck\\n\\n ## Text 3 1 Front',\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Its surface was embossed and covered by a thin normal skin.>>>> 2 Extract the entities contained in the text. Extract only entities contained',\n",
       " '1 Extract\\n 1 textual entity named <<veins of the collateral circulation limited to the neck⟩›.[{\"entity\": \"veins\"}, {\"entity\": \"the collateral circulation\"}, {\"entity\": \"the neck\"}] 1} 1}}',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 The goiter measured 18 x 11 cm.</TEXT> <ENTITY>The goiter</ENTITY> <ENTITY>18',\n",
       " '2.5.1 Extract the entities contained in the text. Extract only entities contained in the text.  Text: The mass was firm, painless, and mobile with the swallowing movements.\\n\\n 1. Extract the entities contained in the text',\n",
       " '1. Extract the entities contained in the text. 2. Extract only the entities contained in the text.\\n\\nExtraction of the two objects of the text. Extraction of both objects of the text.\\nText: <<Study of he',\n",
       " '1. The 3, 4 and TSH laboratory tests 2. T 3, T 4 and TSH 3. The 3, 4 and TSH laboratories tests\\n\\n- Normal\\n- Abnormal\\n- No information',\n",
       " '1.000000 0.084500 0.000000 0.713015 0.295323 0.000000 0',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. 2 Text: <<Cervical and chest CT revealed the presence of a partially calcified thyroid mass slightly plunging in the anterior mediastinum.>>>>',\n",
       " '1.3.2.3. Entities: MNG, contrast 1.3.2.3. Entities: contrast 1.3.3. Extract the entities contained in the text. 1.3.3.1. Entities',\n",
       " '1 2 3 4 The trachea was surrounded by the goiter 2 2 the lower part of the larynx 4 2 4 the goiter 2 the trachea 1 2 3 4 the lower part',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 The right and left vascular axes of the neck (carotid artery and jugular vein) were deviated backward.\\n315',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<MNG>> 3 Extract the entities contained in this text. Extract only entities that are contained in this text. Text: <<The patient underwent',\n",
       " '2 Found 2 entities. Entity_1 Entity_2 Kocher cervicotomy Kocher cervicotomy\\n```\\n\\n###### Text:\\n\\n```\\n<<The incision performed was a Kocher cervic',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: Its lower end plunges behind the sternal manubrium.\\n 4 Extract the entity `plunges`. 4 Extract',\n",
       " '1 Entity extracted\\n\\n Extract the entities contained in the text and their values. Extract only entities contained in the text and their values.\\nText: <<The larynx was deviated towards the right side.>>> 2 Entities extracted\\n\\n Extract',\n",
       " '3 Extracts all entities: The retrosternal part of the goiter was released using the finger by the same incision The finger The retrosternal part of the goiter The goiter Extracts only entities contained in the text (The goiter',\n",
       " '1. Extract autotransplanted; 2. Extract accidently devascularized; 3. Extract parathyroid gland; 4. Extract 1 parathyroid gland; 5. Extract the',\n",
       " '[{\"entity\": \"extraction\"},{\"entity\": \"aspiration drainage\"},{\"entity\": \"operation\"}] 1 3 2} There were 3 entities and in 1, 3 and 2 sentences respectively.\\n 2. Entity extr',\n",
       " '1 entity <<developed a large cervical hematoma>>  <<hematoma>>  <<a large cervical hematoma>>  <<hematoma>>  <<surgery>>; 2 entities <<the patient>>  <<patient>> Text: <<',\n",
       " '1. entities: <<She was readmitted to the operating room, and after evacuation of the hematoma there was no vessels bleeding.>>›  Extracted entities: <<She, vessels bleeding.>>\\n Text: <<She was readmitted to the operating',\n",
       " '1 Extracted entities: completed double suction drainage\\n\\n Text: <<The anatomopathological slide of our frozen biopsy allowed us to identify undifferentiated cells similar to those of an Ewing sarcoma[/{\"entity\": \"slide',\n",
       " '2 Extract 1 entities, then the entities contained in the text (case 2).  Extract 2 entities, then all entities contained in this and other texts (case 3).\\n\\n1. {\"entities\": {\"entity\": [\"dobutamine',\n",
       " '1. Entities contained in the text 2. Only entities contained in the text 3. Hemodynamic support 4. Blood pressure 5. Stabilized 6. Stopped 7. Dobutamine Extract these entities contained in the text',\n",
       " '1.0 1 1  True  False\\n Extract the entities contained in the text. Extract only entities contained in the text.\\n Text: <<Histological study concluded in multinodular colloid goiter.>>> 1 1',\n",
       " '1. Extract all entities from the text. 2. Extract only entities from the text. Text: <<The patient was discharged from the hospital after 20 days in good health.>>> {@entity: {\"patient\", {\"entity\" => \"The',\n",
       " '1. A 21-year-old male 2. pancreatitis 3. symptoms 4. pancreatitis 5. cross-sectional imaging 6. gastroenterology clinic 7. But 8. The p',\n",
       " '1) Extract the entities contained in the text. 2) Extract only entities contained in the text. 3) Text: <<He had presented to the emergency department for abdominal pain consistent with prior episodes of renal colic.>>>> 4',\n",
       " '2 Related Concepts: chronic pancreatitis pancreatic atrophy pancreatitis chronic pancreatitis 30 Entities found: atrophy calcifications chronic pancreatitis findins pancreatic atrophy panc',\n",
       " '2. Extract the entities contained in the text. 3. Extract a list of all entities found in the text. 4. Extract only named entities (in our case, persons, organizations, locations, etc).\\n\\nThe list of entities to extract',\n",
       " '1, 1 Extract the entities contained in the text Extract only entities contained in the text Text: <<His family history was significant as his father had an isolated episode of pancreatitis which required abdominal surgery.>>>> 1, 1',\n",
       " '3 Extract the entities contained in the text. 2/12 Extract only entities contained in the text. Text: <<Magnetic resonance cholangiopancreatography (MRCP) showed severe parenchymal atrophy and panc',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text.\\n\\n Text: <<Due to his young age and atypical presentation, he was referred for genetic testing and counselling.>>>\\n\\n Entity: <<young age',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. The text is the one listed in the instruction. 3 If more than one text, you have to show for each one the result of the extraction. 4',\n",
       " '2.6 Extract only the entities contained in the text.[{\"entity\": \"tested\"}, {\"entity\": \"positive\"}, {\"entity\": \"mutation\"}, {\"entity\": \"Homozygous variant of SPINK1 (N34S)\"}]',\n",
       " '3 Extracts the entities in the text or a subset of them (orange) 5 Extracts the entity names inside the text 6 Extracts all the entities contained in the text 7 Extracts all the entities in the text except the entity',\n",
       " '1 Extracted entities: <<pancreatic insufficiency>> 2 Keeped entities: <<pancreatic insufficiency>> 3 Extracted entities count: 1 4 Keeped entities count: 1\\n Text: <<Cure',\n",
       " '1. He 2. pancreatitis 3. lifespan 4. cancer 5. detection 6. prevention\\n\\nExtract only entities contained in the text. Extract only entities contained in the text. Text: <<Due to the sever',\n",
       " '1. Extract all entities from text 2. Extract only entities contained in text\\n[{\"entity\": \"tests\"}, {\"entity\": \"revealed\"}, {\"entity\": \"elevated bilirubin\"}, {\"entity\": \"liver enzyme levels',\n",
       " '2 Extract the entities contained in the text. Entities contained in the text. 5 × 3-cm mass obstructing the common bile duct Text: <<A computed tomographic scan showed a homogeneous 5 × 3-cm mass ob',\n",
       " '1 entities\\n```text\\nThe results of brush cytology\\nbile duct villous papilloma\\n```',\n",
       " '2. From Extrahepatic bile duct malignant tumor 3. Extrahepatic bile duct malignant tumor 4. Bile duct malignant tumor 5. Extrahepatic bile duct',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. No Text\\n Text: <<The tumor was located in the head section of the bile duct and presented invaded peripancreatic connective tissue.[/INST',\n",
       " '2 Extract only entities contained in the text. 3 Extract entities contained in the text. 4 Extract the entities contained in the text. 5 Extract the entities contained in the text. Extract the entities contained in the text. 7 Extract',\n",
       " '1 Extract Mention Extract Mention Uneventful 1 Pair 1 Pair 0\\n\\n Text: <<She is on medical therapy.>>> 1 Extract Mention is 1 Mention 1 Count Therapy 1 Count 0',\n",
       " '1.  entities 2.  entities 3.\\n The result has been saved in the file named \\'Disease.txt\\'.</p></div> </li><li><div class=\"entity\"><li><div class=\"entity\"><li><div class',\n",
       " '1. She 2. a history of diabetes 3. hypertension 4. treated by glinide and calcium blocker 5. She 6. diabetic 7. hypertensive patient 8. glinide 9. calci',\n",
       " '1  entities 4 years 2  explore 2 She 2  exudative pleuritis of the right lung 4 exudative pleuritis of the right lung without any established diagnosis 4 exploration 4 thoracoscopy with biops',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract the blood pressure 150/70 mmHg. 4 Extract the pulse rate 80/mn. 5 Ex',\n",
       " '2. Extract entities. 2.1. Extract the entities contained in the text. 2.2. Extract only entities contained in the text. 2.3. Show or hide them in plain text. <br> 2.4.',\n",
       " '1 entity extracted\\n 0.03g/24h\\n Text: <<Hemoglobin was 8 g / dl and white blood cell count was 5,290 / μL.>> 0 entities extracted\\n <<H',\n",
       " 'Extracted entities: <<count, time, tests, nitrogen, creatinine, sediment rate, cholesterol, Platelet count, activated partial thromboplastin time, liver function tests, blood urea nitrogen, serum',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. 3. Extract the entities contained in the text.\\n Text: <<Tests for HBsAg and HCV were negative.>>> 1',\n",
       " '1.51 s 7.78% 19608166\\n\\n- abdominal ultrasonography showed ascitic fluid\\n- sign of bowel loop thickening\\n- sign of enteritis\\n- bowel loop',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: <<Neither lymphadenopathy nor liver abnormality was present.>>>> 1 Extracted text: {{Neither l',\n",
       " '1 Extract the entities contained in the text. 0 Extract only entities contained in the text. Text: {\"A chest X-ray film\", \"disclosed\", \"bilateral pleural effusion\", \"bilateral pleural effusion\"} {\"A chest X',\n",
       " '1\\n 1 Tuberculosis investigation including initial tuberculin skin test and the research of Koch bacilli in sputum and urine were negative.<br/>\\n 2 Tuberculosis investigation<br/> 3 Tubercul',\n",
       " '1. Echocardiography, 2. Electrocardiography were normal. 1. Echocardiogram, 2. Electrocardiogram The entities \"Echocardiogram\" and \"electrocardiogram\" were extracted',\n",
       " '2. Extract the entities contained in the text. 3. Extract only entities contained in the text. 4. Extract all the entities in the text. 5. Extract all the entities contained in the text. Text: <<Computed tomographic',\n",
       " '1 Extract the entities contained in the text. 1 extracted the entities contained in the text. 1 normal 1 Pelvic examination 0</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: <<Oesogastroduodenoscopy showed hiatal hernia without oesophageal varices.>>>.\\n``` 1',\n",
       " '1 Examinations were negative, and a percutaneous liver biopsy showed no pathological findings.[{\"entity\": \"examinations\"}, {\"entity\": \"negative\"}, {\"entity\": \"biopsy\"}, {\"entity\": \"showed\"}, {\"entity\": \"',\n",
       " '2 entities extracted: Examination, non specific chronic inflammation\\n Extract the relationships described in the text. Relationships can be between two entities in the text, or between an entity in the text and an abstract entity.\\n Text: <<Erythro',\n",
       " '2 entities Extract the entities contained in the text. Extract only entities contained in the text.\\n    Text: <<An additional serologic survey revealed markedly elevated anti-nuclear antibody (ANA) titer of 1/16',\n",
       " '2  She had also positive serum antibody against the Smith antigen and low serum level of C3 complement  component: 67 mg/dL (serum normal range: 84 – 151). 67 mg/dL',\n",
       " '1. Extract the entities contained in the text. Extract only entities contained in the text. 2. Text: <<Relying on these findings, the patient was diagnosed with SLE since 4 of the 11 diagnostic criteria of the American College of',\n",
       " '1.5.2 EMBEDDED ANNOTATIONS\\n  Annotations enclosed by a start and end tag. The tags should be contained in the text.\\n  Tag style: <<TEXT_ENCLOSED_BY_START_AND_END_',\n",
       " '1 {\"entity\": \"diagnosed\"}, {\"entity\": \"WHO\"}, {\"entity\": \"criteria\"}, {\"entity\": \"NS\"}, {\"entity\": \"referred\"}, {\"entity\": \"enrolled\"}, {\"entity\": \"care\"}, {\"entity\": \"nodding',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. Text: <<The swelling was associated with a high grade fever which was constant and only partially relieved by analgesics.>>>>.[{\"entity\": \"swelling',\n",
       " '1 related entity: patient 1 related entity: history 1 related entity: falling from a tree 1 related entity: hit his abdomen onto a tree branch 1 related entity: nodding episodes 1 related entity: The patient 1 related entity: ab',\n",
       " '2 entities Extract the entities contained in the text.\\n Extract only entities contained in the text. Text: <<On further probe on his childhood history, his mother reported that he was born normally at home by a Traditional Birth Attendant (TBA) in one',\n",
       " '2 Extract the entities contained in the text. 3 Extract only entities contained in the text. The text contains in total 15 entities. In both cases 15 entities were extracted, 2 of them unique. 5-7\\n\\n21',\n",
       " '1. The child 2. enrolled 3. managed 4. Carbamazepine 5. multivitamins 6. Ivermectin 7. Atanga treatment centre 8. the child.\\n```',\n",
       " '1.7.1 1.7.2 1.7.3 1.7.4 <<She reported>> <<the child continued to have seizures and nodding at least twice a day and had since dropped out of school>> <<this medications>>',\n",
       " '1 entity In the text\\n 1 entity contained in the text\\n\\n Text: <<Hemoglobin: 9.9 mmol/L ≥ 13.5 /mL. White blood cells:11.81×1',\n",
       " '1.66667e-05 0.00000 0.00000 1.0000\\n```\\n\\nWe first show the output using the original text as input. The text is first',\n",
       " \"2 entities (The spleen, The liver) are extracted from text with category 'Not palpable'.\\nText: <<The spleen and liver are not palpable.>>>. 2 entities (The spleen, The liver) are extracted from text with\",\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Text: <<There was no renal or supra-pubic tenderness.>>>> 4 entities were extracted by the first rule, and only 2 by',\n",
       " '2 Extract the entities that are linked to 1 or more entity of the text.\\n Text: <<The rectum was full of faecal material which was of normal colour and consistency.>>> 3 Extract the entities that have a link with an external entity',\n",
       " '1 0 Haematological investigations were conducted and showed neutrophilia, lympocytosis, 1 1 monocytosis, and eosinophilia.\\n Text: <<HbS levels were high.>>> 0 H',\n",
       " '2 entities were extracted from the text ({\"Entities\": \"elevated\"}, {\"Entities\": \"results\"}, {\"Entities\": \"tests\"}, {\"Entities\": \"liver\"}, {\"Entities\": \"ALT\"}, {\"Entities\": \"AST\"}, {\"Entities\": \"protein\"}, {\"',\n",
       " '1 Extract the entities contained in the text. 2 Extract entities contained in the text. Entities to be extracted: <<Abdominal Ultrasound showed inflamed internal and external oblique muscles of the anterior abdominal wall>>\\n2016',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text. Text: He received supplementary food rehabilitation and his seizure medication was changed to Sodium Valproate 200mg once a day under direct observation therapy (',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient continued to have regular follow up in the surgical ward; seizures and nodding stopped completely from the time of intervention in the hospital.',\n",
       " '1. Extract the entities. 2. Extract only entities contained in the text.\\n Text: <<With these interventions for over one month the child had no seizures nor nodding and the child returned to normal life.>>>.</p>',\n",
       " '2. Text: A subsequent review of the haematological findings 2 weeks later showed that renal function tests, serum electrolytes were normal except liver enzymes were elevated and the level was still increased.[{\"entity\": \"review\"}, {\"entity\":',\n",
       " '1 Extract the entities contained in the text  Extract only entities contained in the text  Text: <<A 21 year old female patient with the diagnosis of SWS suffering from headaches admitted to our clinic.>>>>\\n <a href=\"https://d',\n",
       " '1 entity 0\\n 1. She 0\\n 2. frequent non-pulsating headaches 2\\n 3. 2 year 2\\n 4. She 0\\n```\\n\\nNotebook 001\\nIn notebook',\n",
       " '2 Extracts of entities: {\"Headache\"}, {\"Relieving\"}, {\"Activity\"}, {\"Worsening\"}, {\"Her headache\"}, {\"non-steroidal anti-inflammatory drugs\"}, {\"physical activity\"}] 2: {\"Her head',\n",
       " '1. Extract the entities contained in the text. Extract only entities contained in the text. Text: <<There was no nausea or aura like symptoms accompanying the headache.>>>\"entities\"}},\"value\": \"There was no nausea or',\n",
       " '2 2 0 0 0 54 54 0 0 0 \"Headaches\" \"hours\" 1 1 0 579 579 592 559 560',\n",
       " '2 Extract the entities contained in the text.[{\"entity\": \"history\"}, {\"entity\": \"headache\"}, {\"entity\": \"headache\"}, {\"entity\": \"positive\"}] 2} 1 2, {\"entity\": \"The family history for head',\n",
       " '1-24 1-9 1-17 1-18 23 4 20 SWS 15ª dia de vida SWS 15ª dia de vida attacks of tonic clonic contractions diagnostic SWS',\n",
       " '1 matches 1 in the text 0 matches elsewhere\\n Text: <<A 3 T MRI was also performed which was reported as normal.>>> 0 matches 0 in the text 1 matches 1 elsewhere\\n Text: <<The parents were advised to bring',\n",
       " '1 entity: At the age of 18 during a laser treatment done in order to get rid of her port wine birthmark she had her first seizure since callosotomy.[{\"entity\": \"seizure\"}, {\"entity\": \"She\"}, {\"entity\":',\n",
       " 'Extract the following entities:\\n >>Carbamazepine<<                        >>400 mg at daily dose<<                              >>she<<  <<never<<\\n After that she was prescribed carbamazepine 400 mg at daily dose and never',\n",
       " \"1: entities 2: 1 entities taken from her: <<her parents>> 3: her: <<she had a normal development at infancy>> 4: she: <<she barely graduated from elementary school and she's hardly literate>> 5:\",\n",
       " '1 entity  >>text\\n2013-08-20 15:33:52,317 0 INFO 1986205864 1 extractor.text.en 1 entity',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text.\\n1 Extract the entities contained in the text.\\n1 Extract only entities contained in the text.\\nText: <<The elder sister had no feature of SWS and',\n",
       " '[[{\"entity\": \"inscribed\"}, {\"entity\": \"doses\"}, {\"entity\": \"ketiapin\"}, {\"entity\": \"headaches\"}, {\"entity\": \"anxiety disorder\"}, {\"entity\": \"anxiety disorder\"}, {\"entity\": \"chronic',\n",
       " '1 She 2 She 3 NSAID drugs NSAID drugs\\n```\\n\\n## Answer (1)\\n\\nThe output shown is correct: the first and third entities are in the original input, while the second is mentioned but not mentioned (also known',\n",
       " '1.1.1 Extract the entities contained in the text 1.1.2 Extract only entities contained in the text Text: <<After the first week of this treatment her headaches were slightly decreased by heaviness but the frequency was the same.>>',\n",
       " '1 Entities: 2 External entities: 2 Internal entities: 1\\n\\n Extract the entities that occur in one text only. Extract the only entity occurs in one text. Text: <<A small red nevus was observed on the right side',\n",
       " '1.0 Extract the entities contained in the text. 0.6 Extract only entities contained in the text.\\n```\\n\\n###### Abstract\\n\\n```\\nExtract_entities_(extract_entities_contained_in_the_text;',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract the entities contained in the text.\\n\\n{{text}} {{entities}}  Her left arm and leg was slightly smaller in portions and showed hemip',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text.  Text: <<On her ophthalmological evaluation she was diagnosed with glaucoma of the right eye.>>\\n 9 14',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text. Text: &#8220;On her psychiatric examination she showed signs of anxiety disorder.&#8221;\\n{Anxiety disorder} & 1 {@',\n",
       " '1. Extract the entities contained in  Cranial CT scans showed diffuse atrophy in the right hemisphere  irregular double-contoured gyriform cortical calcifications in the right occipital area  Right hemisphere  Right',\n",
       " '1 Extracted entity: diffuse atrophy on the right side of the brain  The word contains one or more  entities  with the same meaning  as the word itself  diffuse atrophy on the right hemisphere  diffuse atrophy',\n",
       " '4 Extract entities contained in the text.\\nEntities extracted in the text: <<axial T1 weighted cranial MRI shows right calvarial thickness compared to the left and right hemisphere is asymmetrically smaller than the left.>>>',\n",
       " '1 Extracted entity: T2 weighted MRI 2 Extracted entity: MRI 3 Extracted entity: extensive venous formations around corpus of right lateral ventricle and at Gallen vein localization and widespread vascular',\n",
       " '1 Extracted entity: proteus intelligence test 2 Extracted entity: retardation 3 Text: She was performed a proteus intelligence test...\\n   Extracted entity: test 4 Text: test 5 Extracted entity: retard',\n",
       " '1.Proteus intelligence test 2.she 3.accepted 4.mentally retarded\\nExtract the entities contained in the text. Extract all entities contained in the text. Text: <<In a multidisciplinary team, we treated her',\n",
       " '3 years old boy diseases bipolar trauma hemicorporal point of impact domestic accident 3 years old boy hemicorporal point of impact left hemicorporal A 3 years old boy 3 years old boy without any particular diseases history left',\n",
       " '2. The delay to consult was 5 hours after the incident. 3. 5 hours Text: <<He was admitted straightaway.>> 4. 5 hours Text: <<Admitted straightaway.>> 5. He 6. Admitted',\n",
       " '1 Extraction of entity 0.500000 1 Extraction of entity 0.500000 1 Extraction of entity 1 Extraction of entity  \"<<The clinical examination at admission had showed',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 4 Extract all entities found in the text. 3 Extracts all entities contained in the text. 5 Extracts all entities found in the text',\n",
       " '<entity>hip</entity><entity>reduction</entity><entity>replacement</entity><entity>aim</entity> <entity>one hour</entity> <entity>we</entity><entity>three weeks</entity>\\n\\n        The entities contained',\n",
       " '3 Extract the entities contained in the text.\\n```\\n\\nThe problem is the `Text` parameter. In reality it contains \"`<<`The Salter I detachment of the humerus was orthopedically reduced then immobilized by a th',\n",
       " '1 Related Artifacts 2 Extract the entities contained in the text 3 Extract only entities contained in the text\\n 4 Text: <<Revised after a month, showed a stable left hip on the clinical examination.>>>\" 211168',\n",
       " '1 {\"entity\": \"menstruated\"}, {\"entity\": \"A 33-year-old woman\"}, {\"entity\": \"28 years old\"}] 2 {\"entity\": \"A 33-year-old woman\"}, {\"entity\": \"28',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Her initial menarche was at the age of 14 years and it is in accordance with the normal growth of a child at her age.>> 3',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract the named entities contained in the text. 4 Extract the relationships between entities.\\n Based on clinical examination and a physical examination, the patient was',\n",
       " '1) \"ultrasonography\", \"thorax X-ray\", \"CT Scan Head\" 2) \"CT Scan Head\" 3) \"ultrasonography\", \"thorax X-ray\", \"CT Scan Head\"',\n",
       " '1. extract 2. entities 3. contained 4. suspected 5. show 6. effusion 7. pleural effusion 8. Ultrasonography 9. thorax X-Ray 10. patient\\n\\nText',\n",
       " '1 Extract the entities contained in the text. 2 Extract entities contained in a text to create a collection of entities. 3 Extract entities contained in a text to display it to a user.\\n\\n[{\"entity\": \"examination\"}, {\"entity\":',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 The treatment plan in this patient is P test therapy with Prothyra 1x10 mg for 7 days, with control on 2 weeks after',\n",
       " '1. P test 2. showed 3. result 4. bleeding 5. not bleeding 6. progesterone consumption 7. prothyra 8. 14 days These entities were extracted from the text.\\n Text: <<G',\n",
       " \"2 Extract the entities contained in the text. Extract only entities contained in the text.\\n```\\n\\n```\\n{'entities': ['The treatment', 'followed by', 'test', 'Estrogen+Progesterone', 'Estrogen',\",\n",
       " '1. The E+P test 2. a negative result 3. hysteroscopy 4. uterus evaluation 5. The uterus\\n[{\"entity\": \"test\"}, {\"entity\": \"result\"}, {\"entity\": \"hysteros',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text.  Text: <<A pregnant woman aged 25, G3, P2, is on admission with swelling of the lower extremities.[/INST][{\"entity\": \"',\n",
       " '1 entities 3 0 6 3\\n 2 entities 8 0 5 3\\n 3 entities 9 0 4 3\\n 4 entities 10 0 3 2\\n 5 entities 12',\n",
       " '2 Extract only entities contained in the text.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '1. Anatomical pathology result, 2. Macroscopic observation, 3. The diameter 0.3 cm and 0.4 cm and grayish-white color, 4. The microscopic observations, 5. The fib',\n",
       " 'Extract the entities contained in the text.  Extract only entities contained in the text.  Text: <<A 32-year-old female patient with Kniest syndrome presented at our department with a painful pseudarthrosis after femoral valgisation',\n",
       " '1 Wagner cone stem 1 acetabular roof cup 1 cemented Ecofit cup 2M 1 dysplastic femur with a small medullary space\\n```\\n\\n- Text: <<A Wagner cone stem and acet',\n",
       " '51 The Ecofit cup itself 34 dislocation 1\\n\\n2019-03-04 17:41:00 300153 The Ecofit cup itself is associated with a reduced risk',\n",
       " '1 Extract the entities contained in the text. 2 Extract only the entities contained in the text. 3 Text: <<The patient was satisfied with the range of motion after hip endoprosthesis and reported a significant increase in quality of life.>>>>',\n",
       " '1 entity 0 entities The patient is still comfortable with the hip prosthesis at the most recent follow-up 4 years after implantation.\\n\\n# Text and entity entities\\n\\n>> 1 entity 0 entities <<The patient is still comfortable<< with the',\n",
       " '1 Extracted elements: \"loosening signs of loosening loosen loosing loosening migrating migration migrate migrated migrates reporting reported Trendelenburg signs Trendelenburg sign loosening signs of loosening loosening lo',\n",
       " '1. The patient 2. a 35-year-old female 3. a female 4. urinary frequency 5. 2 months 6. The patient 7. a 35-year-old female 8. a female',\n",
       " '2.00 12 4 Text: <<He was a 33-year-old nonalcoholic male who had been smoking ten cigarettes per day.>> 2.00 12 4 Text: <<Her past medical history',\n",
       " '1. Extract the entities contained in the text.  <span style=\"color:blue\">The physical examination was unremarkable.</span> 2. Extract only entities contained in the text. <span style=\"color:blue\">unremarkable</span',\n",
       " '1.0 0.0 \"urinary tract infection\" \"She\" \"her symptoms\"  \"urinary tract infection\"\\n```</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '1 Extracts: Urine analysis and culture 1 Negative for infection 2 Urine analysis and culture 2 Negative for infection The system should be able to learn that \"negative\" is an adjective and not an entity. So, we may consider',\n",
       " '1, 000\\n\\n 2,500 3 Extract the entities contained in the text. Extract only the entities contained in the text.\\n Text: <<Hematoxylin-eosin (H&E) staining showed',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Through a routine evaluation, urinary system ultrasonography (US) revealed a bladder lesion measuring 7 mm.>>>>\\n 2',\n",
       " '1 Extract 1 Extract 1 Extract MRI revealing a lesion in the dome of the bladder 3 Extract 1 MRI\\n\\n Extracting entities from a text:\\n\\n The text:\\n\\n <<Magnetic reson',\n",
       " '1 Extract extracted entities from text 1 Extract entities from text Text: <<confirm diagnosis histopathological examination TURBT TURBT in April 2018 patient The patient 2018>> 1 Extract extracted entities from text 1',\n",
       " '2 Extract the entities contained in the text. 0 Extract only the entities contained in the text.\\n\\n  Text: <<Then, it was resected by monopolar cautery from superficial to deeper parts with removal of the muscle layers.',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. 3. Text: <<Proper bleeders were taken and three way Foley catheter was applied for a continuous irrigation.>>>,',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text.\\n Text: <<The patient was transferred to the recovery room with complete stability.>>> {@patient}, {@transferred}, {@stability}, {@recovery room}',\n",
       " '1;1;1  6;6;6  3;6;6  1;6;6\\n\\n Text: <<The histopathology slides show a well-defined mass composed of bland looking spindle cells.>>> 3\\n  Extract',\n",
       " '3 Extract negatively valued entities like <<negative>>.[{\"entity\": \"showed\"}, {\"entity\": \"stained\"}, {\"entity\": \"showed diffuse immunoreactivity\"}, {\"entity\": \"immonoreactivity\"}, {\"entity\": \"stained\"},',\n",
       " '2-3%, so the diagnosis of schwannoma was confirmed.  schwannoma 2-3% The system identifies 1 entity (schwannoma), a numeric value (2-3%) and a binary relationship (confirmed).',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: <<Brain and spine MRI and physical examination showed no evidence of other schwannoma or evidence of neurofibromatosis.>>',\n",
       " '1.  Text: “She had no history of neurofibromatosis in her family”. 2.  Entities:  “She”  “no history of neurofibromatosis in her family” 3.  Extracted entities',\n",
       " '1.\\n Skin  Skin examination  café au lait spot Normal\\n 2.\\n Extract the entities contained in the text.\\n- Extract only entities contained in the text.\\n- Extract the properties of the entities contained in the text.',\n",
       " '2. Extracted the entities contained in the text. Extracted only entities contained in the text. 3. Entities contained in the text. Entities contained in the text.\\n  Text: <<She was not a case of von Recklinghausen',\n",
       " '1 mentally ill man 1 suicide by fire 1 35-year-old 3 days 3 days before admission</a> </p> 516 517 516 518 519 51',\n",
       " '1 Extract the entities contained in the text 2 Extract only entities contained in the text 3 Text: <<He acquired full-and partial-thickness injury in approximately 38% of his TBSA, including face and neck (5%),',\n",
       " \"3  5  66 'hospitalized' 'surgeries'  'debridement'  'The patient' <entities>\\nExpert System: <<The patient was hospitalized for 66 days and underwent five debridement sur\",\n",
       " '[[{\"entity\":\"diagnosis\"},{\"entity\":\"schizophrenia\"},{\"entity\":\"treated\"},{\"entity\":\"schizophrenia\"},{\"entity\":\"Haloperidol\"},{\"entity\":\"Diazepam\"}] 1{\"entity\":\"2',\n",
       " '1. Text 2. Entities (2) Extract the entities contained in the text Extract only entities contained in the text Text: The patient was occasionally restrained due to rebellious and self-destruction behavior. Extract the entities contained in the text Ex',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 The nutrition management of this patient 4 started 5 after a week of hospitalization 6 which is considered late.\\n Text: <<After admission, chest',\n",
       " '1 Extract the entities contained in the text. 2 Extract only those entities of the text that are not contained in some other text. 3 Find those entities in the text that are also contained in some other text.</s></s></s></s></s></s></s></s></s>',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text.\\n Text: <<Signs of fluid accumulation were not found.>>> } {{\"Signs\"}, {\"accumulation\"}, {\"found\"}, {\"Signs of fluid',\n",
       " '1 Extract the entities contained in the text 2 Extract only entities contained in the text 3 group 4 belonged 5 SGA 6 the patient 7 group C 8 severely malnourished 9 text\\n The next entity should be grouped',\n",
       " 'Text: <<The patient was also given micronutrient supplementations, specifically vitamin A 100,000 units for the first week, vitamin C 100 mg 3 times a day, and zinc 20 mg once',\n",
       " \"1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<During the early weeks of hospitalization, the patient's weight loss continued.>>>> 1 Extract the entities contained in the text. Extract only\",\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<During the treatment, the patient\\'s appetite was unstable.>>> ```{\"Unstable\" : \"U}, {\"Appetite\" : \"A\"},',\n",
       " '2 2 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient was also hardly cooperative with enteral access.>>>> 2 2 4 Extract the entities contained in the text. Extract',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 The patient did not respond well to analgesics and sedations.\\n```\\n````entities```` {````The patient```}',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: Partially parenteral nutrition 4 Text: enriched 5 Text: administered 6 Text: support 7 Text: needs',\n",
       " '1.1.2 Extract the entities contained in the text. 1.1.2 Extract only entities contained in the text. 1.1.4 Extract phrases matching the given pattern: \"serum albumin level of 2 gr/L',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<On the 66 th day, granulation tissues appeared on the wound bed.>>>> 3 Extract one or more entities contained in the text.',\n",
       " '35/72 [[{\"entity\": \"muscle wasting\"}, {\"entity\": \"subcutaneous fat loss\"}, {\"entity\": \"muscle wasting\"}, {\"entity\": \"subcutaneous fat loss\"}, {\"entity\": \"The patient\"}] 9/',\n",
       " \"2.5. Extracting entities contained in the text.\\nThe program's entity extraction was implemented based on the NLP method of named entity extraction. The entities are represented as the words in the text, excluding the stop words, proper noun\",\n",
       " '1. Extract 2. Extract only 3. The patient 4. discharged from the hospital\\n```</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '2.2 Text: <<A review of the records confirmed that the arterial switch procedure had been carried out at our institution.>>>>> 2.3 Text: <<Although the patient was still intubated, the family requested return to our institution.[/',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Transthoracic echocardiography revealed an anomalous accelerated flow, indicating an anomalous systemic pulmonary shunt.>> Entity:',\n",
       " '1.3.2 Entity extraction Entity extraction is used to extract entities from a text. If you want to know more about this option, please see the entity extraction tutorial.\\n Entity extraction is used to extract entities from a text. If you want to',\n",
       " '1 {The anomalous ectatic bronchial artery} anomalous ectatic bronchial artery 2 {occlusion/dilation} occlusion 3 {successfully occluded/dilated} The anomalous ectatic bronch',\n",
       " \"1 entity extracted 1 entity extracted\\n Text: <<An 18-year-old female collegiate athlete presented with vague right thigh pain.>>> 2 entities extracted\\n Text: <<The patient's primary care physician referred her to our clinic following the discovery\",\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text.\\n Text: <<This case report describes the condition of a 30-year-old man involved in a motor vehicle collision.>>>\\n 30-year',\n",
       " '1 Extracts all the entities in the text 1 Extracts only the names of hip dislocation, femoral head fraktur in the text\\nUser>> 12518;1392\\n\\n\\n  Entities:  post',\n",
       " '3 Extracted entities: The patient hip dislocation hip dislocation hip Reduction nailing intramedullary nailing femoral shaft 3 Extracted entities from the text\\n\\n Text: <<The patient was transferred to a private hospital for further hip rehabil',\n",
       " '1 Extracted entity: ipsilateral fractures 2 Extracted entity: challenge 3 Extracted entity: open reduction 4 Extracted entity: complications 5 Extracted entity: closed reduction 6 Extracted entity:',\n",
       " '3 Extract from the text above all the entities (entities contained in the text).\\n 4 Extract only the entities contained in the text (the text in this situation, therefore without looking at all the other paragraphs of the article).\\n```\\n\\n``',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text.  Text: <<We present here a case of Macrophage activation syndrome associated with Griscelli syndrome type 2 in a 3-years-old male ...',\n",
       " '1. He 2. born 3. complications 4. breast 5. diversification 6. weight 7. length 8. food 9. eater 10. diet 11. description 12. normal 1',\n",
       " '2 months.>> Text: <<A 29-year-old male farmer was diagnosed with paratubal borderline tumour was stable for a year on [[hormonal]] contraceptive.[/TEXT][{\"entity\": \"stable\"}, {\"entity',\n",
       " '2 Extracted entities: <<vomiting urinary complaints bleeding from any site neurological complaints>> 2: 1 2: 2 2: 3 2: 4 2: 5 2: 6 -----------------------',\n",
       " '1: pale; scalp hair; eyelashes; hypotonic; tachycardic; fever; lymphoadenopathy; hepato-splenomegaly. 2: febrile; white eyelashes;',\n",
       " '1. Hb 6.3 g/dL 2. Neutrophils 820/µL 3. Platelets 44 000/µL 4. Leucocytes 1980',\n",
       " '{{\"triglycerides\"}, {\"ferritin\"}, {\"lactic dehydrogenase\"}, {\"CRP\"}, {\"Serum triglycerides\"}, {\"Serum ferrintin\"}, {\"Serum lactic dehydrogenase\"}, {\"',\n",
       " '1 entities (normal 1, was 1, ultrasound 1, showed 1, hepatomegaly 1, splenomegaly 1, biliary ducts 1, ascites 1)\\n 2 normal',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Because of hepato-splenomegaly, pancytopenia, hyperferritinemia and hypofibrinogenemia the diagnosis',\n",
       " '1 Blood culture 2 urine examination 3 malarial serology 4 Kala Azar serology 5 viral serologies such as EBV, hepatitis A, B, C and human immunodeficiency virus HIV, serologies',\n",
       " '1. Extract the entities contained in the text\\n 2. Extract only entities contained in the text\\n 3. Text: <<Serologies of CMV and rubella showed an old immunization.>>>\\n```\\n\\nIn addition, we provide',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The immunological tests such as antinuclear antibodies (ANA), anti-LKM1, anti-mitochondria and anti',\n",
       " '1 entities, 2 extracts in the text, 2 entities.\\n*consanguineous family*\\n*recurrent infection*\\n*silvery-gray color of the hair and eyebrows*\\n*Grisscelli Syndrome*\\n*light',\n",
       " '1. The molecular biology 2. showed 3. mutation in RAB27A gene 4. confirming 5. diagnosis 6. a Griscelli syndrome type 2.\\n 1.The molecular biology 2.',\n",
       " '1 entity, 1 modifier, 2 references (one of which contains an entity) 12 lexical units, 8 units (after the removal of stopwords), 19 words.\\n```\\n\\nThe text below presents information extracted from',\n",
       " '1 entity 1 entity 2 entities 2 entities 3 entities 4 entities 4 entities 5 entities 5 entities 6 entities 6 entities 7 entities 7 entities 8 entities 8 entities 9 entities 9 entities 9 entities 9',\n",
       " '2 2 Extracted entities in the text A good managed infectious process Ceftazidim aminoside Extracted entities in the text A good managed infectious process Ceftazidim aminoside Extracted entities in the text A good managed',\n",
       " '1.  Extract. 2.  Extract only entities. 3.  Text. 4.  Did not refer any motor or sensory deficit. 5.  motor deficit.\\n\\n\\n\\n\\t\\t\\tThis is an example',\n",
       " '1. Extract the entities contained in the text. Extract only entities contained in the text. This text contains the following entities: <<facial palsy>>.\\n\\n Text: <<There was no dysphoria. No diplopia was detected.',\n",
       " '1 entity extracted <entities> in 1 texts\\n\\n[{\"entity\": \"examination\"}, {\"entity\": \"showed\"}, {\"entity\": \"mass\"}, {\"entity\": \"mass\"}, {\"entity\": \"tender\"}, {\"entity\": \"compressible\"}, {\"entity',\n",
       " '1 Extract the entities contained in the text 2 Extract only entities contained in the text Text: The tumor surface was smooth and red-purple. Entities: The tumor surface The tumor surface was smooth The tumor surface was red-purple',\n",
       " '1. Several teeth 2. tumor mass 3. tumor mass 4. Several teeth 5. <<tumor mass>> 6. Several teeth 7. tumor mass\\nText: <<A 30-year-old male patient',\n",
       " '2. Extract the only entities contained in the text. 3. Extract the entities contained in text without text, without stop words and without numerals.[{\"entity\": \"We\"}, {\"entity\": \"noted\"}, {\"entity\": \"absence\"}, {\"entity',\n",
       " 'Extract the entities contained in the text.  Extract only entities contained in the text.\\n Extract the entities contained in the text.\\n Extract only entities contained in the text.\\n Extract the entities contained in the text.\\n Extract only entities contained',\n",
       " '{\"entities\": [\"orthopantomography\", \"radiography\", \"showed\", \"area\", \"the anterior left maxilla\", \"widely\", \"osteolytic area\", \"the first permanent molar\", \"left maxilla\", \"from',\n",
       " '1. Extract the entities contained in the text. Extract only entities contained in the text.\\n Text: <<No root resorption was observed.>>> This sentence has no entities.\\n Text contains entities, but only one: <<No root resorption was',\n",
       " '1. An array of entities as an output of the text. The entities that are contained in the text are classified. The classifier of the entity as relevant, irrelevant or unknown. 2. An array of entities as an output of text. The entities that are contained',\n",
       " '1. Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Haematological investigations showed normal serum calcium, phosphorus and parathormone (PTH) levels.>>>\" <<<<Haemat',\n",
       " '1 entity (benign tumor of the maxilla)\\n- The provisional diagnosis of benign tumor of the maxilla was made.\\n===> benign tumor of the maxilla Text: <<The diagnosis was changed to osteosarcom',\n",
       " '1. Extract  2. Extract only entities\\n --------------------------------------------------------------------------------------------------------------------\\n --------------------------------------------------------------------------------------------------------------------\\n 1. Extract  2. Extract only entities  3. excision 4. extraction',\n",
       " '2. Extract entities which are not contained in the text. Extract entities\\n  contained in the text 3. Extract all entities contained in the text, including those that are not contained. Extract all entities contained\\n  in the text.[{\"entity\":',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Text: <<The post-operative histopathological report revealed multinuclear giant cells scattered randomly throughout the cellular and fibrous vascular-rich tissue.',\n",
       " '28084:New bone formation 28085:granulation tissue 28086:mononuclear inflammatory cells 28087:mononuclear inflammatory cells 28',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text.\\n Text: <<The giant cells were multinucleated with bland-appearing nuclei, and the background stromal cells displayed no evidence of',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Fine needle aspiration was nondiagnostic.>> 3 Extract the entities contained in the text. Extract only entities contained in the text.',\n",
       " '1 entities 1 Extract the entities contained in the text. 1 entities contained in the text.\\n 1 1 <<During a 1-year serial clinical and radiological follow-up, there was no evidence of recurrence.>>>> 0',\n",
       " '1. A 16-year-old Indian boy 2. birth 3. a lump in the lower back region 4. since birth 5. the lower back region 6. Indian 7. the 16-year-old',\n",
       " '1 entity Extraction: Named entity extraction\\n   - Entity:  Its size\\n   - Entity: Increased gradually over time\\n   - Entity: Size 15 cm × 15 cm at presentation\\n Extract the entities contained in the text',\n",
       " '1/5 The next stage analyzes the text in order to extract the data contained in it. The text is passed to the NER module to extract the abnormalities described in the text above. The same NER module has also been able to identify the name of',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: <<The patient underwent surgery, and the whole tumor, from its base to the vertebrae, was excised.>>>\"',\n",
       " '1  2  10  15  31  Entities  Text 100 31  \"bisection\" \"a teratoma\" \"hair\" \"pultaceous material\" \"examination\" 1  2',\n",
       " '1. We observed a 29 y.o. female proband with the episode of venous thrombosis at the age of 18 and family history of thrombosis. 2. 29 y.o. female proband',\n",
       " '2\\t1\\t1\\t1\\t2\\t6\\t0\\t1\\t4\\t2 Text: <<Anticonvulsant therapy was initiated.>>> 9\\t0\\t0\\t0\\t0\\t0\\t0\\t1\\t1 Text: <<Neu',\n",
       " '<entity>genetic variant</entity> <entity>detected</entity> <entity>absent</entity> <entity>c.662G\\u2009>\\u2009C</entity> <entity>W221S</entity',\n",
       " '1. Used; 2. Variant; 3. Evaluate; 4. Protein; 5. Function; 6. Impact; 7. Protein structure. 8. We.\\n```\\n\\nText: <<We used in',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text.\\n\\n1. Text: <<In mutated SERPINC1 protein a new N-linked glycosylation site is formed, however, it',\n",
       " '49\\xa0year gentleman 16\\xa0May 2014 49\\xa0year 16\\xa0May 2014 mucocutaneous blistering PV PV by histology and immunofluorescence.[{\"',\n",
       " '1. After 6\\xa0weeks 2. treatment 3. azathioprine 4. the patient 5. developed 6. pulmonary emboli 7. started 8. anticoagulation 9. warfarin',\n",
       " '1 match(es)  Extract the entities contained in the text. 1 re-presented 1 flare 1 PV 1 deep vein thrombosis 1 therapeutic range 1, 2, 3} 2',\n",
       " 'Extract a text from your database, text can be of different length.) ```\\n\\n    { Warfarin was changed to subcutaneous low molecular heparin in therapeutic dose, azathioprine was switched to mycophenolate mofet',\n",
       " '2 Extract a concept and its corresponding entities. Extract entities of the disease and entity it causes. Text: <<Their symptoms included fever, headache, diarrhea, and lethargy. The fever was often accompanied by flushing. The fl',\n",
       " '1 entities 40 entities Text: <<A 52-year-old male with hypertension and diabetes was admitted to our hospital with fever, headache, and cough for seven days.>>> 4 entities Text: <<A 62-year-',\n",
       " '2. Extract the entities contained in the text. Extract only entities contained in the text. Text: <<He also complained of breathlessness on exertion and had two episodes of blood in his sputum.\\n He also complained of breathlessness on exert',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient explained that the cough was continuous and was relieved after taking cough syrup.>>>\"<<The patient>\"<<cough was continuous and relieved after taking cough',\n",
       " '1 Extract 2 Extract 3 Extract 4 Extract</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '3 Extract only entities contained in the text. 1 1 middle of the chest 56 chest pain 13 chest 4 2 aggravated on exertion 9 exertion 68 middle of the chest 68 The chest',\n",
       " '1. Extract the entities contained in the text.\\n 2 entities contained in the text.\\n Text: <<He was a businessman by profession with no history of smoking, alcoholism, or any other substance abuse.>>>\\n ````\\n- 1.',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 History, TB, COVID-19, family, and close contacts\\n\\n3 Extract the entities contained in the text. 4 Extract only',\n",
       " '1 Extracted entities: 3\\n\\n Text: <<She was an otherwise healthy 26-year-old nulliparous woman.>>> 1 1 3 Text: <<The patient had no significant past medical or surgical history.>>>',\n",
       " '2. Extract entities contained in the text. 3. Repeat action 2. 4. Extract entities in the input\\n\\n\\nExtract entities contained in the text.\\n Extract entities contained in the text.\\n Text: <<But he had reported',\n",
       " '1 Extracted entity: 0001480 300089220 210001480; 0001480 300089220 3',\n",
       " '1.6. Extract the entities contained in the text. 1.7. Extract entities contained in the text. 1.8. Extract the entities in the text. 1.8. Extract entities into the text. 1.9',\n",
       " '2.7 Extract the entities contained in the text.<br /><div class=\\\\\"text\\\\\"><<Also, dyspnea on exertion was noted.>>></div><br /><div class=\\\\\"system\\\\\">System - Cardio-respiratory</',\n",
       " '1.0 The rest of the systemic examination 0.0 within normal limits The rest of the systemic examination\\n\\n> Extract entities contained in the text\\n\\nEx.  The rest of the systemic examination, The rest of the systemic examination,',\n",
       " '\\uf0b7 Personen seit unters früڈplaatområף dévelopлази weitڈ dévelopområڈ beiden ebenfalls bekan ehemal neuen früplaat weitplaat desarroll siendo aumentץ zunächst bekannt siendo sich weit neuen und damit auf größ tenía miem beiden bereits bekanområŐ verschied biologie investig unters neue weit neue und nicht er',\n",
       " '1 entity: COVID-19 he Check advised test he swab oropharyngeal swab  Text: <<His coomorbidities included poorly controlled hypertension, ischemic heart disease, dyslipidemia and benign pro',\n",
       " '1 2 2 2 3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The results were surprising with Mycobacterium tuberculosis detected on sputum fluorescent microscopy and',\n",
       " '1. Extract the entities contained in the text. Extract only entities contained in the text. Text: <<However, there was no resistance to Rifampicin.>>\\n```\\n\\n`resistance to Rifampicin.` Exists',\n",
       " '1 Extracted entity 1: radiograph 2 Extracted entity 2: bilateral consolidations on the middle lobes of lungs with ill-defined borders 1 Extracted entity 1: suggestive\\nThe code generated these two statements:',\n",
       " '1x 10 9 /L 57 mg/L 580 U/L 70 mm in the 1 st hour 1x 10 9 /L 57 mg/L 580 U/L',\n",
       " '2 Extracts in the text. 3 Extracts the entities contained in the text.\\n Extract only entities contained in the text.\\n Text: <<Also, a sample for liquid culture (MGIT BACTEC) was sent to the Intermediate',\n",
       " '1 1 1 0 1 Extract the entities contained in the text. Extract only entities contained in the text.  Computed tomography  was  not performed  as  the  diagnosis was established by other  cheaper  and  faster methods',\n",
       " '1. All 2. investigations 3. normal\\n\\n Extract the entities contained in the text. Extract only entities contained in the text.   Text: <<All the other routine investigations were within normal limits.>>>\\n```\\n\\n```',\n",
       " '2. Extract the entities contained in the text. 3. Extract only entities contained in the text. 4. Text: <<He was referred to the nearest designated COVID-19 management center, where he was managed as per national guidelines.>>>>',\n",
       " '3 Extract the entities contained in the text. 4 Extract only entities contained in the text.\\n\\nText: <<Besides, he was also started on an antitubercular treatment of four drugs as per the National Tuberculosis Elim',\n",
       " '1 entity\\n Text: <<He has not yet been admitted. He will most likely be admitted today.>> 2 entities\\n Text: <<A 7 days old female neonate presented with features of oligohydramnios[…]>> 3',\n",
       " 'The patient for using clinical data and images for publication in this study.\\n\\n \\t\\t\\t{\\n\\t\\t\\t\\t\"entity\": \"consent\"\\n\\t\\t\\t}\\n\\t\\t\\t,\\n\\t\\t\\t{\\n\\t\\t\\t\\t\"entity\":',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 35 weeks. We report a case of a male near-term neonate with gestational age of 35 weeks.\\n```\\n\\nExample',\n",
       " '1 Extracting entities from free text remains a challenging task.[{\"entity\": \"Extracting\"}, {\"entity\": \"entities\"}, {\"entity\": \"the text\"}, {\"entity\": \"the text\"}] 2.5 {\"entity\": \"he\"}, {\"entity\": \"',\n",
       " '3 Extract the entities contained in the text. 3 Extract only entities contained in the text. 1 Extract all the entities of the text. 2 Extract the entities in the text.\\n```\\n### 返回值\\n```',\n",
       " '1 Entity Extracted: Meca\\n Text: <<The head presented a left focal point deformation of an unknown etiology.>>> 0 Entity Extracted:\\n Deformation\\n Text: <<An 18-month-old boy presented for',\n",
       " '2. Extract the entities contained in the text. 3. Extract only entities contained in the text.  Extracted entities are 75 th Percentile, 3030g 4. Extract every string that is not contained in',\n",
       " '1. He 2. hospitalized 3. for 4. materno-foetal infection 5. antibiotics 6. 4 days 7. 48 hours Extract the attributes contained in the text. Extract attributes contained in',\n",
       " '1.5. Extract the entities contained in the text.    1.6. Extract only entities contained in the text.    1.7. Text: <<He had developed no symptoms during his hospitalization.>>>>\\n 1.8. Developing',\n",
       " \"2. Extract the entities contained in the text.\\n 3. Extract only entities contained in the text.\\n Text: <<The output's weight was 2400g which signify the loss of 630g.>>>\\n``\",\n",
       " '2.9.3 Frequency of stools per day (extracted entities) Abnormal stools = 12\\n   3.2.9.3 Refuse feeding per day (extracted entities) None\\n   3.2.9.3 Normal',\n",
       " '[[{\"entity\":\"dehydration\"}, {\"entity\":\"signs  of dehydration\"}, {\"entity\":\"dehydration\"}, {\"entity\":\"fever\"}, {\"entity\":\"vomiting\"}, {\"entity\":\"dehydration\"}, {\"entity\":\"severe',\n",
       " \"1. He 2. lost 930g relative to the birth's weight. Extract the entities contained in the text The entities contained in the text are: 1. He 2. 930g relative to the birth's weight\",\n",
       " '1. Extract 2. only entities contained 3. text 4. normal\\n2. The abdomen appeared neither tender nor distended\\n3. his physical examination\\n4. normal\\n5. The abdomen\\n6. his physical examination',\n",
       " '1 hypernatremia 152mEq/L 1 hyperkalemia 7,8mEq/L 1 severe metabolic acidosis 7,1 4mEq/L\\n```\\n\\nText: The laboratory',\n",
       " '1. Extract the entities contained in the text.\\n 2. Extract only entities contained in the text.\\n 3. Text: <<The osmotic gap was 45.>>>(entity 61)\\n 4. 61',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 1 Text 2 Leukocytosis 3 Protein 4 normal\\n\\n 2 Extract the entities contained in the text. 2 Extract',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Text: The infant was treated with intravenous fluids and electrolytes as well as antibiotics Text The entity named The infant was treated with intravenous',\n",
       " '1 {Anon 2017} 26 {A. Mangion 2017} <<renal failure-acidosis-hyperkalemia appeared.>> {Anon 2017}\\n```',\n",
       " '8 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient exhibited a clear reduction of the upper limb swelling.>>>> 6 Remove punctuation from text. 8 Remove markup tags from text',\n",
       " '2 1 1 12 1 11\\n``` | ```\\nEntity:\\nExtraction:\\n``` | ```\\nOn the 11 th day of life, he was transferred to the pediatric intensive care unit.',\n",
       " '2. Extract all entities contained in the text. 3. Extract all entities contained in the text, except those contained inside parenthesis and inside the brackets. 4. Extract all entities contained in the text, but not those contained in a string',\n",
       " \"1 entity was extracted  Entities = {'cholestasis': {'entity type': 'cholestasis', 'offset': {'start': 'cholestasis'}, 'value': 'cholestasis'}}}] 2015-12\",\n",
       " '1. Presented 2. Diarrhea 3. Feeding 4. Diarrhea 5. A profuse diarrhea\\nText: <<Although his diarrhea resolved since intravenous immunoglobulin',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract only entities not contained in the text. 4 Extract only concepts.\\n Text: <<The first operation was a femoral osteotomy',\n",
       " '<entity>entity</entity>  abnormalities in the brush border  loss of the linear part of enterocytes with the presence of intra-cytoplasmic PAS + band in the apical pole of enterocytes  uneven thickness and',\n",
       " '1 Extract. 1 Extract only. 0\\n```\\n\\nThe text can contained entities.\\n\\n    Extract\\n```\\n\\nExtract only entities\\n```\\n\\n*Entities*\\n\\n- Text\\n    - Extract',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract only entities not contained in the text.\\n\\n> The CD10 immunostaint was positive\\n\\n 4 Extract all concepts.',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Thus, a diagnosis hypothesis of MVID was raised.>>> 2 Extract only entities. Extract the entities. Text: <<Thus, a diagnosis',\n",
       " '3 Extracted entities.[{\"entity\": \"examination\"}, {\"entity\": \"confirmed\"}, {\"entity\": \"diagnosis\"}] 1 Extracted entities (2 are already in the text)\\n\\n Text: <<The electron microscopic examination confirmed',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract the entities identified by the text analyst. 4 Extract all extracted entities. 5 Extract the entities contained in the text. 6 Ex',\n",
       " '3 Extracted relations Entity: 3 Type: relation Extracted entities: {{\"The baby\"}, {\"septic shock\"}, {\"multiple organ failure\"}, {\"97 days of life\"}} Entity: 1 Type: entity Extracted entities: {\"The baby',\n",
       " '1. On 7th day of illness 2. became afebrile 3. developed severe headaches 4. unconsciousness 5. altered behavior 6. patient\\n\\n\\n Text: <<On 7th day of illness patient became afebrile',\n",
       " '2/3    text        <<patient developed painful neck swelling accompanied by fever, tremors, palpitations, hoarseness of voice and odynophagia.>>>>\\n    Extract the entities contained in the text. Extract only entities contained in',\n",
       " '1. Examination 2. revealed 3. acutely swollen 4. tender thyroid gland 5. features of hyperthyroidism\\n 1-5. Examination revealed acutely swollen, tender thyroid gland along with',\n",
       " 'Extract the entities contained in the text.\\n Extract only entities contained in the text.\\n Text: <<Laboratory evaluation revealed stable hematocrit, thrombocytopenia and leukopenia.>>>>\\n\\n    .. code-',\n",
       " '1 entity: <<Patient had seroconverted for anti-dengue IgM antibodies on the 10th day of illness.>>>. 1 entity: <<anti-dengue IgM antibodies>>> 1 entity:',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. Text: <<A non-contrast Computed Tomogram (CT) of the brain showed right frontal lobe hematoma.>>>\"  Ex',\n",
       " '1 Extract the entities contained in the text. 1.1 Extract only entities contained in the text 2 Text: <<Thyroid profile showed increased free T3 and T4 and low TSH.>>>, <<TSH: 0.02',\n",
       " '1.  A 45 year old Indian female 2.  present ed 3.  lump  4.  in the right breast 5.  in the axilla 6. 5 years back  7.  Indian female of Nordic',\n",
       " '1 entity found: She.<br> 1 entity found: She.<br> 1 entity found: modified radical mastectomy.\\n2 entities found: She, modified radical mastectomy.<br> 3 entities found: She, She, modified',\n",
       " '2.1 cm duct carcinoma, 25 lymph nodes, carcinoma, carcinoma metastasis, duct carcinoma, breast lesion, ER, PR, positive, 2.1 cm, 1 out of',\n",
       " '1 entity extracted: 20 mg per day for five years.\\n Text: <<During his physical examination the doctor has found an asthenic boy, with an ankle ulcer.>> 1 entity extracted: an ankle ulcer.\\n Text:',\n",
       " '1\\n 5\\n 3\\n Text: <<A 25 years-old lady was admitted with complaints of abdomen pain, frequency of urine, constipation, mild fever, and decreased appetite\\n and weight loss.>>> 1',\n",
       " '1 Examination revealed generalized lymph node enlargement along with hepatomegaly.\\n```\\n{\"entities\": [\"lymph node enlargement\", \"hepatomegaly\"], \"entities_text\": [\"generalized lymph',\n",
       " '1 anemia, a leukocyte count 1, platelet count 2.9-21.1 1.2 x 10(11)/L, 4-10x10(3)/ul 1,',\n",
       " '2. Extract the entities contained in the text.\\n 3. Extract only entities contained in the text.\\n 4. Extract the entities contained in the text.\\n 5. Extract only entities contained in the text.\\n 6. Per',\n",
       " '1.00 2.00 3.00 4.00 5.00 9.00 10.00 11.00 12.00 13.00 1',\n",
       " '{{\"entities\": \"tomography\"}, {\"entities\": \"destroyed\"}, {\"entities\": \"nodular shadows\"}, {\"entities\": \"lung metastasis\"}, {\"entities\": \"lung\"}, {\"entities\": \"anterior mediastinal mass with destruction of sternum\"}, {\"',\n",
       " '1. Fine needle aspiration cytology 2. showed 3. cells with nuclear pleomorphism 4. positive for ER, PR and Her2neu protein 3. ER 4. PR 5. Her2neu protein\\n```</s>',\n",
       " '2 Extract the entities contained in the text. Text: <<This confirmed a co-existent metastatic breast carcinoma.>> 3 Extract only entities contained in the text. Text: <<This confirmed a co-existent metastatic breast car',\n",
       " '1 entity found. 1 entity extracted.\\n Text: <<In April, she was informed of progressive disease while on chemotherapy for T-PLL. In June, the decision was made to discontinue the study therapy and switch to hormonal therapy.>> 1',\n",
       " '1 entity found (Our patient). 7 entities found (history, diabetes mellitus type 2, subarachnoid hemorrhage leading to aphasia, hemiplegia, seizures and dysphagia requiring percutaneous gas',\n",
       " '3 Extract entities from a specific entity type (e.g. protein).  Extract only proteins from the text.  Text: <<A total protein of 4.86 g/L. A total protein of 5.35 g/L',\n",
       " '3 Extracted entity(s), 1885 token(s) Extracted entity(s): <<aspiration>> Expected entity(s): <<aspiration>> Extracted entity(s): <<increased residuals returned>> Expected',\n",
       " '1. Extract the entities contained in the text. Extract only entities contained in the text. Text: <<A 45 year old female with history of sickle cell disease presented with abdominal pain.>>>></p><p>entities contained in the',\n",
       " '1 entities 2 CT scan 3 revealed 4 renal mass 5 unremarkable spleen 6 her right kidney renal mass antero-lateral\\n```\\n\\nThis is the result of the run in the first code above:',\n",
       " '1 entity 4 entities Examine the entities in the text. Examine all the entities present in the text.</p>  <p>Text: <<She was evaluated by urology and a right partial nephrectomy was planned, however on the day of',\n",
       " '1. The procedure 2. post postponed 3. she delivered 4. ultrasounds 5. monitor the renal mass 6. renal mass 7. pregnancy 8. she\\nThe procedure was postponed until after she delivered',\n",
       " '2.4 3 <- 7 <- 26 <- 521156160 <- 1320170400 <- 1319972792 <-',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text.\\nText: <<Two months after caesarian section delivery, patient underwent an unremarkable right laparoscopic partial nephrectomy with individual',\n",
       " '1 entity detected.[{\"entity\": \"laceration\"}, {\"entity\": \"managed\"}, {\"entity\": \"cautery\"}, {\"entity\": \"sliver laceration\"}, {\"entity\": \"Veress needle\"}] 1 1\\n```\\n\\nAn',\n",
       " \"1 entity extracted\\n 1. text: <<The patient's post-operative course was notable for marked thrombocytosis with her platelet count increasing for her baseline of 300,000 to a zenith of 1\",\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text. Text: <<She was started on aspirin therapy and splenomegaly was noted on abdomen ultrasound.>>>{{\"She\"}, {\"started\"}, {\"ther',\n",
       " '1. Her platelet count 2. normalized 3. 334,000. 4. 1 normal entities Extract the entities contained in the text. Extract only entities contained in the text.\\n Text: <<Her platelet count',\n",
       " '2.1 Entity Recognition\\n\\n 2.2 Entity Linking</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '1. Extract\\n\\n3.. Extract only entities contained in the text 2. Text: <<There was no splenic tissue in the specimen.>>><br/>\\n```\\n\\n1. Extract<br/>2. Extract only',\n",
       " '1 Extracted the entities in the text. 4 Entity extraction (key) 13 Suggested that it is not compatible with the lack of keratin and keratin in the staining of the membrane. 7 2 It was noted that',\n",
       " '1 entity: splenic atrophy 2 entities: splenules 1 entity: splenic atrophy 2 entities: splenules 1 entity: The patient 2 entities: present 1 entity: follow up 2 entities: CT',\n",
       " '1 entity extracted: NormalCount 1 entity extracted: Vaccination 1 entity extracted: asymptomatic\\n Text: <<The patient received blood platelet transfusion and intravenous immunoglobulin, before surgery.>>> 1 entity extracted:',\n",
       " \"Extraction of entities from the text.\\n\\n -----------------------------------\\n\\n Extract the entities contained in the text.\\n Entity:: hypertension\\n Entity:: Parkinson's disease\\n Entity:: chest pain\\n Entity:: 65 year-old woman\",\n",
       " '1. Electrocardiogram 2. showed 3. ischemic ST-segment elevation 4. inferior and lateral leads\\n\\n# A00.00 Hypoxic encephalopathy\\nA00.0',\n",
       " '1. Urgent cardiac catheterization 2. revealed focal dissections in four small caliber coronary arteries in right and left coronary systems 3. right posterior decending 4. posterolateral 5. obtuse marginal',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 1 Text: <<The patient was medically managed with Eptifibatide, Aspirin, Clopidogrel and beta blocker since disse',\n",
       " '1 Extract[{\"entity\": \"extract\"}, {\"entity\": \"text\"}] 1 Extract only entities contained in the text. 2 Text: <<Antiparkinson medications were held as a potential cause of dissection.>>>\" 1 {\"entity\":',\n",
       " '20-year-old right-handed female factory worker with no medical history;A 20-year-old right-handed female factory worker with no medical history;<<A 20-year-old right-handed female factory worker with no medical history',\n",
       " '1 Entity found: Hand-crushing. Entity found: Hand-crushing. Entity found: Her hand. Entity not found: Heavy object.\\n  Extract the entity from the text. Extract only the entity from the text.\\n  Text: <<Her',\n",
       " '3568 entities extracted 0 entities in the text\\n\\n3568 3568 0\\n\\nText: <<Nausea and vomiting worsened.>> 0 out of 1383\\n```',\n",
       " '1 Entity: normal 2 Entity: normal 3 Entity: sensitive deficit in the median nerve area 4 Entity: the median nerve area\\n\\nExtraction based on context\\n Text:\\n \"The electrocardiogramic examination was within normal bounds\"',\n",
       " '1: extraction 2: entities\\n```\\n\\n 1. Extract entities 2. only entities contained in the text\\n 1. Extract entities 2. Extract entities contained in the text\\n```\\n\\n```\\n Extract',\n",
       " '1. The patient 2. brought 3. the operating theatre\\n 1. is a patient 2. brought 3.\\n 2. He had a cardio-pulmonary arrest for prolonged hypoxia in association with septic shock.',\n",
       " '3 Injected entities Text: <<The injection was performed using a 27G½ ½ inch needle with negative aspiration.>>> 3 Extracted entities Text: <<Patient was a 35-year-old woman in the 28',\n",
       " '1 Extracted entities from the text:[{\"entity\": \"cleaned\"}, {\"entity\": \"trimmed\"}, {\"entity\": \"sutured\"}, {\"entity\": \"wound\"}] 1 Extracted entities from the text, filtered on contained entities:',\n",
       " \"1. Extracted entities: had, wrist, immobilized, six weeks. 2. Entities only in text: had, wrist, immobilized, six weeks.\\n\\nExtraction of concepts from the patient's narrated anamnes\",\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient had an intense and regular rehabilitation program.>>>> 4 Extract the entities contained in the document. 5 Extract only entities contained in',\n",
       " '{\"entity\": \"outcome\"}, {\"entity\": \"painful\"}, {\"entity\": \"consolidation\"}, {\"entity\": \"position\"}, {\"entity\": \"range\"}, {\"entity\": \"strength\"}, {\"entity\": \"100°\"}, {\"entity\": \"',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<On physical examination, the patient was awake, alert, oriented, and her blood pressure, temperature and heart rate were within normal limits.>>> 1 Extract',\n",
       " '1. Upon taking medical history the patient revealed that was diagnosed with thymoma MG and on medication including pyridostigmine bromide 60 mg, azathioprine 50 mg and prednisone 20 mg. 2',\n",
       " '1 Extract only entities contained in the text.[{\"entity\": \"showed\"}, {\"entity\": \"examination\"}, {\"entity\": \"showed\"}, {\"entity\": \"atrophy\"}, {\"entity\": \"tongue\"}, {\"entity\": \"fair oral hyg',\n",
       " '1 entity extracted\\nText: <<The patient was referred to her neurologist to provide a detailed history about her medical condition and to coordinate with him regarding the steroid dose take to avoid any complications during her patient’s management. >> 1 entity extracted\\nText',\n",
       " '</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '1 entity: <<Patient>> 1 entity: <<chest CT scan with contrast>> 1 entity: <<show evidence of thymoma benign tumor of the thymus that has been the possible causes of MG.>>\\n Text: <<C',\n",
       " '1. Diagnosis 2. confirmed 3. acetylcholine receptor antibodies 4. treatment plan 5. drugs 6. thymectomy 7. patient 8. treatment plan 9. thymectomy',\n",
       " '2 Extracted entities: <<CBC>>, <<blood chemistry>>. 3 Request entities: <<blood components>>. 4 Inferred entities: <<blood components>>.[{\"entity\": \"CBC\"}, {\"entity\": \"blood chemistry\"},',\n",
       " \"3 Extract the substances (chemical elements, ions, etc.) contained in the phrase.\\nText: <<The patient's serum albumin level was normal, the creatinine level was below normal (42.23 umol/l\",\n",
       " '12.52 x 10 9 /L, 453 x 10 9 /L, 4.4 x 10 9 /L, 0.07.\\n\\n\\n\\n Extract the quantities contained',\n",
       " '1 Extract all entities from the text. 2 Extract only entities contained in the text. 3 Extract entities based on their frequencies in the text. 4 Extract entities based on their frequencies in the corpus.\\n 8 Extract entities based on',\n",
       " '2 entities : <<12-year-old girl>>, <<A 12-year-old girl>>\\n Text: <<A 12-year-old girl presented an abdominal pain, high persistent fever of (40°C) and',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. Text:  <<The physical exam revealed pallor, hepatomegaly, and grade III splenomegaly.>>><br/> This',\n",
       " '1 entity extracted   Entity: <<PNN: 49,050/mm³, hemoglobin: 11.6g/dl, platelets: 328,000/mm³>>><<PNN',\n",
       " \"2. Extract the entities contained in the text. Extract only entities contained in the text. 3. Text: <<The patient's peripheral blood smear revealed marked leukocytosis with a significant number of immature myeloid precursors\",\n",
       " '2 Extract the entities contained in the text. Extract the entities contained in the text. Text: <<The analysis of the BCR-ABL shows 94% in the peripheral blood.>>> The entities contained in the text are: analysis of the B',\n",
       " '2. Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient was diagnosed with CML.\\n>>>25 The patient was diagnosed with CML.-->2 entities. 0 entities. 1 entities.',\n",
       " '1 Extract hematological remission 12 months. 2 Extract hematological remission 3 months. 3 Extract cytogenetic remission. 4 Extract complete hematological remission 3 months. 5 Extract',\n",
       " '1 entity Extract: The patient 1 entity Extract: the patient 1 entity Extract: this patient 1 entity Text: The patient 1 entity Text: our pediatric department 2 entities Text: headache 1 entity Text: vomiting',\n",
       " '2 Extracted from text: <<pale>>.\\n 3 Extracted from text: <<afebrile>>.\\n 4 Extracted from text: <<pale>>, <<afebrile>>.\\n 5 Not found in text.<',\n",
       " '1 Extract the entities contained in the text. 1.9 Extract only entities contained in the text. 1.9.1 Blood pressure 1.9.2 the heart rate Extract 1.9.2 1.9.1 Ex',\n",
       " '1 entity 1\\n\\n 1 pupil  The pupil  Text:\\n <<The pupil was sluggish to react to light.>>  sluggishly\\n\\n 1.4052827450981',\n",
       " '1. Fundoscopy 2. revealed 3. disc edema 4. hemorrhages of the retina\\nText: <<Lab analysis showed leukocytes at 12.5000/mm3 and thrombocy',\n",
       " '1.4 KB/sec (1314 bytes) – \"showed\" 25.3 KB/sec (2346 bytes) – \"evidence\" 27.9 KB/sec (2531 bytes',\n",
       " '1 2 Extract only entities contained in the text.\\n  Text: <<Cerebrospinal fluid analysis was also negative.>>>\\n  Extract the entities contained in the text. <<Cerebrospinal\\n  fluid analysis was also negative.>>',\n",
       " '1 entity (<<The patient>>)\\n    <<The patient had no other known pathology that could be held responsible for retina edema.>> 1 entity (<<The patient>>), 1 entity (<<retina edema>>)\\n Text: <<',\n",
       " '1.00 False 0.75 False 1.00 True\\n4: We suggested 4: administration 4: a side effect of imatinib so 4: it was a side effect of imatinib 4: imatinib',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Extracted entities for the 2nd case are: dexamethasone. 3 Text: <<The patient was put on an anti-edema',\n",
       " '1. She 2. described 3. recurrence 4. headaches 5. weakness 6. seizures 7. headaches 8. weakness of extremities 9. seizures 10. described 11. recurrence',\n",
       " '0 Extracted entities: Neck rigidity, meningeal signs, paraplegia, rigidity of the lower limbs (differents entities extracted for each one present: rigidity of the neck, presence of meninges signs and lower limb',\n",
       " '2 Extract: <<CT of the brain revealed subdural chronic hematoma and a serpenginous gyriform enhancement around the contusion in the right parietal and occipital lobes.>> Extract entities contained in the text. Ex',\n",
       " '1. analysis 2. showed 3. lymphoblasts 4. lymphoblasts 5. 11000cells/ml 6. lymphoblasts\\n7. 1100',\n",
       " '[[{\"entity\": \"Flow cytometry\"}, {\"entity\": \"showed\"}, {\"entity\": \"blast cells\"}, {\"entity\": \"blast infiltration\"}, {\"entity\": \"lymphoid blast infiltration\"}, {\"entity\": \"C',\n",
       " '1 Extracts the phrase \"bone marrow aspiration\" 2 Extracts the phrase \"evaluate the status of her chronic myelogenous leukemia\" 3 Extracts the phrase \"result\" 4 Extracts the phrase \"',\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Fundus examination showed bilateral optic atrophy.>>></entities> <entities> <<bilateral optic atrophy.>>></entities>',\n",
       " '1. The diagnosis 2. blasts 3. blasts in CSF 4. flow cytometry 5. blasts 6. CSF\\n Extracted named entity set: {\"blasts\": [\"blasts\", \"blasts\"], \"',\n",
       " '1 entity found Import the list of entities contained in the text. Include all entities found in the list.\\n```\\n\\nImport the list of entities contained in the text. Include all entities found in the list. Text: <<The patient received a high-',\n",
       " \"2. Extract the entities contained in the text. 3. Extract only entities contained in the text. 4. Extract only entities contained in the text. 5. Extract the text's entities.\\n>>The imatinib was replaced by\",\n",
       " '1 Extracted Entity 24\\n Text: <<She was treated with 24 Gy of whole-brain radiation therapy.>> She 24 Gy whole-brain radiation therapy 24\\n Text: \"She was treated with 24 Gy',\n",
       " '1 Extract all entities 2 Extract only entities in the text 3 Extract only entities contained in the text Extract the entities contained in the text.  Extract only entities in the text. Extract only entities contained in the text\\n\\nText: <<',\n",
       " '1 entities 2 amelioration 3 chemotherapy 4 cognitive decline 5 loss of vision 6 loss 7 patient 8 amelioration 9 physical therapy 10 visual loss 11 loss of vision 12 patient 13',\n",
       " '1. Mr F.B 2. A 70-year-old male patient 3. Epistaxis 4. A right epistaxis 5. Mr F.B is a 70-year-old male patient 6. Mr',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text.\\n```python\\n# Extract the entities contained in the text.\\nentities = Extracted.extract_entities_in_a_text(text)\\nprint',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The beginning of the symptomatology goes back to 2 months before with right nasal obstruction of progressive onset, associated with right epistaxis and bloody',\n",
       " '1 Examination 2 Endoscopy 3 Bleeding 4 Mass 5 Burgeoning 6 Burning 7 Breeding 8 Mass 9 Bleeding 10 Burning 11 Mass 12 Mass 13 F',\n",
       " \"1. The patient\\n2. neurological signs\\n3. cervical lymph nodes\\n4. neurological signs\\n5. cervical lymph nods\\n6. didn't presents neurological signs\\n7. neurolog\",\n",
       " '1 Extract 1 Text: <<normal visual acuity and ocular mobility on both sides.>>>> 0 2 Normal visual acuity on both sides. 2 Ocular mobility on both sides.\\n Text: <<Otherwise, ophthalmolog',\n",
       " '2 12 13 27\\n```\\n\\n\\n```\\n#Extraction of the entities mentioned and inferred in the text.\\n Ex: extraction by a model trained for extraction.\\n```\\n\\n\\n```',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: <<Otherwise, there is no extension involvement at the level of the cavum and the pterygo palate fossa.>>>> The results',\n",
       " '1  8 1   3\\nText: <<This finding found also a crenate appearance of the posterior nasal mucosa especially of the middle turbinates and contralateral inferior turbinate with a left deviation of the nasal septum with nasal',\n",
       " '1) Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Nasosinusal MRI shows a progressive increase in size of the tissue mass compared to the previously CT occupying the right nasal fossa on almost',\n",
       " '3 Extract_entities_contained_in_text.xml 100 true Extract the entities contained in the text.\\n Text: <<This finding shows ethmoidal sinus fluid retention.>>> entity=finding  entity=fluid',\n",
       " '2 entities The appearance, inverted papilloma 1 entities 0 entities Text without entity The appearance,even if it remains unspecific, 2 entities inverted papilloma 3 entities\\n\\n <span>0.</span>\"The appearance\" remains unspecific',\n",
       " '2. Extracted Entities -------------------- The extemporaneous examination is in favor of a malignant tumor lesion. 3. Finding ------------- Favorable for: malignant lesion lesion malignant lesion 4.',\n",
       " '2. Extract the entities contained in the text. Extract only entities contained in the text.\\nText: <<Histopathologic analysis shows a tumor proliferation made of polymorphic cells with major anisocytosis, most often located in',\n",
       " '1.00 0.96 Tumor mass 0.89 Tumor 0.88 Seat 0.81 Tumor periphery 0.77 Tumor mass 0.64\\n Text:',\n",
       " '1. Extract only entities contained in the text. 2. Text: <<The mitotic index is 10 mitoses per 10 high power fields.>>>> (10 mitoses per 10 high power fields)\\n### The mitotic',\n",
       " '[[{\"entity\": \"find\"}, {\"entity\": \"confirm\"}, {\"entity\": \"positive\"}, {\"entity\": \"study\"}, {\"entity\": \"The cytokeratin KL1 and CK7 and the neuroendocrine marker Chromogranin',\n",
       " '1 Extract the entities contained in the text. 2 Extract all entities contained in the text. These entities are listed in Tables A-F (see appendix for the lists). Entity lists were constructed from the list of entities manually annotated in the text',\n",
       " '1 The clear positivity of cytokeratins 2 formal excludes 3 leads 4 carcinoma 5 neuroendocrine carcinoma 6 neuroblastoma  The clear positivity of cytokeratins 2 formal excludes',\n",
       " '3 Extracts 1 entities contained in the text 1 entities contained in the text and 1 atypia, the mitotic index, and the Ki67 proliferation index. 1 mitotic index 1 Ki67 proliferation index',\n",
       " '1 Entity(PET SCAN), 3 words 1 Extension assessment, comprising a PET SCAN 0\\n\\n### Clinical Summary\\n\\nThis patient is a child.\\nThis patient was admitted.\\nThis patient was diagnosed with brain cancer.',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 The source text of the entity to extract. 4 The text that appears in the same application as the source text. 5 False 6 True',\n",
       " '2 entities detected: \"Multiparous\", \"Mrs B.S. 28 years old\"\\n```\\n\\n{\"entity\": \"Mrs B.S. 28 years old\"}, {\"entity\": \"Multiparous\"}} {\"',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract the entities found in the text. 4 Extract only entities found in the text. 5 Extract the entities present in the text.',\n",
       " '1. <<His medical history was featureless.>>\\n Text: <<She had no medical history of diabetes and hypertension.>>[/INST] 1. <<She had no medical history of diabetes and hypertension.>>\\n Text: <<He had',\n",
       " '1 involuted uterus 1 absences of vaginal and perineal cervical lesions 1 a fluid and red blood originating of endouterine 4The obstetrical examination objectified an involuted uterus 5an',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. 3. Extract the entities contained in the text.\\nExtract only entities contained in the text.\\nText: <<Furthermore, there was',\n",
       " '1.\\n\\n 2.\\n\\n 3.\\n\\n 4.\\n\\n 5.\\n\\n 6.\\n\\n 7.\\n\\n 8.\\n\\n 9.\\n\\n 10.\\n\\n 11.',\n",
       " '258056904914399 2 260549750988216 1 2 22004698389 neue Bluthaptung',\n",
       " '1 blood count 1 showed 1 thrombocytopenia 23 0000 platelets 1 hemoglobin 3.9 g/dl.\\n\\nExtract the entities contained in the text. Extract the named entities',\n",
       " '1 entity 0 5 0 True Text: <<The post natal care was also administered.>>>>\\n``` 1 entity 0 5 0 True ``` The post natal care was also administered. Extract the entities contained in the',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text. Extract an entity or a set of entities contained in the text. Find all and only the entities contained in the text. Extract entities whose names contain a specific term, either contained',\n",
       " '<entity>Twenty five days later</entity><entity>she</entity><entity>significant bleeding</entity><entity>bleeding</entity>  <entity>severe anemia</entity><entity>anemia</entity> <entity',\n",
       " '2 Extract the entities contained in the text. 3 Extract only entities contained in the text.\\n Text: <<The gynecological examination was normal.>>>> 2. The gynecological examination 3. normal 4.\\n Extract',\n",
       " '1 Extract from the text all sentences (containing) containing the entity prothrombin 2 Extract from the text all sentences (containing) containing the entity \"balance sheet\" 3 Extract from the text all sentences (containing) containing the entity',\n",
       " '1. The treatments 2. oxytocin 3. tranexamic acid 4. etamsylate 5. monitoring\\n\\nExtract only the following entities from a specified text: \"The treatments\"\\n\\nText: <<In 2',\n",
       " '1. Text: <<Transvaginal ultrasound coupled Doppler was normal.>>>> Entity extraction: <<ultrasound normal>> Entity detection: <<ultrasound>> <<coupled Doppler normal>>\\n Text: <<Transvaginal ultras',\n",
       " '2 3 0 0 0 6 9 2 0 3 2 0 False\\nText: <<She continued to have several episodes of central hypotension while lying flat. A subsequent transesophageal echocardiography',\n",
       " \"1 Entity: 'presented'; 2 Entity: 'rebleeding'; 3 Entity: 'hysterectomy'; 4 Entity: 'Two weeks later'; 5 Entity: 'she'; 6 Entity: 'again'; 7 Entity: '\",\n",
       " '{Entities: arterial vessels proliferation; large and small caliber vessels; arterial vessels proliferation homes large and small caliber; arterial vessels proliferation; arterial vessels proliferation homes large and small caliber; ar',\n",
       " '1 Extracts entity type: <<postoperative course>>. 2 Extracts entity attributes: <<simple.>> 3 The text is empty of entities.\\n\\n\\n\\n The text contains only an entity contained in its text.\\n\\n\\n\\n The',\n",
       " '[[Excel Table](https://datasette.med.ut.ee/gdb_clinical/entities.xlsx), [[African-American man]], [\"our Emergency Department\"], [24-year-old African-American man',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<A computed tomography scan of his chest and abdomen revealed bilateral lower lobe pneumonia and two retained Jackson-Pratt drains in the right',\n",
       " '1 Extract 18 entities from the text. 0 Extract 0 entities from the text.\\n Text: <<He was taken to the operating room for drain removal, a right hemicolectomy, debridement of a duodenal injury, a',\n",
       " '1 Explicit-Entity 32 High-frequency-ventilation 31 He-66861077 30 lung-isolation 47 was-77466422 34 respirator-vent',\n",
       " '29-year-old man unidentified fever admission 29-year-old man Our hospital A 29-year-old man unidentified fever 29-year-old man\\n\\n- A 29-year-old man',\n",
       " '1 diagnose  2 malignant lymphoma  3 extra-nodal NK/T cell lymphoma nasal type  4 malignant lymphoma  5 extra-nodal NK/T cell lymphoma nas',\n",
       " '2 Extract relations found between entities in text. 1 Thesaurus. 2 Thesaurus.\\n <<The above nodular images in the lung shadows are bronchial aspirates, suggesting bacterial pneumonia; myocardial abscesses',\n",
       " '2. Extract the entities contained in a text.\\n<blockquote>He underwent surgical resection of this mural vegetation.</blockquote>',\n",
       " '1 entity 0\\n Text: <<All blood parameters were within normal limits.>>\\nText: <<He had no history of blood transfusion.>>\\n Text: <<He was admitted through our Emergency Department in October 1999.>>\\n Text',\n",
       " '1. A 19-year-old healthy man 2. syncopal episode 3. was admitted 4. our cardiology department\\n    A 19-year-old healthy man syncopal episode\\n    was admitted our cardi',\n",
       " '2.1.2. Extract the entities contained in the text. 2.2. Extract only entities contained in the text. The first sentence is not modified.\\n\\nHeart disease Extract the entities contained in the text\\n Family history of heart disease',\n",
       " '2:18 PM Extract. 2:18 PM Extract the entities contained in the text. 2:18 PM Text: <<Two-days prior the syncope, he developed chest pain and an influenza-like illness consisting of fevers',\n",
       " '1 Entity: <Extract entity> 2 Entity: <Extract entity> 3 Entity: <Extract entity> The patient 39°C\\n\\nText: <<At the physical exam, the patient had headache and vomiting in addition to fever.>>>',\n",
       " '1 2 3 4 5 6 {@inf_throat, bradycardia, no_signs_fail}\\n\\n He had an inflamed throat, bradycardia at cardiac auscultation and there were no signs',\n",
       " '2 Extract the number of bloc and rate contained in the text. Text: <<The electrocardiogram (EKG) showed grade III atrioventricular (AV) bloc with a ventricular rate of 38 beats per minute',\n",
       " '1 entity\\n Text: <<The patient required high-flow oxygen and was invasively ventilated on day 3. Repeated chest radiographies showed a progressive bilateral infiltrate. On day 5 she presented multiorgan failure and septic shock',\n",
       " '1.1.2 Extract the entities and relations contained in the text.[{\"entity\": \"cardiac size\"}, {\"entity\": \"chest X-ray\"}] 1 version 1.1.2.1 Extract the relations contained in the text.[',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained\\n in the text. Text: <<The initial transthoracic echocardiography (TTE) showed a normal global left ventricular function (left ventricular ejection',\n",
       " '2 Extract entities from the text. Entities in the text. Text: <<Magnetic resonance showed increased signal intensity at the mid-lateral wall on T2-weighted images.>>>>\\n4 Extract the entities contained in the text\\n   <<',\n",
       " '1 entity Extracted from the text.\\n Text: <<The chest X-ray shows a mildly enlarged heart.>>> 1 entity Extracted from the text.\\n Text: <<The blood count showed leukocytosis.>>> 1',\n",
       " '2  entities\\n 3  entities\\n <<<<The patient was treated with cefotaxime and doxycycline.>>> (34)\\n Extract the entities contained in the text and associated with a relation. Extract only entities contained in the text',\n",
       " '1 entity: \"tests\" 2 entities: \"negative\", \"hospitalization\" 1 entity: \"mycoplasma\" 1 entity: \"lyme\" 1 entity: \"bartonella\"\\n Extract entities only contained in the text',\n",
       " '1 86 The TTE revealed a normal LVEF and an improvement in the LVGLS with segmental reduced values concordant with the CMR abnormalities.\\n @@The TTE revealed@@  @@normal LVEF@@',\n",
       " '2/12\\n    <entity>At one-month follow-up</entity><entity>the patient</entity>\\n    <entity>recurring cardiovascular symptoms</entity><entity>abnormal electrocardiographic</entity><entity>ech',\n",
       " '[{\"entity\": \"hematemesis\"}, {\"entity\": \"A 33-year man\"}, {\"entity\": \"Gulf\"}, {\"entity\": \"this year\"}, {\"entity\": \"15 days ago\"}, {\"entity\": \"the month of February this year\"',\n",
       " '3 Extract only entities contained in the text.<br>  \"Extract the entities contained in the text. Extract only entities contained in the text.<br> Text: <<There was no history of abdominal pain, jaundice or features of chronic liver',\n",
       " '3 7 Extract 27 Extract the entities contained in the text. Extract the entities mentioned in the text. Extract entities present in the text (entities of the text ). Extract only the entities mentioned in the text or contained in the text.',\n",
       " '1.000000 1 0 0 After 1 symptomatic 1 treatment 1 he 1 returned 1 back 0 After 1 returned 1 back 0 1 he returned 1 After 1 he 0',\n",
       " '1.2 Extract the entities contained in the text. 1.3 Extract only entities contained in the text. 1.4 Extract mentions in the text. 1.5 Extract the mentions and attributes of entities contained in the text.',\n",
       " '1.2 entities 1.3 entities 1.2 entities 1.3 attributes 1.2 attributes 1.3 attributes 1.2 attributes 1.3 entities 1.2 entities 1.2 entities 1.2 entities',\n",
       " '1. An admission for evaluation 2. Endoscopy 3. Adenocarc Question: In this text, find the entities \"admitting\", \"endoscopy\" and \"histopathologic examination\".\\n```\\n## Entities extraction',\n",
       " '1. Find entities in text. 2. Extract entities contained in text. 3. Sentence analysis and disambiguation. 4. Extract all entities in the text. 5. Extract all high entities in text 6. Extract',\n",
       " '3 Extract the entities contained in the text.<BR> 4 Extract only entities contained in the text.<BR/> Text: <<Brucella agglutination test was negative.>>><BR> A negative result would be a negative Brucella ag',\n",
       " '1. Extract a noun.  Entity: SOL.  Text: <<shows. SOL.>>  Text type: <<noun. SOL>>  2. Extract a set of nouns.  Entities: SOL,',\n",
       " '1 Extract entities that are relevant to the patient\\'s symptoms. 2. Create an annotation of the symptoms given to the patient and then extract additional entities that are relevant to those symptoms. The annotations would be used during the extraction of relevant entities.[{\"',\n",
       " '1.07533104 1 1.07533104 0 0.0527453016 0 0.0527453016 1',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text.\\n Text: <<Bone marrow aspirate showed decreased red cells and platelets and marrow biopsy done was reported as metastasis from',\n",
       " '1 entities contained in the text. FDP\\n 5,170 ng/dl\\n fibrinogen\\n 152mg/dl\\n```\\n\\n## Entity Recognizer (Extracting entities from text)\\n\\n```\\n2',\n",
       " '1 Extracted entity He 2 Extracted entity He 3 Extracted entity He 4 Extracted entity He 5 Extracted entity Medical Oncology department 6 Extracted entity chemotherapy Text: <<He was treated with chemotherapy',\n",
       " '1. He 2. succumbed 3. his illness 4. 10 months 5. diagnosis The extracted entities are those represented in capital letters in parentheses. 6. Extract an entity from the text if the entity exists inside the',\n",
       " '1 Extracted entity: Pregnant patient 1 Extracted entity: Cesarean delivery 2 Referred to our tertiary clinic 1 Extracted entity: A 26-year-old pregnant patient 1 Extracted entity',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient was having severe right sided abdominal pain with sudden onset.>>>> The patient  right sided abdominal pain sudden onset;',\n",
       " '2 Extract the entities contained in the text. Extract entities containing in the text. Text: <<She was in the 18 th week of her pregnancy based on last menstrual period.>>>&nbsp;</p> 3 Extract the entities contained in',\n",
       " '1 entities 2 entities 3 in size 3 mid and upper right abdomen 3 vascularity 3 in size 3 in size 3 edematous multicystic adnexal mass 3 edematous multicystic adnex',\n",
       " '1. The mass 2. The mass be suspected to originate from right ovary 3. Right ovary 4. right ovary\\n Extract the relationships between entities. Extract only relationships between entities contained in the text.\\n Text: <<The mass',\n",
       " '3 Extract the entities contained in the text. 4 Extract only entities contained in the text. 5 Text: <<It was pushing the pregnant uterus into the left and anterior direction.>>>\\n\\n2000000000',\n",
       " '2 Entity(s). 1.100% evidence 1.100% malignancy Extract only evidence malignancy  Ultrasonographic Extract only evidence  Extract evidence malignancy 100.00%',\n",
       " '1.00  {\"entities\": \"pain complaint\", \"finding\", \"laparotomy\", \"diagnosis\", \"adnexal torsion\", \"adnexal mass\"}[{\"entities\": \"sudden pain\", \"adnex',\n",
       " '1 Extract 1 Extract The skin and fascia incisions were approximately 4cm and 2.5cm in length Skin 35.7 The thick subcutaneous fat tissue Fat 1707.4 this difference was due to the',\n",
       " '1/2cm\\n   3cm\\n   5cm\\n   7cm\\n\\nText: <<An incision of the anterior rectus sheath was approximately 2cm medial to the lateral border of the rectus muscle and it was extended to caud',\n",
       " '1 incision 3 entities 2 dissected 1 edge 4 the rectus muscle 5 rectus muscle 2 laterally 9 semilunar line of rectus muscle 7 1cm width.[{\"entity\": \"rectus muscle\"}, {\"',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text.\\n Text: <<Then, the rectus muscle was retracted medially to expose the posterior sheath of rectus (below the arcuate line, only the',\n",
       " \"1 Extract the entities contained in the text. Extract only entities contained in the text.\\n\\n3 Extract the entities contained in the text. Extract the entities that are not only contained in the text, but also contained in the text's entities.\",\n",
       " '1. Therefore 2. traction forces from enlarging uterus 3. advancing pregnant abdomen 4. enlarging uterus 5. traction forces 6. enlarging uterus in advancing pregnant abdom',\n",
       " '1. A large edematous, necrotic and dark purple torsion of a right adnexal mass 2. A right adnexal mass',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text\\n```It was pulled out and was partially dissected from its surface layer following a 2cm incision.```\\n\\n```',\n",
       " '1 entity 7 entities 2 entities 3 entities 4 entities 1 entities 6 entities 6 entities 2 entities\\n Extract 1 entity contained 1 entity contained 1 entity contained 6 entities contained 6 entities contained 2 entities contained 2',\n",
       " '[[{\"entity\": \"pathology\"}, {\"entity\": \"benign\"}, {\"entity\": \"teratoma\"}, {\"entity\": \"mucinous cystadenoma\"}] 1 7] 0 20} {\"entity\": \"benign\"},',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 2 <<Follow up on the pregnant patient was uneventful a month later.>>>\\nExtract the entities contained in the text. Extract only entities contained in',\n",
       " '1 Extracted entity: FEMALE 70yrs old Osteoarthritis\\n```\\n\\n```\\n### Sentence: 1 - Extracted entity: FEMALE 70yrs old Osteoarth',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text.\\n\\n2. Text: <<The x-rays showed bone on bone Tricompartment OA Knee with Varus Malalignment',\n",
       " '1 entity found:  <<She was posted for Single Stage Bilateral Total Knee Replacement and as planned the Left Knee Was Operated first.>>>>\\n\\n  Extract the entities contained in the text. Extract only entities contained in all the',\n",
       " '1.000000 0.000000 0 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The AP cut was then proceeded with.>>> 0.00',\n",
       " '[[{\"entity\": \"Extract\"}, {\"entity\": \"entities\"}, {\"entity\": \"text\"}, {\"entity\": \"risk\"}, {\"entity\": \"fracture\"}, {\"entity\": \"used\"}, {\"entity\": \"used\"}, {\"entity\": \"femur\"}, {\"entity',\n",
       " '1 entity 1 entities Text: <<A sponge was left in the operative field. >> 2 entities Text: <<The periosteum was closed.[/INST][{\"entity\": \"packed\"}, {\"entity\": \"graft\"}] 1',\n",
       " '1 matched entity text: text: <<Male infant 9.5 month old>> <<examined>> <<the ipsilateral testis lying in a high iliac crest position>> <<scrotum empty>> <<Male infant 9.5',\n",
       " '1 match 3 entities \"crying\" \"swelling with spiral course\" \"intrabdominal pressure\" in the text \"<<With the increase in intrabdominal pressure\"\\n  \"there was an ever-increasing swelling with spiral',\n",
       " '1. The swelling looked like a spigelian hernia 2. spigelian hernia 4. The swelling\\n```\\n\\nShowing 1 to 31 of 314 entries.\\n\\n1. The sw',\n",
       " '2. Extract only those entities that are contained in the text. Extract Entities Extract Entities Extract entities contained in the text entities that are contained in the text entities containing in the text entities contained in the text <<How was the skin of the fetus',\n",
       " '1.1.6. Extract the entities contained in the text. Extract only entities contained in the text. 1.1.2. Text: <<Moreover the ipsilateral scrotum was empty and the testis could be palpated',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. 3. Text: <<Ultrasonography showed a loop of herniated small bowel and an undescended testis on the right.',\n",
       " '1 Extract\\n 2 Extract only\\n\\n 1 Extract\\n 2 Extract only\\n 3 Extract\\n 4 Extract only\\n 5 Extract\\n 6 Extract only\\n 7 Extract\\n 8 Extract only',\n",
       " '1 entity Text: <<an hernia sac>> Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Upon entering the inguinal canal<< a large hernia sac was identified.>> 1 entity Text: <<',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 <<This followed a course through the superficial inguinal ring, extended upwards to the anterior abdomninal wall below the subcutaneous plane',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 1 We noticed that the hernia orifice was in a higher than normal position 5 cm from the pubic bone. Extract the entities found in the',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 bulk 4 testis 5 reduced 6 the abdomen 7 ipsilateral mobile intravaginal testis\\nText: <<He',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The vas and the vessels were intravaginal, the gubernaculum was fixed in an ectopic position and the dorsal inguinal wall',\n",
       " '1. We 2. the large sac 3. the vas and vessels 4. the testis Identified 1. The large sac 2. The vas and vessels 3. The testis Not Identified 1. The removes We 2',\n",
       " '1 Extracted entity: testis 1 Extracted entity: fixed\\n 2 Extracted entity: testis 2 Extracted entity: subdartos pouch 3 Extracted entity: strenghened the dorsal ingu',\n",
       " '5 3 1 0 0 1 0 \"Patient\" \"stayed\" \"the hospital\" \"a day\" 2 1 2 3 \"Patient\" \"a day in the hospital\"  \"patient\" 2',\n",
       " '2.2.3 Extract the entity contained in the text. Extract an entity contained in the text. Text: <<No postoperative complications happened.>>>> 2.3 Text: <<No postoperative complications happened.>>>> 2',\n",
       " '2 Entities Extractor 4 Units Entities Extractor 5 Units Entities Extractor 8 Units Entities 12 Units\\n12 Entities 0 12 Entities 12 Entities 0',\n",
       " '1 Extracted entity  Entity \"The boy\" Text: \"The boy\" Extracted entity  Entity \"now five years after the initial operation\"  Text: \"now five years after the initial operation\" Extracted entity  Extracted entity  Entity',\n",
       " '4 Execute\\n 1 Extract the entities contained in the text.\\n\\n4 Execute <br><ul><li>Extract the entities contained in the text.  </li></ul>\\n\\n 63 years old\\n\\nwound in mouth',\n",
       " '1. Text: \"examination\" 2. Text: \"revealed\" 3. Text: \"lesion\" 4. Text: \"carcinoma\" 5. Text: \"oral squamous cell carcinoma\" 6.',\n",
       " '1. Biopsy 2. lesion 3. infiltrate 4. rich in plasma cells 5. infiltrate 6. plasma cells Text: <<On day 2 of admission, hematesis appeared and he was taken to',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 1 Diagnosis 0 Text: <<Based on this microscopical finding, the final diagnosis was periodontal disease associated with a proliferative non',\n",
       " '1 {text} 2 {refereed, therapy, procedures, The patient} 3 {a specialized dental surgeon}\\nText: <<Clinical examination showed facial puffiness, and euvolemia, the patient was normotensive and',\n",
       " '258 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<After that, according to follow-up with the patient, there were no signs of disease remission.>>> 259 Extract the entities contained',\n",
       " '1 Extract entities contained in the text. 2 Extract only entities contained in the text.\\n 3 \"lesion\" \"increased in size\", \"symptoms\", \"lesion\" 4 \"The lesion\", \"patient\"',\n",
       " \"- 1 entity detected in this extract:\\n\\n 'eosinophils'\\n\\n - 3 entities detected in this extract:\\n\\n 'evidence', 'cells' (2), 'eosinophils'\\n\\n - no entities detected in\",\n",
       " '2 1 2 3 2 <entities> \"An immunohistochemical staining panel\" \"positive\" </entities>  <<An immunohistochemical staining panel was done to determine the nature of this inflam',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. 3. Text: <<These immunohistochemical findings were fundamental for the final diagnosis of LCH.>>>>\\n\\n![image](',\n",
       " \"1. Extract the entities contained in the text. Extract only entities contained in the text. Text: <<The patient's history revealed swellings and pain at knee joint for nearly last 20 years.>>>>\\n```\\n\\nThe patient'\",\n",
       " \"1 2 3 But pain 2 2 2 didn't relieve and limitations in range of motion occurred at knee joint. But pain didn't relieve and limitations in range of motion occurred at knee joint. Knee joint <<But pain >>\",\n",
       " '1: <<findings>> 1: <<examination>> 1: <<mass at anterior knee region.>> 1: <<solid and semi-mobile mass at anterior knee region.>> 2: <<solid and semi-mobile mass at anterior knee region.',\n",
       " '1 Extracted entity: <<Knee joint range of motion was 80 degrees flexion and 0 degrees extension.>>\\n<<Knee joint range of motion was 80 degrees flexion and 0 degrees extension.>> 0 0',\n",
       " \"2 Extract the entities contained in the text. Extract only entities contained in the text.: <<There wasn't any neurovascular pathology.>> 25/08/2017 Extract the entities contained in the text. Extract only\",\n",
       " '2 Extract. 100\\n```\\n\\n<div align=\"center\"><img src=\"https://raw.githubusercontent.com/golom-bio/golom/main/data/generated_models/en_extract_entities',\n",
       " '2 : 0 0 1 0 2 667 732 <<Decision for a surgical intervention was made and after informing the patient, consent was taken>> 589 596 <<The patient was consented',\n",
       " '1.Text (String), 2.Extract the entities contained in the text 2\\n```</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '2 Extract all entities from the text.[{\"entity\":\"knee\"},{\"entity\":\"entered\"},{\"entity\":\"incision\"},{\"entity\":\"knee\"}] 1 entity 4 Extract the entities contained in the text.[{\"entity\":\"kne',\n",
       " '1 Extract the entities contained in the text. 2 Extract only those entities contained in the text. 3 Passed the tissues. 4 Cutaneous and subcutaneous tissues.\\n```\\n\\n```\\n{\"entity\": \"Extract\"},',\n",
       " '1 Extract the entities contained in the text 2 Extract only entities contained in the text Text: <<Quadriceps mechanism was opened with a medial parapatellar incision and patella was toppled to left side.>>>, <<Quad',\n",
       " '1.892454545455 0.080727053377051 1.00000000000002 0.0 0',\n",
       " '1 Extract only entities contained in the text.[{\"entity\": \"tissue\"}, {\"entity\": \"excised\"}, {\"entity\": \"synoviectomy\"}, {\"entity\": \"synovial tissue\"}, {\"entity\": \"synoviectomy\"}] 1{\"',\n",
       " '2.1.1 Extracting named entities from a text\\n\\n## Abstract\\n\\nDue to the presence of several entities which make it difficult to understand its contents, the text is very complex. The text is about surgery and contains names of surgical procedures.',\n",
       " '1 Extracted entity:: The excised mass The excised mass has been sent to the laboratory\\n\\n Text: <<Tumor cells on the peritoneal surface were predominantly in the advanced level.>>>\\n Extracted entity:: Tumor cells',\n",
       " '3 5 Chondromatosis synovial chondromatosis\\n```\\n\\n#### ``` Extract the entities contained in the text. Extract only entities contained in the text. Text: <<Pathology evaluation showed that the mass was consistent with syn',\n",
       " \"1 2 3 Recurrence  detected  visit 2 1\\nRecurrence 2 3 1\\n```\\n\\n```\\n{u'entities': u'Recurrence', u'begin': 1, u'end\",\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Text:\"<<Knee movements were at full range when compared with the other knee.>>>\" Extract all entities mentioned in the text. Extract only entities contained',\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<There was no pain or other complaints.>>>\\n[{\"entity\": \"pain\"}, {\"entity\": \"other complaints\"}] 2 entities} {\"entity\":',\n",
       " '1 Extract 31-year-old woman 1 Extract 3 months\\n\\n 1 Extract chest pain 1 Extract bone and joint pain 1 Extract hair loss 1 Extract asthenia\\n```\\n>>> \"\"\"\"Extract',\n",
       " '3 References.[{\"entity\": \"we\"}, {\"entity\": \"fever\"}, {\"entity\": \"polypnea\"}, {\"entity\": \"arterial hypertension\"}, {\"entity\": \"rash\"}, {\"entity\": \"synovitis\"}, {\"entity\": \"ed',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text.\\n Text: <<Diagnostic assessment: laboratory tests disclosed the following values: Increase level of erythrocyte sedimentation rate 120 mm/1',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text.\\nText: <<The blood count showed hemoglobin at 9g/dl, MCV at 85 µ 3, lymph',\n",
       " '1. entity «test» 2. entity «negative» 3. entity «test»\\n Extract the dates contained in the text. Extract only dates contained in the text.\\n Text: <<30 years old African woman, gravida 4 para',\n",
       " '1.3 Extracted entities: {\"entity\": \"Creatinine\"}, {\"entity\": \"normal\"}] 1.4 Extracted textual entities: {\"text\": \"Creatinine was normal.\"}] 1.5 Extracted terms: {\"',\n",
       " '1/320 with homogeneous pattern, anti-dsDNA level was 160U/ml. 1/320 anti-dsDNA level was 160U/ml. Text: <<Anti-nuclear',\n",
       " '1. Extract the entities contained in the text.\\n\\n1. Extract only entities contained in the text.\\n\\nText: <<Anti-cardiolipin IgG antibodies were positive 25UGPL.>>>\\n\\nAn',\n",
       " '1. Extracts all words within Text.\\n\\t2. Extracts all words that are entities within Text.\\n\\n\\t\\t>> Rheumatoid Factor was negative. <<\\n\\n\\t3. Extracts all words in Text from the voc',\n",
       " '<entity>C4 complement fractions</entity>  C3 <<100mg/dl and 25mg/dl.</entity>  C4 <<0.2 g/l and 0.05 g/l>> 100',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. Text: <<Chest computed tomography (CT) scan showed proximal pulmonary embolism.>>>> Entity: <<pulmonary em',\n",
       " '1. Renal ultrasound 2. normal\\n    Extracted entities are represented as a tuple (entityname, normal), since these\\n    entities come from the same text in a normalised form.[{\"entityname\": \"ultrasound\"}, {\"entity',\n",
       " '1 1 2 2 2 3 3 2 2 3 \"nephritis\" \"nephritis\" \"proliferation\" \"activity class III lupus nephritis \"lupus nephritis',\n",
       " 'Examined the entities contained in the text. Examined only entities contained in the text. Text: <<Serum calcium was elevated 132 mg/l with hyper-calciuria 479 mg/24 h. 2',\n",
       " '1: alcaline phosphatase 2: hypercalcemia 3: hypercalcemia 4: alcaline phosphatase 5: symptoms of hypercalcemia 6: 420 UI/l',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Text: Serum and urine immunofixation as well as Bence-Jones proteinuria were negative.\\nThis is a negative result',\n",
       " '1. Femoral bone mineral density 2. Lumbar bone mineral density 3. Osteoporosis 4. A T 5. -2.6 6. Osteoporosis\\n\\nExtract the relationship between the entities. Extract',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text 3 Text: <<Other causes of hypercalcemia and bone lysis were excluded.>>>\\n 1: hypercalcemia and bone lysis',\n",
       " '2. Extract the values contained in the text. Extract only values contained in the text. Text: <<Suggestion: Start a hormonal synthetic pregnancy, prednisone, heparin.[/{\"entity\": \"pregnancy\"}, {\"entity\":',\n",
       " '2 Extract the entities contained in the text Extract all entities contained in the text Extract only entities contained in the text 3 Extract all entities contained in the text including those whose name is similar to the name of an entity Text: <<Therapeutic intervention',\n",
       " '1 Extracted Entity: Mycophenolate mofetil 2 g/day 2 Extracted Entity: Mycophenolate mofet\\n\\n## Annotate the text with this information:\\n\\n * the entities contained in the text',\n",
       " '1 treatment\\\\nPulmonary embolism\\\\nPulmonary embolism\\\\nTreatment initiation\\\\nheparin\\\\nsubcutaneous\\\\nenoxaparin 0.1 ml/10 kg/12h',\n",
       " '2. Extract entities in the text. 3. Extract only entities contained in the text. 4. Extract the relationships between the entities in the text. 5. Extract the relationships between the entities in the text containing only those specified in the relationship',\n",
       " '1. She 2. require 3. Alendronate 70 mg/week 4. Vitamin D 400u/day 5. osteoporosis\\n1. She - entity of type: PERSON, PAT',\n",
       " '1) The left parathyroid gland 2) was surgically removed\\n 3) Extracting information from the texts to generate the entities.\\n The system receives the texts and extracts two entities respectively. Each entity includes one element in the text and',\n",
       " '1 Extraction  {\"entity\": \"examination\"}, {\"entity\": \"revealed\"}, {\"entity\": \"adenoma\"}, {\"entity\": \"parathyroid adenoma\"}] 2 Extraction  {\"entity\": \"parathyroid ad',\n",
       " '2 Extract the entities contained in the text. Extract only entities contained in the text. Extract the entities contained in the text. 48 hours The surgery\\n\\n###### 1 The surgery she developed oral paresthesia 48 hours',\n",
       " '1 hypocalcemia 72 mg/l Extract the entities contained in the text. Extract only entities contained in the text.\\nText: <<Thyroid with non-focal low-density area of 15 cm in the isthm',\n",
       " '1. She 2. required 3. supplementation 4. few months\\n\\n 4 entities\\n 7 tokens (including punctuation)\\n 2 word types (no stopwords)\\n 2 sentences (including punctuation)\\n```',\n",
       " '1. The patient\\n 2. The patient remained asymptomatic.\\n Extract all occurrences of the text: <<The patient was discharged the next day.>>> Extract one occurrence of the text: <<The patient was discharged the',\n",
       " '1) Corticosteroids 2) dropped 3) the text\\n[{\"entity\": \"Corticosteroids\"}, {\"entity\": \"dropped\"}, {\"entity\": \"the text\"}] 1: Entity mentioned 2: Entity mentioned 3:',\n",
       " '1. The follow-up 2. 4 years The following is an example of output for the same input 1. The follow-up 2. 4 years\\n------------------------------------------------------------------------\\nText: <<The follow-up was 4 years.',\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text.\\n Text: <<Forty year old male presented with a huge mass in this left arm.>>>\\n```</s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '2. Extract all the entities (persons, organizations, locations, events, dates) contained in the text. 3. Extract only entities contained in the text. Text: <<Tumour was friable with necrotic tissue and a large',\n",
       " '1: <<extract the entities contained in the text.>> 1: <<extract only entities contained in the text.>> 1: <<Text: <<However the patient did not undergo surgery and was takin treatment from local bone setters during the last three years',\n",
       " '1 Extracted entities: «32x28 cms with circumference of 87 cms»\\n 15655 entities: <<The current dimensions of tumor was 32x28 cms with circumference of 87 cms.',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. Text: <<X-ray showed complete destruction of the upper humerus with central calcification.>>>\\n```\\n\\n``{\"upper humerus',\n",
       " '1.00 1.00 0.00 A chondrosarcoma was diagnosed in the biopsy.\\n 0.49 1.00 0.15 Biopsy revealed a chondrosarcom',\n",
       " '1 entity:\\n\\n Skeletal survey\\n\\n bone scan\\n\\n lesion\\n\\n body\\n\\n 0 entity.\\n```\\n\\n```\\n Text: <<No additional lesions were identified.>>> 0 entities.\\n```',\n",
       " '1 entity 0 entities\\n The output does not always match the input. If a text was given as input, extract all entities contained in it. Extracting entities from the text should not depend on other entity extraction outputs.\\n Text: <<A forequarter',\n",
       " \"1 2 Extracted entities: <<the patient's>> <<no complains with no recurrence of the tumor's>>\\n-3years\\n\\n-3years follow up\\nText: <<The patient has no complains with no recur\",\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Entity: <<She>> <<consulted>> <<the exacerbation of a left pelvic pain that has been evolving for two weeks prior to admission',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 1 Text: <<A transient lull was observed following a treatment with a progesterone (hydroxyprogesterone caproate) and',\n",
       " '2. Extract the entities contained in the text. 3. Extract only entities contained in the text. 4. Text: <<The resurgence of that lancinating and permanent pain irradiating to the loins and associated with slight vaginal',\n",
       " '3 Entities, 5 Attributes 4 0.001849774 0.14 38.0 18 809 0.5 161 0.05 14',\n",
       " '2 Extract the entities contained in the text.\\n Extract only entities contained in the text.\\n Text: <<She has never practiced contraception.>>> 3 Identify the relationship between the entities.\\nIdentify the relationships between the entities.\\nText',\n",
       " '1 Entity extracted:  She\\n 1 Entity extracted:  treated\\n 1 Entity extracted:  inflammatory disease\\n 1 Entity extracted:  pelvic inflammatory disease\\n 1 Entity extracted:  acute pelvic inflam',\n",
       " '2 entities 1 birth 1 child 1 girl\\n Text: <<My son was born with a cleft of the soft palate.>> 1 entity 1 birth 1 son 1 cleft\\n Text: <<I lost my leg in an accident in',\n",
       " '2. Extract the entities contained in the text Explanation: 2 Extract the entities contained in the text. 3 Extract only entities contained in the text. Explanation: 3. Extract only entities contained in the text. Text: <<',\n",
       " '3 Extract the entities contained in the text.[{\"entity\": \"signs\"}, {\"entity\": \"test\"}, {\"entity\": \"echography\"}, {\"entity\": \"sympathetic signs of pregnancy\"}, {\"entity\": \"urinary pregnancy test\"}, {\"entity\": \"positive',\n",
       " '1. On admission 2. bleeding 3. nausea 4. fever 5. vomiting 6. vaginal bleeding 7. nausea 8. fever 9. vomiting 10. the patient 11. main',\n",
       " '1 general condition    1 blood pressure: 110/70mmHg    1 respiratory rate: 20 cycles/min    1 pulse rate: 70 pulses/min    1 temperature: 37.3 ℃',\n",
       " '1. The abdomen 2. was flat, and 3. mobile with respiration.\\n Text: <<He reported early satiety but no weight loss. He was on a strict vegetarian diet. Routine blood work on admission was unremarkable.',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. 3 Extract the entities contained in the text. Text: <<On palpation there was just a tenderness of the left iliac fossa and the bow',\n",
       " '1 External cervical os 2 vaginal discharge Extract only entities contained in the text Text: <<External cervical os vaginal discharge Inspection under speculum revealed normal gravid external cervical os and there was no vaginal discharge',\n",
       " '1 Extract the entities contained in the text. Extract only entities contained in the text. Text: On digital exploration, the cervix was posterior long and closed, the uterus was globular, increased in size and compatible with an eight weeks pregnancy',\n",
       " '1.0015424961855107 17.0 19.0 7.0 1.0 The left adnexae presented with a tender, smooth and mobile mass of seven centimeters',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. 1 Text: <<The posterior cervico-vaginal fornix was neither tender nor bulging.>>>>  [[{\"entity\": \"tender',\n",
       " '1 entity: β hCG 96 702 mIU/ml\\n1 date: 96 702 mIU/ml\\n[{\"entity\": \"revealed\"}, {\"entity\": \"level\"}, {\"entity\": \"',\n",
       " '1.\\n Extract the entities contained in the text.\\n Extract only entities contained in the text.\\n Text: <<Ultrasonography revealed a heterogenous left ovarian mass of 82 millimeters in diameter, an empty uter',\n",
       " '1 Extract the entities contained in the text.   2 Extract only entities contained in the text.   3 Extract only entities contained in the text AND not the text.   4 Extract only the text\\nThis comforted our first diagnosis.   5 Extract',\n",
       " '1.665345\\n```\\n\\nAs can be seen in the example, the input text is in English and does not contain any special characters (the text has been manually selected to simplify the presentation of the problem). Only the entities of the',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text.\\n Text: <<We dissected the ovarian capsule and carried out ablation of the gestational sac, then we did hemostasis.>>>  Ex',\n",
       " '1 entity: The specimen 2 entity: analysed 3 entity: found 4 entity: tissue 5 entity: trophoblastic tissue 6 entity: the ovarian capsule 7 entity: ovarian pregnancy 8 entity: decid',\n",
       " '1. The\\n```if a text contains a word \"The\" then the text entity is The .\\n``` 2. text Entity extracted from the sentence is The ``The`` .\\n``` 3. The sentence is the text .\\n```',\n",
       " '1. hCG 2. level 3. decreased 4. disappeared 5. 25 days after surgery\\n{text}, {entity}, {entity}, {entity}, {entity}, {entity}, {entity}, {entity}, {entity}, {',\n",
       " 'Extract the entities contained in the text. Extract only entities contained in the text.\\n Text: <<We report the case of a 15-year-old Caucasian girl who was diagnosed with Silver-Russell syndrome at the age of four',\n",
       " '{{{{\"Recombinant growth hormone\"}}}}} 0 16\\n {{{{\"growth hormone\"}}}} {{{\"was administered\"}} {{{\"without an appropriate increase in growth velocity\"}}}}  {{{\"18 months\"',\n",
       " '20.1058776</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '1. The patient 2. characteristic 3. homozygous for the R217X mutation in the growth hormone receptor gene 4. R217X mutation in the growth hormone receptor gene\\n```',\n",
       " \"2 Extracting entities in text 15 years the patient's sexual development almost completed irregularly her height 129.8 cm 3 4.71 standard deviations the median her age.\\n```\\n\\nAge in\",\n",
       " '1 entity, 2 entities and 3 entities, respectively.\\n\\nExtract the entities contained in the text of a given size (e.g., 2 maximum). Text: <<This is a case report of a 59-year old woman with a',\n",
       " '1 entities\\n  100%\\tentities\\textracted\\n  100%\\textracted</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '2. What range of values is normal for each of these tests?\\n 3. What is the reference range for each of these tests?\\n 4. Which text entities would you like to be extracted from the text?\\n 5. Which entities do you want',\n",
       " '1: solid right ovarian 50 an mm-size tumour, 2: small amount of fluid in the Douglas pouch, 3: smooth, solid right ovarian 50 an mm-size tumour, 4: A smooth',\n",
       " '1 Extract. 2 Extract only. 3 Text. 4 Ca-125, free-T4 and TSH. 5 tumour free status. 6 normal range values. 7 2-year. 8 the patient.',\n",
       " '1 entities 0 entities Text: <<A 3 years old girl born from non-consanguineous parents, without any neonatal suffering; with good psychomotor development, from a popular district in one of our cities, without any obvious contact with dogs;',\n",
       " '2 Extract only those entities contained in the text.\\n Extract only entities that are contained in the text (a non-pulsatile, painless, axial, irreducible exophthalmia with no sign of conjunctivitis or kerat',\n",
       " '3 Extract the entities mentioned explicitly in the text, such as \"imaging\", \"Brain\", \"MRI\" and \"orbital apex\". Extract the same entities as in instruction 2, in addition to \"lesion\" and \"orbital',\n",
       " '3 Extract the entities contained in all texts. Extract only entities contained in all texts. 4 Extract the entities contained in no text. Extract only entities contained in no text. 5 Extract all entities contained in all texts. Extract all entities not',\n",
       " '1 entity extracted\\n 1 entity removed\\n```\\n\\nThe patient was operated… 1 entity extracted 1 entity removed\\n\\n```\\n a right extra-dural frontal approach\\n```\\n\\na cyst puncture… 1 entity extracted',\n",
       " '2 Extract the entities contained in the text.[{\"entity\": \"treatment\"}, {\"entity\": \"regression\"}, {\"entity\": \"exophthalmia\"}, {\"entity\": \"improvement\"}, {\"entity\": \"exophthalmia\"}, {\"entity',\n",
       " '2 Extract only entities contained in the text. Text: <<The patient however still retains a right unilateral nasal hemianopia after two years of follow-up.>>>. 3 Extract only entities contained in the text. Text: <<The',\n",
       " '1 entity was extracted  from the text.\\n Extracted entity: <<autistic disorder>>\\n Extracted entities contained in the text:  <<We received a boy 3-year-old boy with autistic disorder on hospital of pediatric ward',\n",
       " '1.  Family history of illness 2.  Autistic spectrum disorder 3.  He 4. <<He>> 5. He has no family history of illness or autistic spectrum disorder 22.02.2013_10',\n",
       " '1 Extract: <<The history revealed that at 2 years of age.>>>>\\n\\n{\"<The history revealed that at 2 years of age.>\"} 1 9\\n  {\"<The history>\"} 0 7\\n  {\"<',\n",
       " '4 Disordered communication behavior 3 Childhood communication disorder 2 Communication disorder 2 Affected child 2 Social interaction difficulties 2 Communication disorder 2 Social behavior disturbance 2 Social interaction behaviors 2 Delay Communication 1 Child The child',\n",
       " '1 Extract the entities contained in the text. 1 Extract only entities contained in the text. Text: <<Blood work was normal (thyroid-stimulating hormone (TSH), hemoglobin, mean corpuscular volume (MC',\n",
       " '1 Genetic testing 2 unremarkable 3 normal karyotype 4 negative 5 demyelinating attack 6 imaging 7 electroencephalography 8 assessment 8 Genetic testing 1unremarkable 3 normal karyotype',\n",
       " '1 1 41 44 210 213\\n```\\n\\n- ##### Autonicity\\n\\nAutonicity represents the degree to which a clinical finding is autonomously present in the patient, independent of the patient’s response',\n",
       " '2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3</span><strong><span class=\"entity-mention\"><a href=\"#\">plan</a></span></strong',\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text.\\nText: <<For that purpose, the parents moved to morocco to be surrounded by family without any huge improvement.>>>>\\nFor a person: <<For that purpose',\n",
       " '2 Extracted text: <<Upon direct questioning at initial presentation, the 3-year-old child was reported by the parents to have unexplained fatigue, Gastrointestinal symptoms included bloating, constipation and diarrhea',\n",
       " '2 3 4 5\\n\\tExtract only entities from text.\\n 2 Psychiatric symptoms included a frequently depressed mood, disproportionate anger, and emotional lability.\\n 3 frequently depressed mood\\n 4 disproportionate anger',\n",
       " '2.000 entities were extracted from the text. The extracted entities are: a child, weighing 3500 g, score 9, score 10, at 1 minute and 5 minutes after birth respectively.\\n - entities 4',\n",
       " '1. Development (n) in the first 24 months of life (n) appeared fine (n) according to the parents-his (n) motor skills (g) seemed to progress (wv) normally (wv) and (vh) he',\n",
       " '2  years of age, however, his language skills slowly began to regress. after 2  years of age.\\n```\\n\\n- 2  years of age\\n- his language skills slowly began to regress\\n- after 2  years of',\n",
       " '1 match 51 %: He 100 %: started to whine repeatedly 100 %: scream without provocation 100 %: change in temperament 100 %: whine 100 %: scream',\n",
       " '[[{\"entity\": \"examination\"}, {\"entity\": \"revealed\"}, {\"entity\": \"weight\"}, {\"entity\": \"normal for age\"}] 1:{\"entity\": \"age\"}, {\"entity\": \"weight\"}, {\"entity\": \"normal for age\"}]',\n",
       " '1 entities extracted from the text. >> He\\n\\n 2018-04-02 15:02:25.607 1 entities found\\n Text: <<He was uncommunicative, restless, and somewhat',\n",
       " '3 Extract the entities contained in the text. Extract only entities contained in the text. Text: <<General examination was unremarkable other than dark rings around the eyes.\\n >>>\\n```\\n\\nPlease check this bug.\\n\\nHere, the output entities',\n",
       " '2 entities detected: \"anti-tissue transglutaminase antibodies levels\".\\n Text: <<The serology did not support celiac disease.>>> 1 entities detected: \"celiac disease\".\\n Text: <<The child is on a gluten',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Text: <<It shows a total villous atrophy corresponding to a stage 4 of Marsh classification.>>>> 4. Atrophy 3.',\n",
       " '2 Extracting n-entities from the text. 3 The n-entities were successfully extracted. 4 The n-entities contained in the text were successfully extracted. 95% Confidence interval for the sample proportion was 0.464-0',\n",
       " \"1 month  the boy's gastrointestinal symptoms  changed 1 month  the boy's gastrointestinal symptoms  the boy's behavior  the boy 1 month  <<Within 1 month, the boy's gastro\",\n",
       " '3 Extracted entities: <\"The mother\">  <\"her boy\">  <\"communicate\"> 1 Extracted entity substrings: <\"her boy\">  Text: <<The mother reported the onset of communication in her boy.>>>',\n",
       " '1. The child 2. Continued 3. Has 4. Remained\\n```\\n\\n```\\n{\\n  \"entities\": [\\n    \"The child\",\\n    \"has\",\\n    \"remained\",\\n    \"The child',\n",
       " 'There might be missing contextual sentences before and after. That is not possible to know the correct text for sure, but it does not inter neueŐ prze przeplaatka. She was treated with antibiotіс neŭplaatst на ноugno prophyl actic.[{\"',\n",
       " '1 She 1 appointed 1 hospital 1 surgical center 1 drainage 1 perineal abscess 1 She 1 a week before\\n2 Extract the names, if any, in the text. Extract only the names in the text',\n",
       " '2 Extract the entities contained in the text. Extract only entities\\nfound in the text. Text: <<Past medical history included Henoch-Schönlein purpura during childhood.>>>  entities  Text: <<Past medical history included Henoch',\n",
       " '2 Extract the entities contained in the text. Extract all entities. Text: <<Social history included smoking (11 pack-years), family history was non-contributory.>>>> 3 Extract the entities contained in the text. Extract',\n",
       " '1 entity contained in the text: <<drug allergies>>. 1 entities contained in the text: <<drug allergies>>.\\n\\n Extract only entities mentioned in the text. Text: <<She had no known drug allergies.>>> 0 entities',\n",
       " '1 entity  CT  scan  revealed  sm bil ple eff  sm hep en  Ge fasc thin soft tissue stranding  perineal str  fasc  bubble\\n\\n                            1 entity   sm bil ple eff  sm hep en  Gerota',\n",
       " '4 4 7} {\"entity\": \"Fournier\\'s gangrene\"}, {\"entity\": \"diagnosis\"}, {\"entity\": \"FGSI\"}, {\"entity\": \"UFGSI\"}, {\"entity\": \"LRINEC\"}, {\"entity',\n",
       " '1 entity  The \"Blood\"   The \"surgical material\" The main entities within the text are 0 The \"Blood\" And 0 The \"surgical material\"\\n\\n[{\"entity\": \"analysis\"}, {\"entity\": \"blood',\n",
       " '1 Extract 2 Extract 3 days  second CT obstetrical consultation  no significant findings 3 days Text: <<Although no abdominal aortic aneurysm was identified, extensive colonic diverticulosis was found.>>',\n",
       " '1. Human immunodeficiency virus 2. diabetic screen 3. negative 4. human immunodeficiency virus 5. diabetic screen 6. negative\\n\\n- Extract the entities contained in the text. Extract only entities',\n",
       " '1. <<remained febrile>>\\n\\n### Extract the entities contained in the text. Extract only entities contained in the text.\\n\\nExtract only entities contained in the text.\\n Text: <<Yet, the patient remained febrile.>>>',\n",
       " '1 Extract the entities contained in the text. 2 Extract only entities contained in the text. Text: <<Percutaneous tracheotomy was also performed.>>> 3 <<Percutaneous tracheotomy was also performed.>>>\"',\n",
       " '2 Extract annotated entities.[{\"entity\": \"therapy\"}, {\"entity\": \"availability\"}, {\"entity\": \"therapy\"}] 3 Extract unannotated entities.[{\"entity\": \"oxygen\"}, {\"entity\": \"Hyperbaric oxygen',\n",
       " '1. Extract the entities contained in the text. 2. Extract only entities contained in the text. 3. Text: <<Along with that, a localized oedema appeared in her left upper limb.>>>>>\\n```',\n",
       " '1. A palpable mass along the anterior margin of the sternocleidomastoid muscle 2. the anterior margin of the sternocleidomastoid muscle\\n\\n###### Keywords: palpable mass, palpable mass in the',\n",
       " '1 Explanation: Entities Extraction\\n\\n\\nExtract the entities and their relations. Extract only entities and their relations contained in the text.\\n Text: <<The patient was a 55 y-old-man who was admitted to our facility because',\n",
       " '1 entity(Linezolide 600 mg q12h i.v.)\\n```</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '1. extracted_entities:[{\"entity\": \"afebrile\"}, {\"entity\": \"condition\"}, {\"entity\": \"improved\"}, {\"entity\": \"afebrile\"}, {\"entity\": \"patients\"}] 2. extracted_entities_from_text',\n",
       " '1 Extracted entities: <<She was discharged from ICU 13 days later.>>>>\\n1/1 0 sec 0.00 bytes\\n```\\n\\nAnother experiment with the Text entity extractor:\\n\\n```',\n",
       " 'Text weitڈ prze neue gleich 4dau die Bl Gebietd weitere Bl Gebietd Bl beiden Bl veins Thrombus im bl beiden v blood bl Gebietd  veins ThRombus bl v th v thrombigt und ven ve neuen Bl area blood Bl',\n",
       " '1. On a follow-up examination 6 months later<br/> 2. the young woman<br/> 3. a young woman<br/> 4. a woman<br> Extract the entities contained in the text.<br/> Extract only']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor.test_data['model_responses']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL INSTRUCT simplest_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/pferrazzi/miniconda3/envs/lm_finetune_env/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config import postprocessing\n",
    "from utils.test_data_processor import TestDataProcessor\n",
    "import pandas as pd\n",
    "from utils.generate_ft_adapters_list import generate_ft_adapters_list\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "adapters = 'ferrazzipietro/Mistral-7B-v0.1_simplest_prompt_adapters_en.layer1_4_torch.bfloat16_32_32_0.01_4_0.0002'\n",
    "model_checkpoint = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "layer = 'en.layer1'\n",
    "language = layer.split('.')[0]\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[layer]\n",
    "preprocessor = DataPreprocessor(model_checkpoint=model_checkpoint, \n",
    "                                tokenizer = model_checkpoint)\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset,\n",
    "                                                 instruction_on_response_format='Return the result in a json format: [{\"entity\":\"entity_name\"}].',\n",
    "                                                 simplest_prompt=True)\n",
    "_, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, layer)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            #load_in_8bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            # llm_int8_threshold= 6.0,\n",
    "            # llm_int8_has_fp16_weight = False,\n",
    "            # llm_int8_skip_modules= [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it]\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_checkpoint, low_cpu_mem_usage=True,\n",
    "    quantization_config = bnb_config,\n",
    "    return_dict=True, \n",
    "    #torch_dtype=torch.float16,\n",
    "    device_map= \"auto\")\n",
    "merged_model = PeftModel.from_pretrained(base_model, adapters, token=HF_TOKEN, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_eos_token=False)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = \"left\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses:   0%|          | 0/681 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating responses: 704it [06:34,  1.78it/s]                         \n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.74ba/s]\n"
     ]
    }
   ],
   "source": [
    "postprocessor = TestDataProcessor(test_data=val_data,\n",
    "                                  preprocessor=preprocessor, \n",
    "                                  n_shots_inference=0, \n",
    "                                  language=language, \n",
    "                                  tokenizer=tokenizer)\n",
    "postprocessor.add_inference_prompt_column()\n",
    "postprocessor.add_ground_truth_column()\n",
    "#try:\n",
    "postprocessor.add_responses_column(model=merged_model, \n",
    "                                tokenizer=tokenizer, \n",
    "                                batch_size=32, \n",
    "                                max_new_tokens_factor=2)\n",
    "postprocessor.test_data.to_csv(f\"data/test_data_processed/maxNewTokensFactor{6}_nShotsInference{0}_{adapters.split('/')[1]}.csv\", index=False)\n",
    "# except Exception as e:\n",
    "#     print(\"ERROR IN PROCESSING: \", Exception, adapters)\n",
    "del merged_model\n",
    "del base_model\n",
    "del tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  5.10ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2928976"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor.test_data.to_csv(f\"data/test_data_processed/maxNewTokensFactor{6}_nShotsInference{0}_{adapters.split('/')[1]}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[{\"entity\": \"46-year-old man\"}, {\"entity\": \"hypertension\"}, {\"entity\": \"dysl',\n",
       " '[{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"indicated\"}, {\"entity\": \"ECS\"',\n",
       " '[{\"entity\": \"findings\"}, {\"entity\": \"malignancy\"}, {\"entity\": \"right parotid malignancy\"},',\n",
       " '[{\"entity\": \"parotidectomy\"}, {\"entity\": \"examination\"}, {\"entity\": \"confirmed\"}, {\"entity\":',\n",
       " '[{\"entity\": \"hypercortisolism\"}, {\"entity\": \" managed\"}, {\"entity\": \"metyrapone\"}, {\"',\n",
       " '[{\"entity\": \"50-years-old woman\"}, {\"entity\": \"hypertensive\"}, {\"entity\": \"hospital',\n",
       " '[{\"entity\": \"MNG\"}, {\"entity\": \"her mother\"}, {\"entity\": \"sisters\"}, {\"entity\": \"c',\n",
       " '[{\"entity\": \"signs of cervical compression\"}, {\"entity\": \"respiratory signs\"}, {\"entity\": \"digest',\n",
       " '[{\"entity\": \"thyroid dysfunction\"}]</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '[{\"entity\": \"mass\"}, {\"entity\": \"took\"}, {\"entity\": \"the front and the two sides of the neck\"',\n",
       " '[{\"entity\": \"surface\"}, {\"entity\": \"embossed\"}, {\"entity\": \"covered\"}, {\"entity\": \"skin\"}]',\n",
       " '[{\"entity\": \"veins of the collateral circulation\"}, {\"entity\": \"limited to the neck\"}] [{\"entity\": \"']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor.test_data['model_responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[{\"entity\": \"diagnosed\"}, {\"entity\": \"unveiled\"}, {\"entity\": \"referred\"}, {\"entity\": \"',\n",
       " '[{\"entity\": \"study\"}, {\"entity\": \"tests\"}, {\"entity\": \"indicated\"}, {\"entity\": \"ECS\"',\n",
       " '[{\"entity\": \"findings\"}, {\"entity\": \"cavity\"}, {\"entity\": \"malignancy\"}, {\"entity\": \"met',\n",
       " '[{\"entity\": \"parotidectomy\"}, {\"entity\": \"examination\"}, {\"entity\": \"confirmed\"}, {\"entity\":',\n",
       " '][{\"entity\": \"hypercortisolism\"}, {\"entity\": \"managed\"}] ---------- ------------ The entities contained in the',\n",
       " '[{\"entity\": \"hypertensive\"}, {\"entity\": \"hospitalized\"}, {\"entity\": \"mass\"}, {\"entity\": \"appe',\n",
       " '][{\"entity\": \"history\"}, {\"entity\": \"surgery\"}, {\"entity\": \"MNG\"}, {\"entity\": \"her mother\"},',\n",
       " '][{\"entity\": \"compression\"}, {\"entity\": \"signs\"}, {\"entity\": \"cervical compression\"}, {\"entity\": \"',\n",
       " '[{\"entity\": \"dysfunction\"}, {\"entity\": \"thyroid dysfunction\"}] \\n[{\"entity\": \"she\"',\n",
       " '[{\"entity\": \"The mass\"}, {\"entity\": \"the neck\"}] ][]][//][{\"entity\": \"The',\n",
       " '[{\"entity\": \"covered\"}, {\"entity\": \"surface\"}, {\"entity\": \"thin normal skin\"}] ][{\"entity\":',\n",
       " '[{\"entity\": \"limited\"}, {\"entity\": \"the neck\"}] ][{\"entity\": \"veins of the collateral circulation']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor.test_data['model_responses']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. diagnosed: diagnose\\n 2. mellitus: diabetes mellitus\\n 3. hypertension',\n",
       " '{\"Text\": \"study\", \"study\": \"Hormonal study\"}][{\"Entity\": \"study\"}, {\"Entity\":',\n",
       " '1. findings\\n 2. pointed\\n 3. malignancy\\n 4. metastases\\n 5. liver',\n",
       " 'Entities: \"parotidectomy\", \"examination\", \"confirmed\", \"ACC\", \"The patient\"\\n Types:',\n",
       " 'Entities: hypercortisolism, managed, metyrapone, ketoconazole, lanreotide,',\n",
       " '1. hypertensive \\n2. hospitalized\\n3. cervical mass\\n4. appeared\\n5. a',\n",
       " '{\"family history\", \"surgery\", \"MNG\", \"mother\", \"sisters\", \"cousins\"} ]]]>',\n",
       " '1. signs of cervical compression\\n 2. signs of respiratory compression\\n 3. signs of digestive compression',\n",
       " \"{'She': 'PERSON'} [{'thyroid dysfunction': 'disorder'}]</s></s></s></s></s></s></s></s></s>\",\n",
       " '{\"The mass\"} ]</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '{\"surface\": \"embossed and covered by a thin normal skin\"}][{\"surface\": \"covered by a thin normal skin\"}, {\"',\n",
       " 'Entities: {\"Some veins of the collateral circulation\"}[{\"veins of the collateral circulation\"}]\\n\\n{\"coll']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor.test_data['model_responses']  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_finetune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
