WARNING: grid.env NOT FOUND
NO Enviroment
Date: Tue 23 Apr 2024 07:39:04 AM UTC
Directory: /home/ferrazzi/llm/mistral_finetuning
This job will be executed on th following nodes: vgpu6-0

/home/ferrazzi/.conda/envs/gpu_venv_lates/bin/python
Python 3.8.18
['ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_8_0.0002']
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 4
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_4_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_8_0.0002 n_shots_inference: 0 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_2_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_4_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_8_0.0002 n_shots_inference: 2 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_32_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_16_64_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_32_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_32_64_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_32_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_2_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_4_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_NoQuant_torch.bfloat16_64_64_0.01_8_0.0002 n_shots_inference: 4 max_new_tokens_factor: 8
NO QUANTIZATION
