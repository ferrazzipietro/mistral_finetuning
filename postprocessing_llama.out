WARNING: grid.env NOT FOUND
NO Enviroment
Date: Mon 15 Apr 2024 04:04:24 PM UTC
Directory: /home/ferrazzi/llm/mistral_finetuning
This job will be executed on th following nodes: vgpu6-0

/home/ferrazzi/.conda/envs/gpu_venv_lates/bin/python
Python 3.8.18
['ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_2_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_4_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_8_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.01_2_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.01_4_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.01_8_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.05_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.05_2_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.05_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.05_4_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.05_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.05_8_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_2_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_4_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_32_32_0.01_8_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.05_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.05_2_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.05_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.05_4_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.05_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.05_8_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.01_2_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.01_2_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.01_4_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.01_4_0.0008', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.01_8_0.0002', 'ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_64_32_0.01_8_0.0008']
PROCESSING: ferrazzipietro/llama-2-7b-chat-hf_adapters_en.layer1_8_torch.bfloat16_16_32_0.05_2_0.0002 n_shots_inference: 0 max_new_tokens_factor: 4
QUANTIZATION
