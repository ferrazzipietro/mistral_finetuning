{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from dotenv import dotenv_values\n",
    "from datasets import load_dataset, Dataset\n",
    "from utils.data_preprocessor import DataPreprocessor\n",
    "from utils.postprocessor import DataPostprocessor\n",
    "from utils.evaluator import Evaluator\n",
    "from config import config\n",
    "\n",
    "HF_TOKEN = dotenv_values(\".env.base\")['HF_TOKEN']\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "\n",
    "load_model = False\n",
    "if load_model:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "    base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "        config.BASE_MODEL_CHECKPOINT, low_cpu_mem_usage=True,\n",
    "        quantization_config = bnb_config,\n",
    "        return_dict=True,  load_in_4bit=True, #torch_dtype=torch.float16,\n",
    "        device_map= \"auto\")\n",
    "\n",
    "    adp = config.ADAPTERS_CHECKPOINT\n",
    "    merged_model = PeftModel.from_pretrained(base_model_reload, adp, token=HF_TOKEN, device_map=\"auto\")\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(config.BASE_MODEL_CHECKPOINT, add_eos_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ferrazzipietro/e3c-sentences\", token=HF_TOKEN)\n",
    "dataset = dataset[config.TRAIN_LAYER]\n",
    "preprocessor = DataPreprocessor()\n",
    "dataset = preprocessor.preprocess_data_one_layer(dataset)\n",
    "train_data, val_data, _ = preprocessor.split_layer_into_train_val_test_(dataset, config.TRAIN_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = DataPostprocessor(val_data, preprocessor, 2, 'eng', tokenizer)\n",
    "preprocessor.instruction_on_response_format = 'Output must be of this format: [{\"entity\": \"entity_name\"}]. Do not provide anything else than the required format.'\n",
    "# postprocessor.add_inference_prompt_column()\n",
    "# postprocessor.add_ground_truth_column()\n",
    "# postprocessor.add_responses_column(merged_model, tokenizer, batch_size=16)\n",
    "# postprocessor.test_data.to_csv('data/postprocessor_output.csv', index=False)\n",
    "postprocessor.test_data = load_dataset('csv', data_files='data/postprocessor_output.csv', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation':      TP  FP  FN\n",
       " 0     8   3   2\n",
       " 1     2   1   2\n",
       " 2     4   2   0\n",
       " 3     5   0   0\n",
       " 4     2   3   0\n",
       " ..   ..  ..  ..\n",
       " 676   1   0   3\n",
       " 677   3   4   1\n",
       " 678   3   0   0\n",
       " 679   0   1   5\n",
       " 680   2   3   2\n",
       " \n",
       " [681 rows x 3 columns],\n",
       " 'precision': 0.5660495764041418,\n",
       " 'recall': 0.4891540130151844,\n",
       " 'f1': 0.5248}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = Evaluator(preprocessor, postprocessor.test_data)\n",
    "results = evaluator.generate_evaluation_table()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL RESPONSE: [{\"entity\": \"measured\"}, {\"entity\": \"goiter\"}, {\"entity\": \"18 x 11 cm\"}] \n",
      "\n",
      "[[{\"entity\": \"pat\"}, {\"entity\": \"presented\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}, {\"entity\": \"18 x 11 cm\"}] \n",
      "\n",
      "These entities are contained in the text: \"a 9-month-old\", \"3-day\", \"38.5°C\", \"24 hours\", \"febrile peaks\", \"38.5°C\" and \"18 x 11 cm\". \n",
      "\n",
      "The entities extracted are: \n",
      "\n",
      "[{\"entity\": \"presentation\"}, {\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"peaks\"}, {\"entity\": \"18 x 11 cm\"}] \n",
      "\n",
      "I think there is a mistake in the text, as the temperature is given in degrees Celsius but there is a mention of \"febrile peaks\", indicating a fever but without indicating the degree of the fever, which can be in Celsius or Fahrenheit. I assume it means febrile peaks of 38.5°C.\n",
      "\n",
      "The table below shows the entities contained in the text, their entities contained in the text and their entities contained in the text:\n",
      "\n",
      "\n",
      "MODEL RESPONSE: [{\"entity\": \"measured\"}, {\"entity\": \"goiter\"}, {\"entity\": \"18 x 11 cm\"}]\n",
      "\n",
      "\n",
      "GROUND TRUTH: [{\"entity\": \"measured\"}, {\"entity\": \"The goiter\"}, {\"entity\": \"18 x 11 cm\"}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "index = 12\n",
    "def show_example(index):\n",
    "    one_example = postprocessor.test_data['model_responses'][index]\n",
    "    print('ORIGINAL MODEL RESPONSE:', one_example)\n",
    "    one_example = re.findall(r'\\[\\{(.+?)\\}\\]', one_example)\n",
    "    one_example = '[{' + one_example[0] +  '}]'\n",
    "    print(f'\\n\\nMODEL RESPONSE: {one_example}')\n",
    "    print(f'\\n\\nGROUND TRUTH: {postprocessor.test_data[\"ground_truth\"][index]}')\n",
    "show_example(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL RESPONSE: ][{\"entity\": \"test\"}, {\"entity\": \"accepted\"}, {\"entity\": \"retarded\"}, {\"entity\": \"she\"}, {\"entity\": \"75 points\"}] \n",
      "[{\"entity\": \"mildly mentally retarded\"}, {\"entity\": \"75 points\"}] \n",
      "[{\"entity\": \"mildly mentally retarded\"}, {\"entity\": \"9-month-old boy\"}, {\"entity\": \"38.5°C\"}] \n",
      "[{\"entity\": \"refusal\"}, {\"entity\": \"bear\"}, {\"entity\": \"febrile peaks\"}, {\"entity\": \"38.5°C\"}] \n",
      "[{\"entity\": \"3-day\"}, {\"entity\": \"24 hours\"}] ������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      "\n",
      "\n",
      "MODEL RESPONSE: [{\"entity\": \"test\"}, {\"entity\": \"accepted\"}, {\"entity\": \"retarded\"}, {\"entity\": \"she\"}, {\"entity\": \"75 points\"}]\n",
      "\n",
      "\n",
      "GROUND TRUTH: [{\"entity\": \"test\"}, {\"entity\": \"retarded\"}, {\"entity\": \"mildly mentally retarded\"}, {\"entity\": \"she\"}, {\"entity\": \"75 points\"}]\n"
     ]
    }
   ],
   "source": [
    "show_example(121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'diagnosed'}, {'entity': 'unveiled'}, {'entity': 'referred'}, {'entity': 'io'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[{\"entity\": \"diagnosed\"}, {\"entity\": \"unveiled\"}, {\"entity\": \"referred\"}, {\"entity\":\"io\"}]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor = DataPostprocessor(val_data, preprocessor, 2, 'eng', tokenizer)\n",
    "preprocessor.instruction_on_response_format = 'Output must be of this format: [{\"entity\": \"entity_name\"}]. Do not provide anything else than the required format.'\n",
    "postprocessor.test_data = load_dataset('csv', data_files='data/postprocessor_output.csv', split='train')\n",
    "#postprocessor._postprocess_model_output(postprocessor.test_data['model_responses'][0])\n",
    "postprocessor._postprocess_model_output('[{\"entity\": \"diagnosed\"}, {\"entity\": \"unveiled\"}, {\"entity\": \"referred\"}, {\"entity\":\"io\"}] dsacbasdkjcbskòa ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
