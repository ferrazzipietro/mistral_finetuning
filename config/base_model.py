max_new_tokens_factor_list = [8]
n_shots_inference_list = [0,1,2,3,4]
TRAIN_LAYER = 'en.layer1'
save_directory = "data/llama" # "data/gemma/test_data_processed"
BASE_MODEL_CHECKPOINT = "meta-llama/Llama-2-13b-chat-hf"# "google/gemma-7b-it" # "mistralai/Mistral-7B-Instruct-v0.2"
