# EVALUATION
similar_is_equal_threshold_list=[100]
words_level = True
similarity_types = ['case', 'stop_words', 'subset', 'superset', 'levenshtein']
wrong_keys_to_entity = False
offset = False


# params for evaluation.py, not all
input_data_dir_path = 'data/mistral/NoQuant_FT_float16'
output_data_path = 'data/evaluation_results/mistral_NoQuant_FT_float16.csv'

